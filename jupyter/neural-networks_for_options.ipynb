{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow_core.estimator import inputs\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18740 train examples\n",
      "2083 test examples\n",
      "6329 train examples\n",
      "704 test examples\n",
      "6329 train examples\n",
      "704 test examples\n",
      "6296 train examples\n",
      "700 test examples\n"
     ]
    }
   ],
   "source": [
    "def normalize_and_encode(dataframe):\n",
    "    column_names_to_not_normalize = ['result']\n",
    "    column_names_to_normalize = [x for x in list(dataframe) if x not in column_names_to_not_normalize ]\n",
    "    x = dataframe[column_names_to_normalize].values\n",
    "    x_scaled = preprocessing.normalize(x)\n",
    "    df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = dataframe.index)\n",
    "    dataframe[column_names_to_normalize] = df_temp\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit([ \"H\", \"A\", \"D\"])\n",
    "    dataframe.loc[:,['result']]=le.transform(dataframe['result'])\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def get_X_and_y(dataframe):\n",
    "    X = dataframe.drop(columns=['result']).values\n",
    "    y = dataframe[['result']].values\n",
    "    return X,y\n",
    "\n",
    "df01 = pd.read_csv('../data/sliding01.csv', sep=',', index_col=0)\n",
    "df02 = pd.read_csv('../data/sliding02_shots.csv', sep=',', index_col=0)\n",
    "df03 = pd.read_csv('../data/sliding03_shots_extra.csv', sep=',', index_col=0)\n",
    "df04 = pd.read_csv('../data/sliding04_shots_possession_extra.csv', sep=',', index_col=0)\n",
    "\n",
    "n01 = normalize_and_encode(df01)\n",
    "n02 = normalize_and_encode(df02)\n",
    "n03 = normalize_and_encode(df03)\n",
    "n04 = normalize_and_encode(df04)\n",
    "\n",
    "train01, test01 = train_test_split(n01, test_size=0.1)\n",
    "print(len(train01), 'train examples')\n",
    "print(len(test01), 'test examples')\n",
    "\n",
    "train02, test02 = train_test_split(n02, test_size=0.1)\n",
    "print(len(train02), 'train examples')\n",
    "print(len(test02), 'test examples')\n",
    "\n",
    "train03, test03 = train_test_split(n03, test_size=0.1)\n",
    "print(len(train03), 'train examples')\n",
    "print(len(test03), 'test examples')\n",
    "\n",
    "train04, test04 = train_test_split(n04, test_size=0.1)\n",
    "print(len(train04), 'train examples')\n",
    "print(len(test04), 'test examples')\n",
    "\n",
    "\n",
    "train_X01,train_y01 = get_X_and_y(train01)\n",
    "train_X02,train_y02 = get_X_and_y(train02)\n",
    "train_X03,train_y03 = get_X_and_y(train03)\n",
    "train_X04,train_y04 = get_X_and_y(train04)\n",
    "\n",
    "test_X01,test_y01 = get_X_and_y(test01)\n",
    "test_X02,test_y02 = get_X_and_y(test02)\n",
    "test_X03,test_y03 = get_X_and_y(test03)\n",
    "test_X04,test_y04 = get_X_and_y(test04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.049957</td>\n",
       "      <td>0.165301</td>\n",
       "      <td>0.330601</td>\n",
       "      <td>0.183667</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>0.073467</td>\n",
       "      <td>0.514268</td>\n",
       "      <td>0.367334</td>\n",
       "      <td>0.073467</td>\n",
       "      <td>0.073467</td>\n",
       "      <td>0.220401</td>\n",
       "      <td>0.293868</td>\n",
       "      <td>0.514268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077897</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.121172</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.138483</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.553931</td>\n",
       "      <td>0.415448</td>\n",
       "      <td>0.138483</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.484690</td>\n",
       "      <td>0.415448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.109311</td>\n",
       "      <td>0.117119</td>\n",
       "      <td>0.105407</td>\n",
       "      <td>0.195198</td>\n",
       "      <td>0.078079</td>\n",
       "      <td>0.117119</td>\n",
       "      <td>0.390396</td>\n",
       "      <td>0.312317</td>\n",
       "      <td>0.156158</td>\n",
       "      <td>0.156158</td>\n",
       "      <td>0.078079</td>\n",
       "      <td>0.585594</td>\n",
       "      <td>0.507514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068789</td>\n",
       "      <td>0.117049</td>\n",
       "      <td>0.155945</td>\n",
       "      <td>0.180075</td>\n",
       "      <td>0.108045</td>\n",
       "      <td>0.072030</td>\n",
       "      <td>0.648271</td>\n",
       "      <td>0.396166</td>\n",
       "      <td>0.108045</td>\n",
       "      <td>0.108045</td>\n",
       "      <td>0.144060</td>\n",
       "      <td>0.360151</td>\n",
       "      <td>0.396166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.108097</td>\n",
       "      <td>0.154424</td>\n",
       "      <td>0.205899</td>\n",
       "      <td>0.102949</td>\n",
       "      <td>0.205899</td>\n",
       "      <td>0.205899</td>\n",
       "      <td>0.308848</td>\n",
       "      <td>0.463272</td>\n",
       "      <td>0.051475</td>\n",
       "      <td>0.308848</td>\n",
       "      <td>0.154424</td>\n",
       "      <td>0.360322</td>\n",
       "      <td>0.514746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20818</td>\n",
       "      <td>2</td>\n",
       "      <td>0.162536</td>\n",
       "      <td>0.123527</td>\n",
       "      <td>0.055262</td>\n",
       "      <td>0.097521</td>\n",
       "      <td>0.065014</td>\n",
       "      <td>0.162536</td>\n",
       "      <td>0.260057</td>\n",
       "      <td>0.487607</td>\n",
       "      <td>0.065014</td>\n",
       "      <td>0.130029</td>\n",
       "      <td>0.130029</td>\n",
       "      <td>0.325071</td>\n",
       "      <td>0.682650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20819</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061498</td>\n",
       "      <td>0.110696</td>\n",
       "      <td>0.113771</td>\n",
       "      <td>0.092247</td>\n",
       "      <td>0.092247</td>\n",
       "      <td>0.122995</td>\n",
       "      <td>0.307489</td>\n",
       "      <td>0.584228</td>\n",
       "      <td>0.030749</td>\n",
       "      <td>0.122995</td>\n",
       "      <td>0.153744</td>\n",
       "      <td>0.215242</td>\n",
       "      <td>0.645726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20820</td>\n",
       "      <td>2</td>\n",
       "      <td>0.073697</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.184242</td>\n",
       "      <td>0.122828</td>\n",
       "      <td>0.163770</td>\n",
       "      <td>0.122828</td>\n",
       "      <td>0.409426</td>\n",
       "      <td>0.368484</td>\n",
       "      <td>0.204713</td>\n",
       "      <td>0.081885</td>\n",
       "      <td>0.122828</td>\n",
       "      <td>0.614139</td>\n",
       "      <td>0.368484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20821</td>\n",
       "      <td>2</td>\n",
       "      <td>0.044350</td>\n",
       "      <td>0.175065</td>\n",
       "      <td>0.300111</td>\n",
       "      <td>0.066691</td>\n",
       "      <td>0.100037</td>\n",
       "      <td>0.166729</td>\n",
       "      <td>0.400149</td>\n",
       "      <td>0.466840</td>\n",
       "      <td>0.100037</td>\n",
       "      <td>0.100037</td>\n",
       "      <td>0.133383</td>\n",
       "      <td>0.366803</td>\n",
       "      <td>0.533532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20822</td>\n",
       "      <td>2</td>\n",
       "      <td>0.055791</td>\n",
       "      <td>0.140313</td>\n",
       "      <td>0.175391</td>\n",
       "      <td>0.200447</td>\n",
       "      <td>0.033408</td>\n",
       "      <td>0.100223</td>\n",
       "      <td>0.334078</td>\n",
       "      <td>0.267263</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>0.033408</td>\n",
       "      <td>0.167039</td>\n",
       "      <td>0.467709</td>\n",
       "      <td>0.668156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20823 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0           2   0.049957   0.165301   0.330601   0.183667    0.110200   \n",
       "1           1   0.077897   0.103862   0.121172   0.103862    0.138483   \n",
       "2           1   0.109311   0.117119   0.105407   0.195198    0.078079   \n",
       "3           0   0.068789   0.117049   0.155945   0.180075    0.108045   \n",
       "4           2   0.108097   0.154424   0.205899   0.102949    0.205899   \n",
       "...       ...        ...        ...        ...        ...         ...   \n",
       "20818       2   0.162536   0.123527   0.055262   0.097521    0.065014   \n",
       "20819       2   0.061498   0.110696   0.113771   0.092247    0.092247   \n",
       "20820       2   0.073697   0.153535   0.184242   0.122828    0.163770   \n",
       "20821       2   0.044350   0.175065   0.300111   0.066691    0.100037   \n",
       "20822       2   0.055791   0.140313   0.175391   0.200447    0.033408   \n",
       "\n",
       "       home-losses  home-goals  home-opposition-goals  away-wins  away-draws  \\\n",
       "0         0.073467    0.514268               0.367334   0.073467    0.073467   \n",
       "1         0.103862    0.553931               0.415448   0.138483    0.103862   \n",
       "2         0.117119    0.390396               0.312317   0.156158    0.156158   \n",
       "3         0.072030    0.648271               0.396166   0.108045    0.108045   \n",
       "4         0.205899    0.308848               0.463272   0.051475    0.308848   \n",
       "...            ...         ...                    ...        ...         ...   \n",
       "20818     0.162536    0.260057               0.487607   0.065014    0.130029   \n",
       "20819     0.122995    0.307489               0.584228   0.030749    0.122995   \n",
       "20820     0.122828    0.409426               0.368484   0.204713    0.081885   \n",
       "20821     0.166729    0.400149               0.466840   0.100037    0.100037   \n",
       "20822     0.100223    0.334078               0.267263   0.133631    0.033408   \n",
       "\n",
       "       away-losses  away-goals  away-opposition-goals  \n",
       "0         0.220401    0.293868               0.514268  \n",
       "1         0.103862    0.484690               0.415448  \n",
       "2         0.078079    0.585594               0.507514  \n",
       "3         0.144060    0.360151               0.396166  \n",
       "4         0.154424    0.360322               0.514746  \n",
       "...            ...         ...                    ...  \n",
       "20818     0.130029    0.325071               0.682650  \n",
       "20819     0.153744    0.215242               0.645726  \n",
       "20820     0.122828    0.614139               0.368484  \n",
       "20821     0.133383    0.366803               0.533532  \n",
       "20822     0.167039    0.467709               0.668156  \n",
       "\n",
       "[20823 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.039230</td>\n",
       "      <td>0.057061</td>\n",
       "      <td>0.488587</td>\n",
       "      <td>0.238944</td>\n",
       "      <td>0.417260</td>\n",
       "      <td>0.189015</td>\n",
       "      <td>0.028531</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053495</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.574178</td>\n",
       "      <td>0.278173</td>\n",
       "      <td>0.256775</td>\n",
       "      <td>0.106990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.010640</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.029555</td>\n",
       "      <td>0.059110</td>\n",
       "      <td>0.495044</td>\n",
       "      <td>0.236439</td>\n",
       "      <td>0.557848</td>\n",
       "      <td>0.284465</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.014777</td>\n",
       "      <td>0.040638</td>\n",
       "      <td>0.066498</td>\n",
       "      <td>0.384213</td>\n",
       "      <td>0.162552</td>\n",
       "      <td>0.321409</td>\n",
       "      <td>0.132997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.012795</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.451585</td>\n",
       "      <td>0.218266</td>\n",
       "      <td>0.466638</td>\n",
       "      <td>0.210740</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.022579</td>\n",
       "      <td>0.041395</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.504270</td>\n",
       "      <td>0.222029</td>\n",
       "      <td>0.376321</td>\n",
       "      <td>0.173108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.015829</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.069647</td>\n",
       "      <td>0.037989</td>\n",
       "      <td>0.560339</td>\n",
       "      <td>0.259592</td>\n",
       "      <td>0.234266</td>\n",
       "      <td>0.117133</td>\n",
       "      <td>0.018995</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.060149</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>0.535013</td>\n",
       "      <td>0.300747</td>\n",
       "      <td>0.357730</td>\n",
       "      <td>0.183614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.064551</td>\n",
       "      <td>0.023782</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.050961</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.546982</td>\n",
       "      <td>0.244613</td>\n",
       "      <td>0.251408</td>\n",
       "      <td>0.105320</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.057756</td>\n",
       "      <td>0.485829</td>\n",
       "      <td>0.234421</td>\n",
       "      <td>0.455252</td>\n",
       "      <td>0.234421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7028</td>\n",
       "      <td>2</td>\n",
       "      <td>0.020289</td>\n",
       "      <td>0.015420</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.048694</td>\n",
       "      <td>0.324626</td>\n",
       "      <td>0.174487</td>\n",
       "      <td>0.474766</td>\n",
       "      <td>0.243470</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.085214</td>\n",
       "      <td>0.482881</td>\n",
       "      <td>0.235354</td>\n",
       "      <td>0.454477</td>\n",
       "      <td>0.263759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7029</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>0.018427</td>\n",
       "      <td>0.014941</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.024901</td>\n",
       "      <td>0.044822</td>\n",
       "      <td>0.104584</td>\n",
       "      <td>0.443238</td>\n",
       "      <td>0.234070</td>\n",
       "      <td>0.458179</td>\n",
       "      <td>0.229089</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.019921</td>\n",
       "      <td>0.024901</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.104584</td>\n",
       "      <td>0.517941</td>\n",
       "      <td>0.273911</td>\n",
       "      <td>0.313753</td>\n",
       "      <td>0.129485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7030</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007617</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>0.019044</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.016928</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.516293</td>\n",
       "      <td>0.249683</td>\n",
       "      <td>0.389336</td>\n",
       "      <td>0.211596</td>\n",
       "      <td>0.021160</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.063479</td>\n",
       "      <td>0.038087</td>\n",
       "      <td>0.355481</td>\n",
       "      <td>0.181972</td>\n",
       "      <td>0.499366</td>\n",
       "      <td>0.236987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7031</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.035667</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>0.055483</td>\n",
       "      <td>0.491416</td>\n",
       "      <td>0.245708</td>\n",
       "      <td>0.392341</td>\n",
       "      <td>0.198152</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.043593</td>\n",
       "      <td>0.067372</td>\n",
       "      <td>0.408193</td>\n",
       "      <td>0.210041</td>\n",
       "      <td>0.483490</td>\n",
       "      <td>0.214004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7032</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.023501</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.039168</td>\n",
       "      <td>0.031334</td>\n",
       "      <td>0.411259</td>\n",
       "      <td>0.254589</td>\n",
       "      <td>0.493511</td>\n",
       "      <td>0.211505</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>0.074418</td>\n",
       "      <td>0.446510</td>\n",
       "      <td>0.246755</td>\n",
       "      <td>0.415176</td>\n",
       "      <td>0.180171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.012482   0.011769   0.007489   0.003566    0.010699   \n",
       "1          1   0.009236   0.012191   0.010640   0.011083    0.003694   \n",
       "2          0   0.007188   0.012795   0.015805   0.015053    0.007526   \n",
       "3          2   0.010289   0.010289   0.007281   0.015829    0.006332   \n",
       "4          2   0.004077   0.020384   0.064551   0.023782    0.006795   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "7028       2   0.020289   0.015420   0.006898   0.016231    0.008116   \n",
       "7029       2   0.009960   0.017929   0.018427   0.014941    0.009960   \n",
       "7030       2   0.007617   0.015870   0.019044   0.012696    0.012696   \n",
       "7031       2   0.005271   0.020806   0.035667   0.007926    0.011889   \n",
       "7032       2   0.006541   0.016450   0.020563   0.023501    0.003917   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.021398    0.039230               0.057061    0.488587   \n",
       "1        0.022166    0.029555               0.059110    0.495044   \n",
       "2        0.015053    0.037632               0.056448    0.451585   \n",
       "3        0.009497    0.069647               0.037989    0.560339   \n",
       "4        0.003397    0.050961               0.027179    0.546982   \n",
       "...           ...         ...                    ...         ...   \n",
       "7028     0.016231    0.040578               0.048694    0.324626   \n",
       "7029     0.024901    0.044822               0.104584    0.443238   \n",
       "7030     0.016928    0.033855               0.033855    0.516293   \n",
       "7031     0.019815    0.047556               0.055483    0.491416   \n",
       "7032     0.011750    0.039168               0.031334    0.411259   \n",
       "\n",
       "      home-shots_on_target  home-opposition_shots  \\\n",
       "0                 0.238944               0.417260   \n",
       "1                 0.236439               0.557848   \n",
       "2                 0.218266               0.466638   \n",
       "3                 0.259592               0.234266   \n",
       "4                 0.244613               0.251408   \n",
       "...                    ...                    ...   \n",
       "7028              0.174487               0.474766   \n",
       "7029              0.234070               0.458179   \n",
       "7030              0.249683               0.389336   \n",
       "7031              0.245708               0.392341   \n",
       "7032              0.254589               0.493511   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "0                            0.189015   0.028531    0.007133     0.000000   \n",
       "1                            0.284465   0.011083    0.011083     0.014777   \n",
       "2                            0.210740   0.007526    0.007526     0.022579   \n",
       "3                            0.117133   0.018995    0.009497     0.003166   \n",
       "4                            0.105320   0.010192    0.006795     0.016987   \n",
       "...                               ...        ...         ...          ...   \n",
       "7028                         0.243470   0.008116    0.016231     0.016231   \n",
       "7029                         0.229089   0.004980    0.019921     0.024901   \n",
       "7030                         0.211596   0.021160    0.008464     0.012696   \n",
       "7031                         0.198152   0.011889    0.011889     0.015852   \n",
       "7032                         0.211505   0.011750    0.007834     0.019584   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "0       0.053495               0.021398    0.574178              0.278173   \n",
       "1       0.040638               0.066498    0.384213              0.162552   \n",
       "2       0.041395               0.056448    0.504270              0.222029   \n",
       "3       0.060149               0.025326    0.535013              0.300747   \n",
       "4       0.033974               0.057756    0.485829              0.234421   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028    0.040578               0.085214    0.482881              0.235354   \n",
       "7029    0.034861               0.104584    0.517941              0.273911   \n",
       "7030    0.063479               0.038087    0.355481              0.181972   \n",
       "7031    0.043593               0.067372    0.408193              0.210041   \n",
       "7032    0.050918               0.074418    0.446510              0.246755   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \n",
       "0                  0.256775                         0.106990  \n",
       "1                  0.321409                         0.132997  \n",
       "2                  0.376321                         0.173108  \n",
       "3                  0.357730                         0.183614  \n",
       "4                  0.455252                         0.234421  \n",
       "...                     ...                              ...  \n",
       "7028               0.454477                         0.263759  \n",
       "7029               0.313753                         0.129485  \n",
       "7030               0.499366                         0.236987  \n",
       "7031               0.483490                         0.214004  \n",
       "7032               0.415176                         0.180171  \n",
       "\n",
       "[7033 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "      <th>home_shot_accuracy</th>\n",
       "      <th>home_shot_efficiency</th>\n",
       "      <th>home_opposition_shot_accuracy</th>\n",
       "      <th>home_opposition_shot_efficiency</th>\n",
       "      <th>away_shot_accuracy</th>\n",
       "      <th>away_shot_efficiency</th>\n",
       "      <th>away_opposition_shot_accuracy</th>\n",
       "      <th>away_opposition_shot_efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.039229</td>\n",
       "      <td>0.057061</td>\n",
       "      <td>0.488583</td>\n",
       "      <td>0.238942</td>\n",
       "      <td>0.417257</td>\n",
       "      <td>0.189014</td>\n",
       "      <td>0.028530</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053495</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.574174</td>\n",
       "      <td>0.278171</td>\n",
       "      <td>0.256774</td>\n",
       "      <td>0.106989</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.010640</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.029555</td>\n",
       "      <td>0.059109</td>\n",
       "      <td>0.495039</td>\n",
       "      <td>0.236437</td>\n",
       "      <td>0.557843</td>\n",
       "      <td>0.284463</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.014777</td>\n",
       "      <td>0.040638</td>\n",
       "      <td>0.066498</td>\n",
       "      <td>0.384210</td>\n",
       "      <td>0.162550</td>\n",
       "      <td>0.321406</td>\n",
       "      <td>0.132996</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.001847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.012795</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.451581</td>\n",
       "      <td>0.218264</td>\n",
       "      <td>0.466634</td>\n",
       "      <td>0.210738</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.022579</td>\n",
       "      <td>0.041395</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.504266</td>\n",
       "      <td>0.222028</td>\n",
       "      <td>0.376318</td>\n",
       "      <td>0.173106</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>0.001227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.015829</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.069646</td>\n",
       "      <td>0.037989</td>\n",
       "      <td>0.560335</td>\n",
       "      <td>0.259590</td>\n",
       "      <td>0.234264</td>\n",
       "      <td>0.117132</td>\n",
       "      <td>0.018994</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.060149</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>0.535009</td>\n",
       "      <td>0.300745</td>\n",
       "      <td>0.357728</td>\n",
       "      <td>0.183613</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.000437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.064550</td>\n",
       "      <td>0.023782</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.050961</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.546979</td>\n",
       "      <td>0.244612</td>\n",
       "      <td>0.251406</td>\n",
       "      <td>0.105319</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.057756</td>\n",
       "      <td>0.485826</td>\n",
       "      <td>0.234419</td>\n",
       "      <td>0.455249</td>\n",
       "      <td>0.234419</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.000837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7028</td>\n",
       "      <td>2</td>\n",
       "      <td>0.020289</td>\n",
       "      <td>0.015420</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.048693</td>\n",
       "      <td>0.324623</td>\n",
       "      <td>0.174485</td>\n",
       "      <td>0.474761</td>\n",
       "      <td>0.243467</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.085213</td>\n",
       "      <td>0.482876</td>\n",
       "      <td>0.235351</td>\n",
       "      <td>0.454472</td>\n",
       "      <td>0.263756</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.001311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7029</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.017928</td>\n",
       "      <td>0.018426</td>\n",
       "      <td>0.014940</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.044821</td>\n",
       "      <td>0.104582</td>\n",
       "      <td>0.443228</td>\n",
       "      <td>0.234064</td>\n",
       "      <td>0.458168</td>\n",
       "      <td>0.229084</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.019920</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.104582</td>\n",
       "      <td>0.517929</td>\n",
       "      <td>0.273905</td>\n",
       "      <td>0.313745</td>\n",
       "      <td>0.129482</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.004022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7030</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007617</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.516288</td>\n",
       "      <td>0.249680</td>\n",
       "      <td>0.389332</td>\n",
       "      <td>0.211593</td>\n",
       "      <td>0.021159</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.063478</td>\n",
       "      <td>0.038087</td>\n",
       "      <td>0.355477</td>\n",
       "      <td>0.181970</td>\n",
       "      <td>0.499360</td>\n",
       "      <td>0.236985</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.000680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7031</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.035667</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>0.055482</td>\n",
       "      <td>0.491412</td>\n",
       "      <td>0.245706</td>\n",
       "      <td>0.392337</td>\n",
       "      <td>0.198150</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.043593</td>\n",
       "      <td>0.067371</td>\n",
       "      <td>0.408189</td>\n",
       "      <td>0.210039</td>\n",
       "      <td>0.483486</td>\n",
       "      <td>0.214002</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7032</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.039167</td>\n",
       "      <td>0.031334</td>\n",
       "      <td>0.411255</td>\n",
       "      <td>0.254586</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>0.211503</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.050917</td>\n",
       "      <td>0.074418</td>\n",
       "      <td>0.446505</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>0.415172</td>\n",
       "      <td>0.180169</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.001618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.012482   0.011769   0.007489   0.003566    0.010699   \n",
       "1          1   0.009236   0.012191   0.010640   0.011083    0.003694   \n",
       "2          0   0.007188   0.012795   0.015805   0.015053    0.007526   \n",
       "3          2   0.010289   0.010289   0.007281   0.015829    0.006331   \n",
       "4          2   0.004077   0.020384   0.064550   0.023782    0.006795   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "7028       2   0.020289   0.015420   0.006898   0.016231    0.008116   \n",
       "7029       2   0.009960   0.017928   0.018426   0.014940    0.009960   \n",
       "7030       2   0.007617   0.015870   0.019043   0.012696    0.012696   \n",
       "7031       2   0.005271   0.020806   0.035667   0.007926    0.011889   \n",
       "7032       2   0.006541   0.016450   0.020563   0.023500    0.003917   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.021398    0.039229               0.057061    0.488583   \n",
       "1        0.022166    0.029555               0.059109    0.495039   \n",
       "2        0.015053    0.037632               0.056448    0.451581   \n",
       "3        0.009497    0.069646               0.037989    0.560335   \n",
       "4        0.003397    0.050961               0.027179    0.546979   \n",
       "...           ...         ...                    ...         ...   \n",
       "7028     0.016231    0.040578               0.048693    0.324623   \n",
       "7029     0.024900    0.044821               0.104582    0.443228   \n",
       "7030     0.016927    0.033855               0.033855    0.516288   \n",
       "7031     0.019815    0.047556               0.055482    0.491412   \n",
       "7032     0.011750    0.039167               0.031334    0.411255   \n",
       "\n",
       "      home-shots_on_target  home-opposition_shots  \\\n",
       "0                 0.238942               0.417257   \n",
       "1                 0.236437               0.557843   \n",
       "2                 0.218264               0.466634   \n",
       "3                 0.259590               0.234264   \n",
       "4                 0.244612               0.251406   \n",
       "...                    ...                    ...   \n",
       "7028              0.174485               0.474761   \n",
       "7029              0.234064               0.458168   \n",
       "7030              0.249680               0.389332   \n",
       "7031              0.245706               0.392337   \n",
       "7032              0.254586               0.493506   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "0                            0.189014   0.028530    0.007133     0.000000   \n",
       "1                            0.284463   0.011083    0.011083     0.014777   \n",
       "2                            0.210738   0.007526    0.007526     0.022579   \n",
       "3                            0.117132   0.018994    0.009497     0.003166   \n",
       "4                            0.105319   0.010192    0.006795     0.016987   \n",
       "...                               ...        ...         ...          ...   \n",
       "7028                         0.243467   0.008116    0.016231     0.016231   \n",
       "7029                         0.229084   0.004980    0.019920     0.024900   \n",
       "7030                         0.211593   0.021159    0.008464     0.012696   \n",
       "7031                         0.198150   0.011889    0.011889     0.015852   \n",
       "7032                         0.211503   0.011750    0.007833     0.019584   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "0       0.053495               0.021398    0.574174              0.278171   \n",
       "1       0.040638               0.066498    0.384210              0.162550   \n",
       "2       0.041395               0.056448    0.504266              0.222028   \n",
       "3       0.060149               0.025326    0.535009              0.300745   \n",
       "4       0.033974               0.057756    0.485826              0.234419   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028    0.040578               0.085213    0.482876              0.235351   \n",
       "7029    0.034861               0.104582    0.517929              0.273905   \n",
       "7030    0.063478               0.038087    0.355477              0.181970   \n",
       "7031    0.043593               0.067371    0.408189              0.210039   \n",
       "7032    0.050917               0.074418    0.446505              0.246753   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \\\n",
       "0                  0.256774                         0.106989   \n",
       "1                  0.321406                         0.132996   \n",
       "2                  0.376318                         0.173106   \n",
       "3                  0.357728                         0.183613   \n",
       "4                  0.455249                         0.234419   \n",
       "...                     ...                              ...   \n",
       "7028               0.454472                         0.263756   \n",
       "7029               0.313745                         0.129482   \n",
       "7030               0.499360                         0.236985   \n",
       "7031               0.483486                         0.214002   \n",
       "7032               0.415172                         0.180169   \n",
       "\n",
       "      home_shot_accuracy  home_shot_efficiency  home_opposition_shot_accuracy  \\\n",
       "0               0.001744              0.000586                       0.001616   \n",
       "1               0.001764              0.000462                       0.001884   \n",
       "2               0.001819              0.000649                       0.001699   \n",
       "3               0.001467              0.000849                       0.001583   \n",
       "4               0.001519              0.000708                       0.001423   \n",
       "...                  ...                   ...                            ...   \n",
       "7028            0.002181              0.000944                       0.002081   \n",
       "7029            0.002630              0.000954                       0.002490   \n",
       "7030            0.002047              0.000574                       0.002300   \n",
       "7031            0.001981              0.000767                       0.002002   \n",
       "7032            0.002425              0.000603                       0.001679   \n",
       "\n",
       "      home_opposition_shot_efficiency  away_shot_accuracy  \\\n",
       "0                            0.001077            0.001728   \n",
       "1                            0.000768            0.001563   \n",
       "2                            0.001008            0.001657   \n",
       "3                            0.001027            0.001780   \n",
       "4                            0.000877            0.001639   \n",
       "...                               ...                 ...   \n",
       "7028                         0.000812            0.001978   \n",
       "7029                         0.002274            0.002634   \n",
       "7030                         0.000677            0.002166   \n",
       "7031                         0.001110            0.002039   \n",
       "7032                         0.000580            0.002164   \n",
       "\n",
       "      away_shot_efficiency  away_opposition_shot_accuracy  \\\n",
       "0                 0.000686                       0.001486   \n",
       "1                 0.000924                       0.001529   \n",
       "2                 0.000702                       0.001731   \n",
       "3                 0.000633                       0.001625   \n",
       "4                 0.000492                       0.001749   \n",
       "...                    ...                            ...   \n",
       "7028              0.000700                       0.002355   \n",
       "7029              0.000634                       0.002055   \n",
       "7030              0.001476                       0.002008   \n",
       "7031              0.000823                       0.001754   \n",
       "7032              0.000808                       0.001700   \n",
       "\n",
       "      away_opposition_shot_efficiency  \n",
       "0                            0.000713  \n",
       "1                            0.001847  \n",
       "2                            0.001227  \n",
       "3                            0.000437  \n",
       "4                            0.000837  \n",
       "...                               ...  \n",
       "7028                         0.001311  \n",
       "7029                         0.004022  \n",
       "7030                         0.000680  \n",
       "7031                         0.001248  \n",
       "7032                         0.001618  \n",
       "\n",
       "[7033 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-possession</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>home-opposition_possession</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-possession</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "      <th>away-opposition_possession</th>\n",
       "      <th>home_shot_accuracy</th>\n",
       "      <th>home_shot_efficiency</th>\n",
       "      <th>home_opposition_shot_accuracy</th>\n",
       "      <th>home_opposition_shot_efficiency</th>\n",
       "      <th>away_shot_accuracy</th>\n",
       "      <th>away_shot_efficiency</th>\n",
       "      <th>away_opposition_shot_accuracy</th>\n",
       "      <th>away_opposition_shot_efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.039229</td>\n",
       "      <td>0.057060</td>\n",
       "      <td>0.488580</td>\n",
       "      <td>0.238941</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.417255</td>\n",
       "      <td>0.189013</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.028530</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053494</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.574171</td>\n",
       "      <td>0.278170</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.256772</td>\n",
       "      <td>0.106988</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010056</td>\n",
       "      <td>0.010056</td>\n",
       "      <td>0.007116</td>\n",
       "      <td>0.015470</td>\n",
       "      <td>0.006188</td>\n",
       "      <td>0.009282</td>\n",
       "      <td>0.058786</td>\n",
       "      <td>0.037128</td>\n",
       "      <td>0.584770</td>\n",
       "      <td>0.275368</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>0.213488</td>\n",
       "      <td>0.111385</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.018564</td>\n",
       "      <td>0.009282</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>0.058786</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.522890</td>\n",
       "      <td>0.293932</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.349625</td>\n",
       "      <td>0.179453</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.000427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.020657</td>\n",
       "      <td>0.065414</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>0.006886</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>0.051643</td>\n",
       "      <td>0.027543</td>\n",
       "      <td>0.554301</td>\n",
       "      <td>0.247886</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.254772</td>\n",
       "      <td>0.106729</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.006886</td>\n",
       "      <td>0.006886</td>\n",
       "      <td>0.020657</td>\n",
       "      <td>0.030986</td>\n",
       "      <td>0.061972</td>\n",
       "      <td>0.454458</td>\n",
       "      <td>0.213458</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.478558</td>\n",
       "      <td>0.244443</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.000873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008720</td>\n",
       "      <td>0.012090</td>\n",
       "      <td>0.010991</td>\n",
       "      <td>0.010991</td>\n",
       "      <td>0.010991</td>\n",
       "      <td>0.014655</td>\n",
       "      <td>0.032974</td>\n",
       "      <td>0.040301</td>\n",
       "      <td>0.373702</td>\n",
       "      <td>0.172196</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.487279</td>\n",
       "      <td>0.282109</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.010991</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.018319</td>\n",
       "      <td>0.032974</td>\n",
       "      <td>0.058620</td>\n",
       "      <td>0.424995</td>\n",
       "      <td>0.197842</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.479951</td>\n",
       "      <td>0.234480</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.000916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008796</td>\n",
       "      <td>0.010995</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>0.013532</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.016916</td>\n",
       "      <td>0.050747</td>\n",
       "      <td>0.054130</td>\n",
       "      <td>0.422888</td>\n",
       "      <td>0.213136</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.517615</td>\n",
       "      <td>0.246967</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.013532</td>\n",
       "      <td>0.010149</td>\n",
       "      <td>0.010149</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.054130</td>\n",
       "      <td>0.348460</td>\n",
       "      <td>0.172538</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.466868</td>\n",
       "      <td>0.257116</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.000712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6991</td>\n",
       "      <td>2</td>\n",
       "      <td>0.020289</td>\n",
       "      <td>0.015419</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.008115</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040577</td>\n",
       "      <td>0.048693</td>\n",
       "      <td>0.324620</td>\n",
       "      <td>0.174483</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.474757</td>\n",
       "      <td>0.243465</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.008115</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040577</td>\n",
       "      <td>0.085213</td>\n",
       "      <td>0.482872</td>\n",
       "      <td>0.235349</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.454468</td>\n",
       "      <td>0.263754</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.001311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6992</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.017928</td>\n",
       "      <td>0.018426</td>\n",
       "      <td>0.014940</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.044820</td>\n",
       "      <td>0.104580</td>\n",
       "      <td>0.443222</td>\n",
       "      <td>0.234061</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>0.458162</td>\n",
       "      <td>0.229081</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.019920</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.034860</td>\n",
       "      <td>0.104580</td>\n",
       "      <td>0.517922</td>\n",
       "      <td>0.273901</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.313741</td>\n",
       "      <td>0.129481</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.004022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6993</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007617</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.516283</td>\n",
       "      <td>0.249678</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.389328</td>\n",
       "      <td>0.211591</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.021159</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.063477</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>0.355474</td>\n",
       "      <td>0.181969</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.499356</td>\n",
       "      <td>0.236982</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.000680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6994</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.035667</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>0.055482</td>\n",
       "      <td>0.491408</td>\n",
       "      <td>0.245704</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.392334</td>\n",
       "      <td>0.198148</td>\n",
       "      <td>0.001651</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.043593</td>\n",
       "      <td>0.067370</td>\n",
       "      <td>0.408186</td>\n",
       "      <td>0.210037</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.483482</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6995</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.039167</td>\n",
       "      <td>0.031333</td>\n",
       "      <td>0.411252</td>\n",
       "      <td>0.254584</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>0.493502</td>\n",
       "      <td>0.211501</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>0.019583</td>\n",
       "      <td>0.050917</td>\n",
       "      <td>0.074417</td>\n",
       "      <td>0.446502</td>\n",
       "      <td>0.246751</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.415168</td>\n",
       "      <td>0.180167</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.001618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6996 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.012482   0.011769   0.007489   0.003566    0.010699   \n",
       "1          2   0.010056   0.010056   0.007116   0.015470    0.006188   \n",
       "2          2   0.004131   0.020657   0.065414   0.024100    0.006886   \n",
       "3          0   0.008720   0.012090   0.010991   0.010991    0.010991   \n",
       "4          0   0.008796   0.010995   0.009473   0.013532    0.003383   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "6991       2   0.020289   0.015419   0.006898   0.016231    0.008115   \n",
       "6992       2   0.009960   0.017928   0.018426   0.014940    0.009960   \n",
       "6993       2   0.007617   0.015869   0.019043   0.012695    0.012695   \n",
       "6994       2   0.005271   0.020806   0.035667   0.007926    0.011889   \n",
       "6995       2   0.006541   0.016450   0.020563   0.023500    0.003917   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.021398    0.039229               0.057060    0.488580   \n",
       "1        0.009282    0.058786               0.037128    0.584770   \n",
       "2        0.003443    0.051643               0.027543    0.554301   \n",
       "3        0.014655    0.032974               0.040301    0.373702   \n",
       "4        0.016916    0.050747               0.054130    0.422888   \n",
       "...           ...         ...                    ...         ...   \n",
       "6991     0.016231    0.040577               0.048693    0.324620   \n",
       "6992     0.024900    0.044820               0.104580    0.443222   \n",
       "6993     0.016927    0.033855               0.033855    0.516283   \n",
       "6994     0.019815    0.047556               0.055482    0.491408   \n",
       "6995     0.011750    0.039167               0.031333    0.411252   \n",
       "\n",
       "      home-shots_on_target  home-possession  home-opposition_shots  \\\n",
       "0                 0.238941         0.001887               0.417255   \n",
       "1                 0.275368         0.001837               0.213488   \n",
       "2                 0.247886         0.001803               0.254772   \n",
       "3                 0.172196         0.001766               0.487279   \n",
       "4                 0.213136         0.001622               0.517615   \n",
       "...                    ...              ...                    ...   \n",
       "6991              0.174483         0.001846               0.474757   \n",
       "6992              0.234061         0.002136               0.458162   \n",
       "6993              0.249678         0.002087               0.389328   \n",
       "6994              0.245704         0.002312               0.392334   \n",
       "6995              0.254584         0.002339               0.493502   \n",
       "\n",
       "      home-opposition_shots_on_target  home-opposition_possession  away-wins  \\\n",
       "0                            0.189013                    0.001680   0.028530   \n",
       "1                            0.111385                    0.001257   0.018564   \n",
       "2                            0.106729                    0.001640   0.006886   \n",
       "3                            0.282109                    0.001897   0.010991   \n",
       "4                            0.246967                    0.001761   0.013532   \n",
       "...                               ...                         ...        ...   \n",
       "6991                         0.243465                    0.002212   0.008115   \n",
       "6992                         0.229081                    0.002844   0.004980   \n",
       "6993                         0.211591                    0.002144   0.021159   \n",
       "6994                         0.198148                    0.001651   0.011889   \n",
       "6995                         0.211501                    0.001577   0.011750   \n",
       "\n",
       "      away-draws  away-losses  away-goals  away-opposition-goals  away-shots  \\\n",
       "0       0.007133     0.000000    0.053494               0.021398    0.574171   \n",
       "1       0.009282     0.003094    0.058786               0.024752    0.522890   \n",
       "2       0.006886     0.020657    0.030986               0.061972    0.454458   \n",
       "3       0.007327     0.018319    0.032974               0.058620    0.424995   \n",
       "4       0.010149     0.010149    0.043980               0.054130    0.348460   \n",
       "...          ...          ...         ...                    ...         ...   \n",
       "6991    0.016231     0.016231    0.040577               0.085213    0.482872   \n",
       "6992    0.019920     0.024900    0.034860               0.104580    0.517922   \n",
       "6993    0.008464     0.012695    0.063477               0.038086    0.355474   \n",
       "6994    0.011889     0.015852    0.043593               0.067370    0.408186   \n",
       "6995    0.007833     0.019583    0.050917               0.074417    0.446502   \n",
       "\n",
       "      away-shots_on_target  away-possession  away-opposition_shots  \\\n",
       "0                 0.278170         0.001886               0.256772   \n",
       "1                 0.293932         0.001865               0.349625   \n",
       "2                 0.213458         0.001607               0.478558   \n",
       "3                 0.197842         0.001646               0.479951   \n",
       "4                 0.172538         0.001621               0.466868   \n",
       "...                    ...              ...                    ...   \n",
       "6991              0.235349         0.001733               0.454468   \n",
       "6992              0.273901         0.002297               0.313741   \n",
       "6993              0.181969         0.002306               0.499356   \n",
       "6994              0.210037         0.001906               0.483482   \n",
       "6995              0.246751         0.002007               0.415168   \n",
       "\n",
       "      away-opposition_shots_on_target  away-opposition_possession  \\\n",
       "0                            0.106988                    0.001680   \n",
       "1                            0.179453                    0.001229   \n",
       "2                            0.244443                    0.001836   \n",
       "3                            0.234480                    0.002018   \n",
       "4                            0.257116                    0.001762   \n",
       "...                               ...                         ...   \n",
       "6991                         0.263754                    0.002325   \n",
       "6992                         0.129481                    0.002683   \n",
       "6993                         0.236982                    0.001925   \n",
       "6994                         0.214000                    0.002057   \n",
       "6995                         0.180167                    0.001909   \n",
       "\n",
       "      home_shot_accuracy  home_shot_efficiency  home_opposition_shot_accuracy  \\\n",
       "0               0.001744              0.000586                       0.001615   \n",
       "1               0.001457              0.000661                       0.001614   \n",
       "2               0.001540              0.000717                       0.001442   \n",
       "3               0.001688              0.000702                       0.002121   \n",
       "4               0.001705              0.000806                       0.001614   \n",
       "...                  ...                   ...                            ...   \n",
       "6991            0.002181              0.000944                       0.002081   \n",
       "6992            0.002630              0.000954                       0.002490   \n",
       "6993            0.002047              0.000574                       0.002300   \n",
       "6994            0.001981              0.000767                       0.002001   \n",
       "6995            0.002425              0.000603                       0.001679   \n",
       "\n",
       "      home_opposition_shot_efficiency  away_shot_accuracy  \\\n",
       "0                            0.001077            0.001728   \n",
       "1                            0.001031            0.001739   \n",
       "2                            0.000888            0.001617   \n",
       "3                            0.000523            0.001706   \n",
       "4                            0.000742            0.001675   \n",
       "...                               ...                 ...   \n",
       "6991                         0.000812            0.001978   \n",
       "6992                         0.002273            0.002634   \n",
       "6993                         0.000677            0.002166   \n",
       "6994                         0.001110            0.002039   \n",
       "6995                         0.000580            0.002164   \n",
       "\n",
       "      away_shot_efficiency  away_opposition_shot_accuracy  \\\n",
       "0                 0.000686                       0.001486   \n",
       "1                 0.000619                       0.001588   \n",
       "2                 0.000500                       0.001759   \n",
       "3                 0.000611                       0.001790   \n",
       "4                 0.000862                       0.001863   \n",
       "...                    ...                            ...   \n",
       "6991              0.000700                       0.002355   \n",
       "6992              0.000634                       0.002055   \n",
       "6993              0.001476                       0.002008   \n",
       "6994              0.000823                       0.001754   \n",
       "6995              0.000808                       0.001700   \n",
       "\n",
       "      away_opposition_shot_efficiency  \n",
       "0                            0.000713  \n",
       "1                            0.000427  \n",
       "2                            0.000873  \n",
       "3                            0.000916  \n",
       "4                            0.000712  \n",
       "...                               ...  \n",
       "6991                         0.001311  \n",
       "6992                         0.004022  \n",
       "6993                         0.000680  \n",
       "6994                         0.001248  \n",
       "6995                         0.001618  \n",
       "\n",
       "[6996 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "21\n",
      "29\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "#number of columns for training data\n",
    "print(train_X01.shape[1])\n",
    "print(train_X02.shape[1])\n",
    "print(train_X03.shape[1])\n",
    "print(train_X04.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model01 = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "#model01.compile(loss = 'sparse_categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )\n",
    "#model01.compile(loss = 'sparse_categorical_crossentropy' , optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False) , metrics = ['accuracy'] )\n",
    "#model01.compile(loss = 'sparse_categorical_crossentropy' , optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False) , metrics = ['accuracy'] )\n",
    "model01.compile(loss = 'sparse_categorical_crossentropy' , optimizer = keras.optimizers.Adagrad(learning_rate=0.01) , metrics = ['accuracy'] )\n",
    "\n",
    "model02 = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(32, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "#model02.compile(loss = 'sparse_categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )\n",
    "#model02.compile(loss = 'sparse_categorical_crossentropy' , optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False) , metrics = ['accuracy'] )\n",
    "#model02.compile(loss = 'sparse_categorical_crossentropy' , optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False) , metrics = ['accuracy'] )\n",
    "model02.compile(loss = 'sparse_categorical_crossentropy' , optimizer = keras.optimizers.Adagrad(learning_rate=0.01) , metrics = ['accuracy'] )\n",
    "\n",
    "model03 = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(32, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "#model03.compile(loss = 'sparse_categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )\n",
    "#model03.compile(loss = 'sparse_categorical_crossentropy' , optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False) , metrics = ['accuracy'] )\n",
    "#model03.compile(loss = 'sparse_categorical_crossentropy' , optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False) , metrics = ['accuracy'] )\n",
    "model03.compile(loss = 'sparse_categorical_crossentropy' , optimizer = keras.optimizers.Adagrad(learning_rate=0.01) , metrics = ['accuracy'] )\n",
    "\n",
    "model04 = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X04.shape[1],)), # 33 features\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(32, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "#model03.compile(loss = 'sparse_categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )\n",
    "#model03.compile(loss = 'sparse_categorical_crossentropy' , optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False) , metrics = ['accuracy'] )\n",
    "#model03.compile(loss = 'sparse_categorical_crossentropy' , optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False) , metrics = ['accuracy'] )\n",
    "model04.compile(loss = 'sparse_categorical_crossentropy' , optimizer = keras.optimizers.Adagrad(learning_rate=0.01) , metrics = ['accuracy'] )\n",
    "\n",
    "\n",
    "early_stoping = EarlyStopping(patience=50)\n",
    "validation_split = 0.2\n",
    "epochs=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 569\n",
      "Trainable params: 569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model01.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14992 samples, validate on 3748 samples\n",
      "Epoch 1/500\n",
      "14992/14992 [==============================] - 4s 246us/sample - loss: 1.0439 - accuracy: 0.4747 - val_loss: 1.0256 - val_accuracy: 0.4995\n",
      "Epoch 2/500\n",
      "14992/14992 [==============================] - 2s 117us/sample - loss: 1.0125 - accuracy: 0.5078 - val_loss: 1.0074 - val_accuracy: 0.5035\n",
      "Epoch 3/500\n",
      "14992/14992 [==============================] - 2s 112us/sample - loss: 0.9999 - accuracy: 0.5135 - val_loss: 0.9998 - val_accuracy: 0.5029\n",
      "Epoch 4/500\n",
      "14992/14992 [==============================] - 1s 77us/sample - loss: 0.9938 - accuracy: 0.5154 - val_loss: 0.9958 - val_accuracy: 0.5061\n",
      "Epoch 5/500\n",
      "14992/14992 [==============================] - 1s 78us/sample - loss: 0.9902 - accuracy: 0.5175 - val_loss: 0.9926 - val_accuracy: 0.5051\n",
      "Epoch 6/500\n",
      "14992/14992 [==============================] - 1s 77us/sample - loss: 0.9877 - accuracy: 0.5190 - val_loss: 0.9898 - val_accuracy: 0.5117\n",
      "Epoch 7/500\n",
      "14992/14992 [==============================] - 1s 78us/sample - loss: 0.9853 - accuracy: 0.5237 - val_loss: 0.9878 - val_accuracy: 0.5112\n",
      "Epoch 8/500\n",
      "14992/14992 [==============================] - 1s 79us/sample - loss: 0.9833 - accuracy: 0.5253 - val_loss: 0.9858 - val_accuracy: 0.5131\n",
      "Epoch 9/500\n",
      "14992/14992 [==============================] - 1s 77us/sample - loss: 0.9813 - accuracy: 0.5265 - val_loss: 0.9863 - val_accuracy: 0.5187\n",
      "Epoch 10/500\n",
      "14992/14992 [==============================] - 1s 79us/sample - loss: 0.9799 - accuracy: 0.5275 - val_loss: 0.9851 - val_accuracy: 0.5200\n",
      "Epoch 11/500\n",
      "14992/14992 [==============================] - 1s 77us/sample - loss: 0.9785 - accuracy: 0.5287 - val_loss: 0.9829 - val_accuracy: 0.5195\n",
      "Epoch 12/500\n",
      "14992/14992 [==============================] - 1s 79us/sample - loss: 0.9775 - accuracy: 0.5275 - val_loss: 0.9815 - val_accuracy: 0.5179\n",
      "Epoch 13/500\n",
      "14992/14992 [==============================] - 1s 79us/sample - loss: 0.9764 - accuracy: 0.5281 - val_loss: 0.9835 - val_accuracy: 0.5216\n",
      "Epoch 14/500\n",
      "14992/14992 [==============================] - 1s 77us/sample - loss: 0.9758 - accuracy: 0.5295 - val_loss: 0.9807 - val_accuracy: 0.5216\n",
      "Epoch 15/500\n",
      "14992/14992 [==============================] - 1s 79us/sample - loss: 0.9752 - accuracy: 0.5305 - val_loss: 0.9796 - val_accuracy: 0.5192\n",
      "Epoch 16/500\n",
      "14992/14992 [==============================] - 1s 79us/sample - loss: 0.9747 - accuracy: 0.5314 - val_loss: 0.9794 - val_accuracy: 0.5229\n",
      "Epoch 17/500\n",
      "14992/14992 [==============================] - 1s 87us/sample - loss: 0.9741 - accuracy: 0.5312 - val_loss: 0.9789 - val_accuracy: 0.5195\n",
      "Epoch 18/500\n",
      "14992/14992 [==============================] - 2s 119us/sample - loss: 0.9737 - accuracy: 0.5305 - val_loss: 0.9788 - val_accuracy: 0.5237\n",
      "Epoch 19/500\n",
      "14992/14992 [==============================] - 2s 106us/sample - loss: 0.9734 - accuracy: 0.5320 - val_loss: 0.9789 - val_accuracy: 0.5219\n",
      "Epoch 20/500\n",
      "14992/14992 [==============================] - 1s 95us/sample - loss: 0.9733 - accuracy: 0.5309 - val_loss: 0.9784 - val_accuracy: 0.5221\n",
      "Epoch 21/500\n",
      "14992/14992 [==============================] - 2s 102us/sample - loss: 0.9730 - accuracy: 0.5307 - val_loss: 0.9782 - val_accuracy: 0.5229\n",
      "Epoch 22/500\n",
      "14992/14992 [==============================] - 2s 119us/sample - loss: 0.9726 - accuracy: 0.5309 - val_loss: 0.9790 - val_accuracy: 0.5224\n",
      "Epoch 23/500\n",
      "14992/14992 [==============================] - 1s 95us/sample - loss: 0.9725 - accuracy: 0.5312 - val_loss: 0.9778 - val_accuracy: 0.5203\n",
      "Epoch 24/500\n",
      "14992/14992 [==============================] - 2s 144us/sample - loss: 0.9722 - accuracy: 0.5323 - val_loss: 0.9777 - val_accuracy: 0.5203\n",
      "Epoch 25/500\n",
      "14992/14992 [==============================] - 1s 85us/sample - loss: 0.9723 - accuracy: 0.5314 - val_loss: 0.9781 - val_accuracy: 0.5245\n",
      "Epoch 26/500\n",
      "14992/14992 [==============================] - 1s 98us/sample - loss: 0.9719 - accuracy: 0.5309 - val_loss: 0.9785 - val_accuracy: 0.5235\n",
      "Epoch 27/500\n",
      "14992/14992 [==============================] - 1s 87us/sample - loss: 0.9720 - accuracy: 0.5316 - val_loss: 0.9792 - val_accuracy: 0.5216\n",
      "Epoch 28/500\n",
      "14992/14992 [==============================] - 1s 83us/sample - loss: 0.9719 - accuracy: 0.5317 - val_loss: 0.9778 - val_accuracy: 0.5248\n",
      "Epoch 29/500\n",
      "14992/14992 [==============================] - 1s 86us/sample - loss: 0.9717 - accuracy: 0.5314 - val_loss: 0.9774 - val_accuracy: 0.5181\n",
      "Epoch 30/500\n",
      "14992/14992 [==============================] - 2s 104us/sample - loss: 0.9715 - accuracy: 0.5307 - val_loss: 0.9771 - val_accuracy: 0.5227\n",
      "Epoch 31/500\n",
      "14992/14992 [==============================] - 1s 87us/sample - loss: 0.9716 - accuracy: 0.5312 - val_loss: 0.9772 - val_accuracy: 0.5240\n",
      "Epoch 32/500\n",
      "14992/14992 [==============================] - 1s 83us/sample - loss: 0.9713 - accuracy: 0.5301 - val_loss: 0.9779 - val_accuracy: 0.5232\n",
      "Epoch 33/500\n",
      "14992/14992 [==============================] - 1s 79us/sample - loss: 0.9714 - accuracy: 0.5317 - val_loss: 0.9786 - val_accuracy: 0.5232\n",
      "Epoch 34/500\n",
      "14992/14992 [==============================] - 1s 81us/sample - loss: 0.9713 - accuracy: 0.5326 - val_loss: 0.9770 - val_accuracy: 0.5232\n",
      "Epoch 35/500\n",
      "14992/14992 [==============================] - 1s 80us/sample - loss: 0.9713 - accuracy: 0.5326 - val_loss: 0.9772 - val_accuracy: 0.5181\n",
      "Epoch 36/500\n",
      "14992/14992 [==============================] - 1s 81us/sample - loss: 0.9713 - accuracy: 0.5318 - val_loss: 0.9779 - val_accuracy: 0.5240\n",
      "Epoch 37/500\n",
      "14992/14992 [==============================] - 1s 77us/sample - loss: 0.9713 - accuracy: 0.5311 - val_loss: 0.9769 - val_accuracy: 0.5232\n",
      "Epoch 38/500\n",
      "14992/14992 [==============================] - 1s 86us/sample - loss: 0.9712 - accuracy: 0.5311 - val_loss: 0.9769 - val_accuracy: 0.5237\n",
      "Epoch 39/500\n",
      "14992/14992 [==============================] - 1s 83us/sample - loss: 0.9711 - accuracy: 0.5317 - val_loss: 0.9774 - val_accuracy: 0.5248\n",
      "Epoch 40/500\n",
      "14992/14992 [==============================] - 1s 82us/sample - loss: 0.9712 - accuracy: 0.5322 - val_loss: 0.9771 - val_accuracy: 0.5261\n",
      "Epoch 41/500\n",
      "14992/14992 [==============================] - 1s 87us/sample - loss: 0.9711 - accuracy: 0.5319 - val_loss: 0.9773 - val_accuracy: 0.5253\n",
      "Epoch 42/500\n",
      "14992/14992 [==============================] - 1s 81us/sample - loss: 0.9710 - accuracy: 0.5326 - val_loss: 0.9768 - val_accuracy: 0.5235\n",
      "Epoch 43/500\n",
      "14992/14992 [==============================] - 1s 92us/sample - loss: 0.9711 - accuracy: 0.5309 - val_loss: 0.9768 - val_accuracy: 0.5245\n",
      "Epoch 44/500\n",
      "14992/14992 [==============================] - 1s 90us/sample - loss: 0.9710 - accuracy: 0.5326 - val_loss: 0.9769 - val_accuracy: 0.5251\n",
      "Epoch 45/500\n",
      "14992/14992 [==============================] - 1s 82us/sample - loss: 0.9710 - accuracy: 0.5320 - val_loss: 0.9771 - val_accuracy: 0.5253\n",
      "Epoch 46/500\n",
      "14992/14992 [==============================] - 1s 84us/sample - loss: 0.9709 - accuracy: 0.5316 - val_loss: 0.9767 - val_accuracy: 0.5240\n",
      "Epoch 47/500\n",
      "14992/14992 [==============================] - 1s 84us/sample - loss: 0.9708 - accuracy: 0.5323 - val_loss: 0.9768 - val_accuracy: 0.5248\n",
      "Epoch 48/500\n",
      "14992/14992 [==============================] - 1s 86us/sample - loss: 0.9709 - accuracy: 0.5311 - val_loss: 0.9767 - val_accuracy: 0.5232\n",
      "Epoch 49/500\n",
      "14992/14992 [==============================] - 1s 88us/sample - loss: 0.9709 - accuracy: 0.5310 - val_loss: 0.9768 - val_accuracy: 0.5232\n",
      "Epoch 50/500\n",
      "14992/14992 [==============================] - 1s 84us/sample - loss: 0.9708 - accuracy: 0.5325 - val_loss: 0.9770 - val_accuracy: 0.5259\n",
      "Epoch 51/500\n",
      "14992/14992 [==============================] - 1s 86us/sample - loss: 0.9709 - accuracy: 0.5320 - val_loss: 0.9770 - val_accuracy: 0.5261\n",
      "Epoch 52/500\n",
      "14992/14992 [==============================] - 1s 95us/sample - loss: 0.9709 - accuracy: 0.5326 - val_loss: 0.9767 - val_accuracy: 0.5229\n",
      "Epoch 53/500\n",
      "14992/14992 [==============================] - 1s 96us/sample - loss: 0.9709 - accuracy: 0.5316 - val_loss: 0.9772 - val_accuracy: 0.5253\n",
      "Epoch 54/500\n",
      "14992/14992 [==============================] - 2s 107us/sample - loss: 0.9708 - accuracy: 0.5321 - val_loss: 0.9768 - val_accuracy: 0.5248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "14992/14992 [==============================] - 1s 97us/sample - loss: 0.9708 - accuracy: 0.5324 - val_loss: 0.9767 - val_accuracy: 0.5221\n",
      "Epoch 56/500\n",
      "14992/14992 [==============================] - 1s 86us/sample - loss: 0.9707 - accuracy: 0.5301 - val_loss: 0.9769 - val_accuracy: 0.5251\n",
      "Epoch 57/500\n",
      "14992/14992 [==============================] - 1s 84us/sample - loss: 0.9706 - accuracy: 0.5314 - val_loss: 0.9768 - val_accuracy: 0.5235\n",
      "Epoch 58/500\n",
      "14992/14992 [==============================] - 1s 98us/sample - loss: 0.9707 - accuracy: 0.5309 - val_loss: 0.9767 - val_accuracy: 0.5224\n",
      "Epoch 59/500\n",
      "14992/14992 [==============================] - 1s 91us/sample - loss: 0.9706 - accuracy: 0.5304 - val_loss: 0.9779 - val_accuracy: 0.5235\n",
      "Epoch 60/500\n",
      "14992/14992 [==============================] - 1s 95us/sample - loss: 0.9708 - accuracy: 0.5309 - val_loss: 0.9767 - val_accuracy: 0.5251\n",
      "Epoch 61/500\n",
      "14992/14992 [==============================] - 2s 113us/sample - loss: 0.9707 - accuracy: 0.5330 - val_loss: 0.9768 - val_accuracy: 0.5248\n",
      "Epoch 62/500\n",
      "14992/14992 [==============================] - 1s 92us/sample - loss: 0.9707 - accuracy: 0.5319 - val_loss: 0.9767 - val_accuracy: 0.5253\n",
      "Epoch 63/500\n",
      "14992/14992 [==============================] - 1s 92us/sample - loss: 0.9706 - accuracy: 0.5307 - val_loss: 0.9768 - val_accuracy: 0.5261\n",
      "Epoch 64/500\n",
      "14992/14992 [==============================] - 1s 78us/sample - loss: 0.9706 - accuracy: 0.5326 - val_loss: 0.9768 - val_accuracy: 0.5253\n",
      "Epoch 65/500\n",
      "14992/14992 [==============================] - 1s 79us/sample - loss: 0.9707 - accuracy: 0.5322 - val_loss: 0.9769 - val_accuracy: 0.5264\n",
      "Epoch 66/500\n",
      "14992/14992 [==============================] - 1s 78us/sample - loss: 0.9707 - accuracy: 0.5307 - val_loss: 0.9767 - val_accuracy: 0.5245\n",
      "Epoch 67/500\n",
      "14992/14992 [==============================] - 1s 77us/sample - loss: 0.9707 - accuracy: 0.5318 - val_loss: 0.9767 - val_accuracy: 0.5251\n",
      "Epoch 68/500\n",
      "14992/14992 [==============================] - 1s 78us/sample - loss: 0.9706 - accuracy: 0.5317 - val_loss: 0.9767 - val_accuracy: 0.5245\n",
      "Epoch 69/500\n",
      "14992/14992 [==============================] - 1s 76us/sample - loss: 0.9706 - accuracy: 0.5318 - val_loss: 0.9767 - val_accuracy: 0.5245\n",
      "Epoch 70/500\n",
      "14992/14992 [==============================] - 1s 79us/sample - loss: 0.9705 - accuracy: 0.5296 - val_loss: 0.9768 - val_accuracy: 0.5245\n",
      "Epoch 71/500\n",
      "14992/14992 [==============================] - 1s 78us/sample - loss: 0.9705 - accuracy: 0.5321 - val_loss: 0.9767 - val_accuracy: 0.5251\n",
      "Epoch 72/500\n",
      "14992/14992 [==============================] - 1s 92us/sample - loss: 0.9705 - accuracy: 0.5320 - val_loss: 0.9771 - val_accuracy: 0.5253\n",
      "Epoch 73/500\n",
      "14992/14992 [==============================] - 2s 104us/sample - loss: 0.9706 - accuracy: 0.5301 - val_loss: 0.9769 - val_accuracy: 0.5267\n",
      "Epoch 74/500\n",
      "14992/14992 [==============================] - 1s 90us/sample - loss: 0.9705 - accuracy: 0.5322 - val_loss: 0.9766 - val_accuracy: 0.5224\n",
      "Epoch 75/500\n",
      "14992/14992 [==============================] - 1s 76us/sample - loss: 0.9706 - accuracy: 0.5312 - val_loss: 0.9767 - val_accuracy: 0.5251\n",
      "Epoch 76/500\n",
      "14992/14992 [==============================] - 1s 76us/sample - loss: 0.9705 - accuracy: 0.5321 - val_loss: 0.9768 - val_accuracy: 0.5245\n",
      "Epoch 77/500\n",
      "14992/14992 [==============================] - 1s 75us/sample - loss: 0.9705 - accuracy: 0.5318 - val_loss: 0.9767 - val_accuracy: 0.5251\n",
      "Epoch 78/500\n",
      "14992/14992 [==============================] - 1s 76us/sample - loss: 0.9705 - accuracy: 0.5325 - val_loss: 0.9770 - val_accuracy: 0.5261\n",
      "Epoch 79/500\n",
      "14992/14992 [==============================] - 1s 75us/sample - loss: 0.9705 - accuracy: 0.5311 - val_loss: 0.9769 - val_accuracy: 0.5267\n",
      "Epoch 80/500\n",
      "14992/14992 [==============================] - 1s 75us/sample - loss: 0.9705 - accuracy: 0.5313 - val_loss: 0.9768 - val_accuracy: 0.5245\n",
      "Epoch 81/500\n",
      "14992/14992 [==============================] - 1s 91us/sample - loss: 0.9705 - accuracy: 0.5317 - val_loss: 0.9767 - val_accuracy: 0.5245\n",
      "Epoch 82/500\n",
      "14992/14992 [==============================] - 2s 104us/sample - loss: 0.9704 - accuracy: 0.5314 - val_loss: 0.9767 - val_accuracy: 0.5229\n",
      "Epoch 83/500\n",
      "14992/14992 [==============================] - 2s 103us/sample - loss: 0.9704 - accuracy: 0.5322 - val_loss: 0.9771 - val_accuracy: 0.5256\n",
      "Epoch 84/500\n",
      "14992/14992 [==============================] - 1s 87us/sample - loss: 0.9705 - accuracy: 0.5312 - val_loss: 0.9773 - val_accuracy: 0.5256\n",
      "Epoch 85/500\n",
      "14992/14992 [==============================] - 1s 92us/sample - loss: 0.9705 - accuracy: 0.5319 - val_loss: 0.9768 - val_accuracy: 0.5259\n",
      "Epoch 86/500\n",
      "14992/14992 [==============================] - 1s 87us/sample - loss: 0.9705 - accuracy: 0.5314 - val_loss: 0.9771 - val_accuracy: 0.5256\n",
      "Epoch 87/500\n",
      "14992/14992 [==============================] - 1s 99us/sample - loss: 0.9704 - accuracy: 0.5315 - val_loss: 0.9769 - val_accuracy: 0.5264\n",
      "Epoch 88/500\n",
      "14992/14992 [==============================] - 2s 111us/sample - loss: 0.9705 - accuracy: 0.5321 - val_loss: 0.9770 - val_accuracy: 0.5261\n",
      "Epoch 89/500\n",
      "14992/14992 [==============================] - 1s 87us/sample - loss: 0.9704 - accuracy: 0.5311 - val_loss: 0.9770 - val_accuracy: 0.5264\n",
      "Epoch 90/500\n",
      "14992/14992 [==============================] - 1s 77us/sample - loss: 0.9704 - accuracy: 0.5319 - val_loss: 0.9766 - val_accuracy: 0.5229\n",
      "Epoch 91/500\n",
      "14992/14992 [==============================] - 1s 82us/sample - loss: 0.9705 - accuracy: 0.5326 - val_loss: 0.9769 - val_accuracy: 0.5264\n",
      "Epoch 92/500\n",
      "14992/14992 [==============================] - 1s 91us/sample - loss: 0.9703 - accuracy: 0.5308 - val_loss: 0.9769 - val_accuracy: 0.5264\n",
      "Epoch 93/500\n",
      "14992/14992 [==============================] - 1s 85us/sample - loss: 0.9704 - accuracy: 0.5316 - val_loss: 0.9767 - val_accuracy: 0.5227\n",
      "Epoch 94/500\n",
      "14992/14992 [==============================] - 1s 78us/sample - loss: 0.9704 - accuracy: 0.5314 - val_loss: 0.9767 - val_accuracy: 0.5245\n",
      "Epoch 95/500\n",
      "14992/14992 [==============================] - 1s 77us/sample - loss: 0.9704 - accuracy: 0.5314 - val_loss: 0.9770 - val_accuracy: 0.5259\n",
      "Epoch 96/500\n",
      "14992/14992 [==============================] - 1s 92us/sample - loss: 0.9704 - accuracy: 0.5313 - val_loss: 0.9768 - val_accuracy: 0.5259\n",
      "Epoch 97/500\n",
      "14992/14992 [==============================] - 1s 91us/sample - loss: 0.9704 - accuracy: 0.5305 - val_loss: 0.9773 - val_accuracy: 0.5251\n",
      "Epoch 98/500\n",
      "14992/14992 [==============================] - 1s 76us/sample - loss: 0.9703 - accuracy: 0.5308 - val_loss: 0.9766 - val_accuracy: 0.5232\n",
      "Epoch 99/500\n",
      "14992/14992 [==============================] - 1s 76us/sample - loss: 0.9703 - accuracy: 0.5318 - val_loss: 0.9770 - val_accuracy: 0.5259\n",
      "Epoch 100/500\n",
      "14992/14992 [==============================] - 1s 76us/sample - loss: 0.9704 - accuracy: 0.5316 - val_loss: 0.9767 - val_accuracy: 0.5245\n",
      "Epoch 101/500\n",
      "14992/14992 [==============================] - 1s 92us/sample - loss: 0.9704 - accuracy: 0.5314 - val_loss: 0.9767 - val_accuracy: 0.5243\n",
      "Epoch 102/500\n",
      "14992/14992 [==============================] - 1s 81us/sample - loss: 0.9704 - accuracy: 0.5318 - val_loss: 0.9768 - val_accuracy: 0.5256\n",
      "Epoch 103/500\n",
      "14992/14992 [==============================] - 2s 108us/sample - loss: 0.9703 - accuracy: 0.5318 - val_loss: 0.9767 - val_accuracy: 0.5229\n",
      "Epoch 104/500\n",
      "14992/14992 [==============================] - 2s 120us/sample - loss: 0.9704 - accuracy: 0.5330 - val_loss: 0.9768 - val_accuracy: 0.5251\n",
      "Epoch 105/500\n",
      "14992/14992 [==============================] - 1s 96us/sample - loss: 0.9703 - accuracy: 0.5315 - val_loss: 0.9769 - val_accuracy: 0.5261\n",
      "Epoch 106/500\n",
      "14992/14992 [==============================] - 1s 77us/sample - loss: 0.9703 - accuracy: 0.5309 - val_loss: 0.9767 - val_accuracy: 0.5232\n",
      "Epoch 107/500\n",
      "14992/14992 [==============================] - 1s 83us/sample - loss: 0.9702 - accuracy: 0.5317 - val_loss: 0.9767 - val_accuracy: 0.5232\n",
      "Epoch 108/500\n",
      "14992/14992 [==============================] - 1s 98us/sample - loss: 0.9703 - accuracy: 0.5312 - val_loss: 0.9768 - val_accuracy: 0.5248\n",
      "Epoch 109/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14992/14992 [==============================] - 1s 82us/sample - loss: 0.9702 - accuracy: 0.5320 - val_loss: 0.9767 - val_accuracy: 0.5235\n",
      "Epoch 110/500\n",
      "14992/14992 [==============================] - 1s 80us/sample - loss: 0.9702 - accuracy: 0.5318 - val_loss: 0.9767 - val_accuracy: 0.5245\n",
      "Epoch 111/500\n",
      "14992/14992 [==============================] - 1s 78us/sample - loss: 0.9703 - accuracy: 0.5317 - val_loss: 0.9768 - val_accuracy: 0.5243\n",
      "Epoch 112/500\n",
      "14992/14992 [==============================] - 1s 78us/sample - loss: 0.9703 - accuracy: 0.5308 - val_loss: 0.9769 - val_accuracy: 0.5261\n",
      "Epoch 113/500\n",
      "14992/14992 [==============================] - 1s 97us/sample - loss: 0.9703 - accuracy: 0.5314 - val_loss: 0.9767 - val_accuracy: 0.5232\n",
      "Epoch 114/500\n",
      "14992/14992 [==============================] - 3s 176us/sample - loss: 0.9703 - accuracy: 0.5321 - val_loss: 0.9772 - val_accuracy: 0.5256\n",
      "Epoch 115/500\n",
      "14992/14992 [==============================] - 2s 161us/sample - loss: 0.9703 - accuracy: 0.5316 - val_loss: 0.9768 - val_accuracy: 0.5243\n",
      "Epoch 116/500\n",
      "14992/14992 [==============================] - 2s 143us/sample - loss: 0.9703 - accuracy: 0.5311 - val_loss: 0.9767 - val_accuracy: 0.5232\n",
      "Epoch 117/500\n",
      "14992/14992 [==============================] - 1s 99us/sample - loss: 0.9703 - accuracy: 0.5308 - val_loss: 0.9768 - val_accuracy: 0.5237\n",
      "Epoch 118/500\n",
      "14992/14992 [==============================] - 1s 90us/sample - loss: 0.9702 - accuracy: 0.5321 - val_loss: 0.9768 - val_accuracy: 0.5248\n",
      "Epoch 119/500\n",
      "14992/14992 [==============================] - 1s 78us/sample - loss: 0.9703 - accuracy: 0.5313 - val_loss: 0.9769 - val_accuracy: 0.5256\n",
      "Epoch 120/500\n",
      "14992/14992 [==============================] - 1s 98us/sample - loss: 0.9702 - accuracy: 0.5305 - val_loss: 0.9777 - val_accuracy: 0.5245\n",
      "Epoch 121/500\n",
      "14992/14992 [==============================] - 2s 106us/sample - loss: 0.9703 - accuracy: 0.5307 - val_loss: 0.9767 - val_accuracy: 0.5240\n",
      "Epoch 122/500\n",
      "14992/14992 [==============================] - 1s 79us/sample - loss: 0.9702 - accuracy: 0.5321 - val_loss: 0.9767 - val_accuracy: 0.5240\n",
      "Epoch 123/500\n",
      "14992/14992 [==============================] - 1s 74us/sample - loss: 0.9702 - accuracy: 0.5316 - val_loss: 0.9769 - val_accuracy: 0.5264\n",
      "Epoch 124/500\n",
      "14992/14992 [==============================] - 1s 76us/sample - loss: 0.9702 - accuracy: 0.5313 - val_loss: 0.9768 - val_accuracy: 0.5243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4d00e3d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model01.fit(train_X01, train_y01, validation_split=validation_split,epochs=epochs,callbacks=[early_stoping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 21)                462       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                1408      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 4,641\n",
      "Trainable params: 4,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model02.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5063 samples, validate on 1266 samples\n",
      "Epoch 1/500\n",
      "5063/5063 [==============================] - 2s 338us/sample - loss: 1.0645 - accuracy: 0.4679 - val_loss: 1.0769 - val_accuracy: 0.4368\n",
      "Epoch 2/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 1.0587 - accuracy: 0.4669 - val_loss: 1.0753 - val_accuracy: 0.4368\n",
      "Epoch 3/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 1.0579 - accuracy: 0.4669 - val_loss: 1.0749 - val_accuracy: 0.4368\n",
      "Epoch 4/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 1.0566 - accuracy: 0.4669 - val_loss: 1.0736 - val_accuracy: 0.4368\n",
      "Epoch 5/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 1.0513 - accuracy: 0.4669 - val_loss: 1.0662 - val_accuracy: 0.4368\n",
      "Epoch 6/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 1.0467 - accuracy: 0.4669 - val_loss: 1.0615 - val_accuracy: 0.4368\n",
      "Epoch 7/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 1.0422 - accuracy: 0.4669 - val_loss: 1.0561 - val_accuracy: 0.4368\n",
      "Epoch 8/500\n",
      "5063/5063 [==============================] - 1s 101us/sample - loss: 1.0360 - accuracy: 0.4669 - val_loss: 1.0497 - val_accuracy: 0.4368\n",
      "Epoch 9/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 1.0301 - accuracy: 0.4669 - val_loss: 1.0458 - val_accuracy: 0.4368\n",
      "Epoch 10/500\n",
      "5063/5063 [==============================] - 1s 101us/sample - loss: 1.0253 - accuracy: 0.4669 - val_loss: 1.0401 - val_accuracy: 0.4368\n",
      "Epoch 11/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 1.0216 - accuracy: 0.4669 - val_loss: 1.0368 - val_accuracy: 0.4368\n",
      "Epoch 12/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 1.0186 - accuracy: 0.4669 - val_loss: 1.0343 - val_accuracy: 0.4368\n",
      "Epoch 13/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 1.0164 - accuracy: 0.4669 - val_loss: 1.0323 - val_accuracy: 0.4368\n",
      "Epoch 14/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 1.0153 - accuracy: 0.4669 - val_loss: 1.0296 - val_accuracy: 0.4368\n",
      "Epoch 15/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 1.0137 - accuracy: 0.4669 - val_loss: 1.0285 - val_accuracy: 0.4368\n",
      "Epoch 16/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 1.0125 - accuracy: 0.4669 - val_loss: 1.0266 - val_accuracy: 0.4368\n",
      "Epoch 17/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 1.0111 - accuracy: 0.4805 - val_loss: 1.0257 - val_accuracy: 0.4921\n",
      "Epoch 18/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 1.0105 - accuracy: 0.5169 - val_loss: 1.0246 - val_accuracy: 0.4945\n",
      "Epoch 19/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 1.0095 - accuracy: 0.5183 - val_loss: 1.0253 - val_accuracy: 0.4921\n",
      "Epoch 20/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 1.0089 - accuracy: 0.5183 - val_loss: 1.0226 - val_accuracy: 0.4953\n",
      "Epoch 21/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 1.0080 - accuracy: 0.5195 - val_loss: 1.0221 - val_accuracy: 0.5024\n",
      "Epoch 22/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 1.0073 - accuracy: 0.5189 - val_loss: 1.0248 - val_accuracy: 0.4913\n",
      "Epoch 23/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 1.0067 - accuracy: 0.5187 - val_loss: 1.0204 - val_accuracy: 0.5000\n",
      "Epoch 24/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 1.0053 - accuracy: 0.5198 - val_loss: 1.0247 - val_accuracy: 0.4929\n",
      "Epoch 25/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 1.0051 - accuracy: 0.5228 - val_loss: 1.0221 - val_accuracy: 0.4945\n",
      "Epoch 26/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 1.0050 - accuracy: 0.5210 - val_loss: 1.0186 - val_accuracy: 0.5024\n",
      "Epoch 27/500\n",
      "5063/5063 [==============================] - 1s 101us/sample - loss: 1.0040 - accuracy: 0.5175 - val_loss: 1.0180 - val_accuracy: 0.4992\n",
      "Epoch 28/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 1.0035 - accuracy: 0.5222 - val_loss: 1.0177 - val_accuracy: 0.5079\n",
      "Epoch 29/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 1.0030 - accuracy: 0.5197 - val_loss: 1.0198 - val_accuracy: 0.4929\n",
      "Epoch 30/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 1.0024 - accuracy: 0.5222 - val_loss: 1.0212 - val_accuracy: 0.4945\n",
      "Epoch 31/500\n",
      "5063/5063 [==============================] - 1s 101us/sample - loss: 1.0021 - accuracy: 0.5236 - val_loss: 1.0166 - val_accuracy: 0.5071\n",
      "Epoch 32/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 1.0019 - accuracy: 0.5198 - val_loss: 1.0152 - val_accuracy: 0.5008\n",
      "Epoch 33/500\n",
      "5063/5063 [==============================] - 1s 101us/sample - loss: 1.0012 - accuracy: 0.5189 - val_loss: 1.0148 - val_accuracy: 0.5008\n",
      "Epoch 34/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 1.0008 - accuracy: 0.5212 - val_loss: 1.0143 - val_accuracy: 0.5008\n",
      "Epoch 35/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 1.0002 - accuracy: 0.5206 - val_loss: 1.0154 - val_accuracy: 0.4992\n",
      "Epoch 36/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9998 - accuracy: 0.5220 - val_loss: 1.0137 - val_accuracy: 0.5055\n",
      "Epoch 37/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9990 - accuracy: 0.5195 - val_loss: 1.0178 - val_accuracy: 0.4961\n",
      "Epoch 38/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9992 - accuracy: 0.5234 - val_loss: 1.0136 - val_accuracy: 0.4976\n",
      "Epoch 39/500\n",
      "5063/5063 [==============================] - 1s 151us/sample - loss: 0.9988 - accuracy: 0.5228 - val_loss: 1.0129 - val_accuracy: 0.5047\n",
      "Epoch 40/500\n",
      "5063/5063 [==============================] - 1s 141us/sample - loss: 0.9985 - accuracy: 0.5236 - val_loss: 1.0124 - val_accuracy: 0.5008\n",
      "Epoch 41/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9979 - accuracy: 0.5220 - val_loss: 1.0118 - val_accuracy: 0.5024\n",
      "Epoch 42/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9976 - accuracy: 0.5244 - val_loss: 1.0118 - val_accuracy: 0.5024\n",
      "Epoch 43/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9972 - accuracy: 0.5228 - val_loss: 1.0128 - val_accuracy: 0.5000\n",
      "Epoch 44/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9972 - accuracy: 0.5226 - val_loss: 1.0111 - val_accuracy: 0.5024\n",
      "Epoch 45/500\n",
      "5063/5063 [==============================] - 1s 123us/sample - loss: 0.9964 - accuracy: 0.5224 - val_loss: 1.0120 - val_accuracy: 0.4968\n",
      "Epoch 46/500\n",
      "5063/5063 [==============================] - 1s 151us/sample - loss: 0.9962 - accuracy: 0.5238 - val_loss: 1.0110 - val_accuracy: 0.5047\n",
      "Epoch 47/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 0.9957 - accuracy: 0.5228 - val_loss: 1.0117 - val_accuracy: 0.5008\n",
      "Epoch 48/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9958 - accuracy: 0.5210 - val_loss: 1.0112 - val_accuracy: 0.4992\n",
      "Epoch 49/500\n",
      "5063/5063 [==============================] - 1s 148us/sample - loss: 0.9951 - accuracy: 0.5236 - val_loss: 1.0094 - val_accuracy: 0.5024\n",
      "Epoch 50/500\n",
      "5063/5063 [==============================] - 1s 148us/sample - loss: 0.9948 - accuracy: 0.5226 - val_loss: 1.0090 - val_accuracy: 0.5047\n",
      "Epoch 51/500\n",
      "5063/5063 [==============================] - 1s 108us/sample - loss: 0.9942 - accuracy: 0.5254 - val_loss: 1.0090 - val_accuracy: 0.5016\n",
      "Epoch 52/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9941 - accuracy: 0.5230 - val_loss: 1.0093 - val_accuracy: 0.5000\n",
      "Epoch 53/500\n",
      "5063/5063 [==============================] - 1s 101us/sample - loss: 0.9937 - accuracy: 0.5248 - val_loss: 1.0081 - val_accuracy: 0.5000\n",
      "Epoch 54/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9936 - accuracy: 0.5234 - val_loss: 1.0083 - val_accuracy: 0.5000\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5063/5063 [==============================] - 1s 101us/sample - loss: 0.9936 - accuracy: 0.5246 - val_loss: 1.0075 - val_accuracy: 0.5008\n",
      "Epoch 56/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 0.9927 - accuracy: 0.5262 - val_loss: 1.0110 - val_accuracy: 0.5032\n",
      "Epoch 57/500\n",
      "5063/5063 [==============================] - 1s 125us/sample - loss: 0.9930 - accuracy: 0.5236 - val_loss: 1.0076 - val_accuracy: 0.5024\n",
      "Epoch 58/500\n",
      "5063/5063 [==============================] - 1s 136us/sample - loss: 0.9925 - accuracy: 0.5264 - val_loss: 1.0069 - val_accuracy: 0.5047\n",
      "Epoch 59/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9923 - accuracy: 0.5258 - val_loss: 1.0092 - val_accuracy: 0.4984\n",
      "Epoch 60/500\n",
      "5063/5063 [==============================] - 1s 136us/sample - loss: 0.9922 - accuracy: 0.5252 - val_loss: 1.0089 - val_accuracy: 0.4992\n",
      "Epoch 61/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9920 - accuracy: 0.5276 - val_loss: 1.0108 - val_accuracy: 0.5024\n",
      "Epoch 62/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9917 - accuracy: 0.5228 - val_loss: 1.0060 - val_accuracy: 0.5047\n",
      "Epoch 63/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9913 - accuracy: 0.5238 - val_loss: 1.0071 - val_accuracy: 0.5016\n",
      "Epoch 64/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9909 - accuracy: 0.5262 - val_loss: 1.0076 - val_accuracy: 0.5000\n",
      "Epoch 65/500\n",
      "5063/5063 [==============================] - 1s 136us/sample - loss: 0.9905 - accuracy: 0.5248 - val_loss: 1.0054 - val_accuracy: 0.5047\n",
      "Epoch 66/500\n",
      "5063/5063 [==============================] - 1s 123us/sample - loss: 0.9905 - accuracy: 0.5248 - val_loss: 1.0052 - val_accuracy: 0.5047\n",
      "Epoch 67/500\n",
      "5063/5063 [==============================] - 1s 137us/sample - loss: 0.9900 - accuracy: 0.5234 - val_loss: 1.0046 - val_accuracy: 0.5063\n",
      "Epoch 68/500\n",
      "5063/5063 [==============================] - 1s 114us/sample - loss: 0.9900 - accuracy: 0.5295 - val_loss: 1.0048 - val_accuracy: 0.5032\n",
      "Epoch 69/500\n",
      "5063/5063 [==============================] - 1s 142us/sample - loss: 0.9901 - accuracy: 0.5274 - val_loss: 1.0043 - val_accuracy: 0.5071\n",
      "Epoch 70/500\n",
      "5063/5063 [==============================] - 1s 145us/sample - loss: 0.9897 - accuracy: 0.5264 - val_loss: 1.0044 - val_accuracy: 0.5087\n",
      "Epoch 71/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 0.9894 - accuracy: 0.5264 - val_loss: 1.0040 - val_accuracy: 0.5055\n",
      "Epoch 72/500\n",
      "5063/5063 [==============================] - 1s 122us/sample - loss: 0.9892 - accuracy: 0.5266 - val_loss: 1.0038 - val_accuracy: 0.5079\n",
      "Epoch 73/500\n",
      "5063/5063 [==============================] - 1s 154us/sample - loss: 0.9889 - accuracy: 0.5272 - val_loss: 1.0048 - val_accuracy: 0.5024\n",
      "Epoch 74/500\n",
      "5063/5063 [==============================] - 1s 121us/sample - loss: 0.9885 - accuracy: 0.5283 - val_loss: 1.0040 - val_accuracy: 0.5079\n",
      "Epoch 75/500\n",
      "5063/5063 [==============================] - 0s 99us/sample - loss: 0.9881 - accuracy: 0.5291 - val_loss: 1.0036 - val_accuracy: 0.5079\n",
      "Epoch 76/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9882 - accuracy: 0.5279 - val_loss: 1.0034 - val_accuracy: 0.5079\n",
      "Epoch 77/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9877 - accuracy: 0.5272 - val_loss: 1.0029 - val_accuracy: 0.5111\n",
      "Epoch 78/500\n",
      "5063/5063 [==============================] - 0s 95us/sample - loss: 0.9878 - accuracy: 0.5291 - val_loss: 1.0038 - val_accuracy: 0.5039\n",
      "Epoch 79/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9874 - accuracy: 0.5274 - val_loss: 1.0025 - val_accuracy: 0.5103\n",
      "Epoch 80/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9873 - accuracy: 0.5278 - val_loss: 1.0084 - val_accuracy: 0.5008\n",
      "Epoch 81/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9875 - accuracy: 0.5266 - val_loss: 1.0037 - val_accuracy: 0.5039\n",
      "Epoch 82/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9871 - accuracy: 0.5264 - val_loss: 1.0021 - val_accuracy: 0.5142\n",
      "Epoch 83/500\n",
      "5063/5063 [==============================] - 1s 142us/sample - loss: 0.9867 - accuracy: 0.5279 - val_loss: 1.0058 - val_accuracy: 0.5032\n",
      "Epoch 84/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9868 - accuracy: 0.5289 - val_loss: 1.0023 - val_accuracy: 0.5063\n",
      "Epoch 85/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9864 - accuracy: 0.5281 - val_loss: 1.0021 - val_accuracy: 0.5071\n",
      "Epoch 86/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9864 - accuracy: 0.5281 - val_loss: 1.0020 - val_accuracy: 0.5079\n",
      "Epoch 87/500\n",
      "5063/5063 [==============================] - 0s 99us/sample - loss: 0.9855 - accuracy: 0.5305 - val_loss: 1.0012 - val_accuracy: 0.5095\n",
      "Epoch 88/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9859 - accuracy: 0.5281 - val_loss: 1.0026 - val_accuracy: 0.5032\n",
      "Epoch 89/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9858 - accuracy: 0.5274 - val_loss: 1.0012 - val_accuracy: 0.5111\n",
      "Epoch 90/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9855 - accuracy: 0.5299 - val_loss: 1.0023 - val_accuracy: 0.5032\n",
      "Epoch 91/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9851 - accuracy: 0.5281 - val_loss: 1.0002 - val_accuracy: 0.5095\n",
      "Epoch 92/500\n",
      "5063/5063 [==============================] - 1s 106us/sample - loss: 0.9851 - accuracy: 0.5287 - val_loss: 1.0013 - val_accuracy: 0.5000\n",
      "Epoch 93/500\n",
      "5063/5063 [==============================] - 1s 125us/sample - loss: 0.9850 - accuracy: 0.5315 - val_loss: 1.0011 - val_accuracy: 0.5095\n",
      "Epoch 94/500\n",
      "5063/5063 [==============================] - 1s 142us/sample - loss: 0.9848 - accuracy: 0.5307 - val_loss: 0.9998 - val_accuracy: 0.5150\n",
      "Epoch 95/500\n",
      "5063/5063 [==============================] - 1s 151us/sample - loss: 0.9844 - accuracy: 0.5325 - val_loss: 1.0007 - val_accuracy: 0.5103\n",
      "Epoch 96/500\n",
      "5063/5063 [==============================] - 1s 128us/sample - loss: 0.9845 - accuracy: 0.5262 - val_loss: 1.0022 - val_accuracy: 0.5032\n",
      "Epoch 97/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9840 - accuracy: 0.5293 - val_loss: 0.9997 - val_accuracy: 0.5063\n",
      "Epoch 98/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9839 - accuracy: 0.5266 - val_loss: 1.0013 - val_accuracy: 0.5063\n",
      "Epoch 99/500\n",
      "5063/5063 [==============================] - 0s 99us/sample - loss: 0.9836 - accuracy: 0.5305 - val_loss: 0.9996 - val_accuracy: 0.5142\n",
      "Epoch 100/500\n",
      "5063/5063 [==============================] - 0s 95us/sample - loss: 0.9833 - accuracy: 0.5307 - val_loss: 1.0070 - val_accuracy: 0.5000\n",
      "Epoch 101/500\n",
      "5063/5063 [==============================] - 0s 99us/sample - loss: 0.9838 - accuracy: 0.5293 - val_loss: 0.9994 - val_accuracy: 0.5142\n",
      "Epoch 102/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9834 - accuracy: 0.5317 - val_loss: 1.0002 - val_accuracy: 0.5095\n",
      "Epoch 103/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9832 - accuracy: 0.5309 - val_loss: 1.0008 - val_accuracy: 0.5095\n",
      "Epoch 104/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9829 - accuracy: 0.5313 - val_loss: 0.9996 - val_accuracy: 0.5095\n",
      "Epoch 105/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9829 - accuracy: 0.5327 - val_loss: 0.9991 - val_accuracy: 0.5150\n",
      "Epoch 106/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9828 - accuracy: 0.5311 - val_loss: 0.9987 - val_accuracy: 0.5142\n",
      "Epoch 107/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9822 - accuracy: 0.5293 - val_loss: 0.9991 - val_accuracy: 0.5134\n",
      "Epoch 108/500\n",
      "5063/5063 [==============================] - 0s 96us/sample - loss: 0.9823 - accuracy: 0.5317 - val_loss: 1.0015 - val_accuracy: 0.5063\n",
      "Epoch 109/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9820 - accuracy: 0.5315 - val_loss: 0.9983 - val_accuracy: 0.5142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9820 - accuracy: 0.5351 - val_loss: 0.9978 - val_accuracy: 0.5103\n",
      "Epoch 111/500\n",
      "5063/5063 [==============================] - 1s 152us/sample - loss: 0.9822 - accuracy: 0.5327 - val_loss: 0.9989 - val_accuracy: 0.5126\n",
      "Epoch 112/500\n",
      "5063/5063 [==============================] - 1s 123us/sample - loss: 0.9819 - accuracy: 0.5307 - val_loss: 0.9995 - val_accuracy: 0.5142\n",
      "Epoch 113/500\n",
      "5063/5063 [==============================] - 1s 125us/sample - loss: 0.9818 - accuracy: 0.5313 - val_loss: 0.9995 - val_accuracy: 0.5126\n",
      "Epoch 114/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 0.9812 - accuracy: 0.5335 - val_loss: 0.9977 - val_accuracy: 0.5039\n",
      "Epoch 115/500\n",
      "5063/5063 [==============================] - 1s 146us/sample - loss: 0.9815 - accuracy: 0.5301 - val_loss: 0.9976 - val_accuracy: 0.5103\n",
      "Epoch 116/500\n",
      "5063/5063 [==============================] - 1s 158us/sample - loss: 0.9814 - accuracy: 0.5323 - val_loss: 0.9981 - val_accuracy: 0.5024\n",
      "Epoch 117/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9816 - accuracy: 0.5307 - val_loss: 0.9969 - val_accuracy: 0.5111\n",
      "Epoch 118/500\n",
      "5063/5063 [==============================] - 1s 161us/sample - loss: 0.9809 - accuracy: 0.5307 - val_loss: 0.9995 - val_accuracy: 0.5111\n",
      "Epoch 119/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9809 - accuracy: 0.5313 - val_loss: 0.9976 - val_accuracy: 0.5134\n",
      "Epoch 120/500\n",
      "5063/5063 [==============================] - 1s 145us/sample - loss: 0.9808 - accuracy: 0.5307 - val_loss: 0.9972 - val_accuracy: 0.5126\n",
      "Epoch 121/500\n",
      "5063/5063 [==============================] - 1s 175us/sample - loss: 0.9803 - accuracy: 0.5333 - val_loss: 0.9967 - val_accuracy: 0.5095\n",
      "Epoch 122/500\n",
      "5063/5063 [==============================] - 1s 143us/sample - loss: 0.9807 - accuracy: 0.5337 - val_loss: 0.9977 - val_accuracy: 0.5142\n",
      "Epoch 123/500\n",
      "5063/5063 [==============================] - 1s 127us/sample - loss: 0.9799 - accuracy: 0.5327 - val_loss: 0.9972 - val_accuracy: 0.5103\n",
      "Epoch 124/500\n",
      "5063/5063 [==============================] - 1s 135us/sample - loss: 0.9798 - accuracy: 0.5319 - val_loss: 0.9997 - val_accuracy: 0.5103\n",
      "Epoch 125/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9801 - accuracy: 0.5331 - val_loss: 0.9969 - val_accuracy: 0.5111\n",
      "Epoch 126/500\n",
      "5063/5063 [==============================] - 1s 113us/sample - loss: 0.9798 - accuracy: 0.5315 - val_loss: 0.9961 - val_accuracy: 0.5095\n",
      "Epoch 127/500\n",
      "5063/5063 [==============================] - 1s 123us/sample - loss: 0.9793 - accuracy: 0.5333 - val_loss: 0.9962 - val_accuracy: 0.5111\n",
      "Epoch 128/500\n",
      "5063/5063 [==============================] - 1s 109us/sample - loss: 0.9794 - accuracy: 0.5283 - val_loss: 0.9962 - val_accuracy: 0.5087\n",
      "Epoch 129/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9795 - accuracy: 0.5337 - val_loss: 0.9964 - val_accuracy: 0.5063\n",
      "Epoch 130/500\n",
      "5063/5063 [==============================] - 1s 112us/sample - loss: 0.9792 - accuracy: 0.5329 - val_loss: 0.9963 - val_accuracy: 0.5095\n",
      "Epoch 131/500\n",
      "5063/5063 [==============================] - 1s 180us/sample - loss: 0.9793 - accuracy: 0.5323 - val_loss: 0.9959 - val_accuracy: 0.5103\n",
      "Epoch 132/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9790 - accuracy: 0.5329 - val_loss: 0.9964 - val_accuracy: 0.5111\n",
      "Epoch 133/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9788 - accuracy: 0.5351 - val_loss: 0.9956 - val_accuracy: 0.5032\n",
      "Epoch 134/500\n",
      "5063/5063 [==============================] - 1s 121us/sample - loss: 0.9791 - accuracy: 0.5337 - val_loss: 0.9953 - val_accuracy: 0.5111\n",
      "Epoch 135/500\n",
      "5063/5063 [==============================] - 1s 108us/sample - loss: 0.9785 - accuracy: 0.5345 - val_loss: 0.9975 - val_accuracy: 0.5142\n",
      "Epoch 136/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9786 - accuracy: 0.5337 - val_loss: 0.9957 - val_accuracy: 0.5055\n",
      "Epoch 137/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9789 - accuracy: 0.5323 - val_loss: 0.9953 - val_accuracy: 0.5111\n",
      "Epoch 138/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 0.9786 - accuracy: 0.5339 - val_loss: 0.9956 - val_accuracy: 0.5111\n",
      "Epoch 139/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9779 - accuracy: 0.5362 - val_loss: 1.0038 - val_accuracy: 0.5039\n",
      "Epoch 140/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9785 - accuracy: 0.5323 - val_loss: 0.9979 - val_accuracy: 0.5126\n",
      "Epoch 141/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 0.9777 - accuracy: 0.5321 - val_loss: 0.9962 - val_accuracy: 0.5158\n",
      "Epoch 142/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9783 - accuracy: 0.5351 - val_loss: 0.9952 - val_accuracy: 0.5103\n",
      "Epoch 143/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9776 - accuracy: 0.5331 - val_loss: 0.9960 - val_accuracy: 0.5150\n",
      "Epoch 144/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9779 - accuracy: 0.5345 - val_loss: 1.0019 - val_accuracy: 0.5071\n",
      "Epoch 145/500\n",
      "5063/5063 [==============================] - 1s 106us/sample - loss: 0.9779 - accuracy: 0.5353 - val_loss: 0.9957 - val_accuracy: 0.5118\n",
      "Epoch 146/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9777 - accuracy: 0.5339 - val_loss: 0.9955 - val_accuracy: 0.5118\n",
      "Epoch 147/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9772 - accuracy: 0.5331 - val_loss: 0.9947 - val_accuracy: 0.5103\n",
      "Epoch 148/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9774 - accuracy: 0.5347 - val_loss: 0.9960 - val_accuracy: 0.5126\n",
      "Epoch 149/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9769 - accuracy: 0.5368 - val_loss: 0.9941 - val_accuracy: 0.5095\n",
      "Epoch 150/500\n",
      "5063/5063 [==============================] - 1s 112us/sample - loss: 0.9776 - accuracy: 0.5335 - val_loss: 0.9947 - val_accuracy: 0.5111\n",
      "Epoch 151/500\n",
      "5063/5063 [==============================] - 1s 158us/sample - loss: 0.9765 - accuracy: 0.5357 - val_loss: 0.9974 - val_accuracy: 0.5118\n",
      "Epoch 152/500\n",
      "5063/5063 [==============================] - 1s 128us/sample - loss: 0.9771 - accuracy: 0.5329 - val_loss: 0.9989 - val_accuracy: 0.5103\n",
      "Epoch 153/500\n",
      "5063/5063 [==============================] - 1s 130us/sample - loss: 0.9769 - accuracy: 0.5315 - val_loss: 0.9959 - val_accuracy: 0.5142\n",
      "Epoch 154/500\n",
      "5063/5063 [==============================] - 1s 163us/sample - loss: 0.9766 - accuracy: 0.5313 - val_loss: 0.9975 - val_accuracy: 0.5126\n",
      "Epoch 155/500\n",
      "5063/5063 [==============================] - 1s 109us/sample - loss: 0.9767 - accuracy: 0.5353 - val_loss: 0.9945 - val_accuracy: 0.5111\n",
      "Epoch 156/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9766 - accuracy: 0.5329 - val_loss: 0.9935 - val_accuracy: 0.5111\n",
      "Epoch 157/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9765 - accuracy: 0.5345 - val_loss: 0.9932 - val_accuracy: 0.5095\n",
      "Epoch 158/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9765 - accuracy: 0.5337 - val_loss: 0.9951 - val_accuracy: 0.5126\n",
      "Epoch 159/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9760 - accuracy: 0.5353 - val_loss: 0.9946 - val_accuracy: 0.5063\n",
      "Epoch 160/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9763 - accuracy: 0.5337 - val_loss: 0.9948 - val_accuracy: 0.5103\n",
      "Epoch 161/500\n",
      "5063/5063 [==============================] - 0s 99us/sample - loss: 0.9761 - accuracy: 0.5351 - val_loss: 0.9941 - val_accuracy: 0.5103\n",
      "Epoch 162/500\n",
      "5063/5063 [==============================] - 1s 101us/sample - loss: 0.9758 - accuracy: 0.5317 - val_loss: 0.9931 - val_accuracy: 0.5055\n",
      "Epoch 163/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9761 - accuracy: 0.5362 - val_loss: 0.9938 - val_accuracy: 0.5079\n",
      "Epoch 164/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9762 - accuracy: 0.5321 - val_loss: 0.9936 - val_accuracy: 0.5087\n",
      "Epoch 165/500\n",
      "5063/5063 [==============================] - 0s 96us/sample - loss: 0.9758 - accuracy: 0.5337 - val_loss: 0.9928 - val_accuracy: 0.5111\n",
      "Epoch 166/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9761 - accuracy: 0.5313 - val_loss: 0.9927 - val_accuracy: 0.5095\n",
      "Epoch 167/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9758 - accuracy: 0.5337 - val_loss: 0.9994 - val_accuracy: 0.5087\n",
      "Epoch 168/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9757 - accuracy: 0.5355 - val_loss: 0.9932 - val_accuracy: 0.5047\n",
      "Epoch 169/500\n",
      "5063/5063 [==============================] - 0s 95us/sample - loss: 0.9756 - accuracy: 0.5357 - val_loss: 0.9932 - val_accuracy: 0.5095\n",
      "Epoch 170/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9756 - accuracy: 0.5364 - val_loss: 0.9933 - val_accuracy: 0.5103\n",
      "Epoch 171/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9749 - accuracy: 0.5370 - val_loss: 0.9960 - val_accuracy: 0.5166\n",
      "Epoch 172/500\n",
      "5063/5063 [==============================] - 0s 99us/sample - loss: 0.9753 - accuracy: 0.5357 - val_loss: 0.9924 - val_accuracy: 0.5055\n",
      "Epoch 173/500\n",
      "5063/5063 [==============================] - 0s 96us/sample - loss: 0.9750 - accuracy: 0.5380 - val_loss: 0.9926 - val_accuracy: 0.5103\n",
      "Epoch 174/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9751 - accuracy: 0.5347 - val_loss: 0.9922 - val_accuracy: 0.5087\n",
      "Epoch 175/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9749 - accuracy: 0.5337 - val_loss: 0.9926 - val_accuracy: 0.5103\n",
      "Epoch 176/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9747 - accuracy: 0.5402 - val_loss: 0.9923 - val_accuracy: 0.5087\n",
      "Epoch 177/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9747 - accuracy: 0.5349 - val_loss: 0.9935 - val_accuracy: 0.5103\n",
      "Epoch 178/500\n",
      "5063/5063 [==============================] - 0s 99us/sample - loss: 0.9746 - accuracy: 0.5357 - val_loss: 0.9923 - val_accuracy: 0.5047\n",
      "Epoch 179/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9743 - accuracy: 0.5337 - val_loss: 0.9921 - val_accuracy: 0.5055\n",
      "Epoch 180/500\n",
      "5063/5063 [==============================] - 1s 138us/sample - loss: 0.9748 - accuracy: 0.5351 - val_loss: 0.9923 - val_accuracy: 0.5118\n",
      "Epoch 181/500\n",
      "5063/5063 [==============================] - 1s 112us/sample - loss: 0.9747 - accuracy: 0.5347 - val_loss: 0.9925 - val_accuracy: 0.5118\n",
      "Epoch 182/500\n",
      "5063/5063 [==============================] - 1s 145us/sample - loss: 0.9745 - accuracy: 0.5366 - val_loss: 0.9926 - val_accuracy: 0.5103\n",
      "Epoch 183/500\n",
      "5063/5063 [==============================] - 1s 157us/sample - loss: 0.9739 - accuracy: 0.5372 - val_loss: 0.9963 - val_accuracy: 0.5126\n",
      "Epoch 184/500\n",
      "5063/5063 [==============================] - 1s 131us/sample - loss: 0.9743 - accuracy: 0.5353 - val_loss: 0.9923 - val_accuracy: 0.5047\n",
      "Epoch 185/500\n",
      "5063/5063 [==============================] - 1s 168us/sample - loss: 0.9745 - accuracy: 0.5360 - val_loss: 0.9928 - val_accuracy: 0.5111\n",
      "Epoch 186/500\n",
      "5063/5063 [==============================] - 1s 147us/sample - loss: 0.9742 - accuracy: 0.5355 - val_loss: 0.9922 - val_accuracy: 0.5095\n",
      "Epoch 187/500\n",
      "5063/5063 [==============================] - 1s 109us/sample - loss: 0.9740 - accuracy: 0.5357 - val_loss: 0.9917 - val_accuracy: 0.5063\n",
      "Epoch 188/500\n",
      "5063/5063 [==============================] - 1s 181us/sample - loss: 0.9740 - accuracy: 0.5358 - val_loss: 0.9912 - val_accuracy: 0.5039\n",
      "Epoch 189/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9739 - accuracy: 0.5360 - val_loss: 0.9932 - val_accuracy: 0.5111\n",
      "Epoch 190/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9738 - accuracy: 0.5360 - val_loss: 0.9946 - val_accuracy: 0.5134\n",
      "Epoch 191/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9739 - accuracy: 0.5362 - val_loss: 0.9914 - val_accuracy: 0.5087\n",
      "Epoch 192/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9739 - accuracy: 0.5349 - val_loss: 0.9912 - val_accuracy: 0.5095\n",
      "Epoch 193/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9739 - accuracy: 0.5349 - val_loss: 0.9918 - val_accuracy: 0.5103\n",
      "Epoch 194/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9736 - accuracy: 0.5366 - val_loss: 0.9920 - val_accuracy: 0.5118\n",
      "Epoch 195/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9735 - accuracy: 0.5345 - val_loss: 0.9963 - val_accuracy: 0.5118\n",
      "Epoch 196/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9735 - accuracy: 0.5347 - val_loss: 0.9964 - val_accuracy: 0.5111\n",
      "Epoch 197/500\n",
      "5063/5063 [==============================] - 1s 143us/sample - loss: 0.9736 - accuracy: 0.5378 - val_loss: 0.9907 - val_accuracy: 0.5126\n",
      "Epoch 198/500\n",
      "5063/5063 [==============================] - 1s 162us/sample - loss: 0.9732 - accuracy: 0.5398 - val_loss: 0.9906 - val_accuracy: 0.5079\n",
      "Epoch 199/500\n",
      "5063/5063 [==============================] - 1s 157us/sample - loss: 0.9734 - accuracy: 0.5362 - val_loss: 0.9923 - val_accuracy: 0.5095\n",
      "Epoch 200/500\n",
      "5063/5063 [==============================] - 1s 109us/sample - loss: 0.9731 - accuracy: 0.5351 - val_loss: 0.9908 - val_accuracy: 0.5063\n",
      "Epoch 201/500\n",
      "5063/5063 [==============================] - 1s 116us/sample - loss: 0.9730 - accuracy: 0.5374 - val_loss: 0.9958 - val_accuracy: 0.5111\n",
      "Epoch 202/500\n",
      "5063/5063 [==============================] - 1s 123us/sample - loss: 0.9732 - accuracy: 0.5370 - val_loss: 0.9906 - val_accuracy: 0.5126\n",
      "Epoch 203/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9726 - accuracy: 0.5357 - val_loss: 0.9906 - val_accuracy: 0.5063\n",
      "Epoch 204/500\n",
      "5063/5063 [==============================] - 1s 127us/sample - loss: 0.9729 - accuracy: 0.5333 - val_loss: 0.9924 - val_accuracy: 0.5111\n",
      "Epoch 205/500\n",
      "5063/5063 [==============================] - 1s 131us/sample - loss: 0.9728 - accuracy: 0.5360 - val_loss: 0.9907 - val_accuracy: 0.5087\n",
      "Epoch 206/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9725 - accuracy: 0.5335 - val_loss: 0.9940 - val_accuracy: 0.5142\n",
      "Epoch 207/500\n",
      "5063/5063 [==============================] - 1s 106us/sample - loss: 0.9716 - accuracy: 0.5396 - val_loss: 0.9905 - val_accuracy: 0.5071\n",
      "Epoch 208/500\n",
      "5063/5063 [==============================] - 1s 135us/sample - loss: 0.9730 - accuracy: 0.5360 - val_loss: 0.9916 - val_accuracy: 0.5126\n",
      "Epoch 209/500\n",
      "5063/5063 [==============================] - 1s 132us/sample - loss: 0.9725 - accuracy: 0.5366 - val_loss: 0.9917 - val_accuracy: 0.5118\n",
      "Epoch 210/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9721 - accuracy: 0.5398 - val_loss: 0.9903 - val_accuracy: 0.5071\n",
      "Epoch 211/500\n",
      "5063/5063 [==============================] - 1s 152us/sample - loss: 0.9727 - accuracy: 0.5353 - val_loss: 0.9918 - val_accuracy: 0.5118\n",
      "Epoch 212/500\n",
      "5063/5063 [==============================] - 1s 134us/sample - loss: 0.9724 - accuracy: 0.5368 - val_loss: 0.9929 - val_accuracy: 0.5126\n",
      "Epoch 213/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9726 - accuracy: 0.5370 - val_loss: 0.9902 - val_accuracy: 0.5134\n",
      "Epoch 214/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9725 - accuracy: 0.5380 - val_loss: 0.9904 - val_accuracy: 0.5118\n",
      "Epoch 215/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9722 - accuracy: 0.5376 - val_loss: 0.9919 - val_accuracy: 0.5118\n",
      "Epoch 216/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9722 - accuracy: 0.5384 - val_loss: 0.9898 - val_accuracy: 0.5134\n",
      "Epoch 217/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9725 - accuracy: 0.5358 - val_loss: 0.9904 - val_accuracy: 0.5118\n",
      "Epoch 218/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9723 - accuracy: 0.5368 - val_loss: 0.9896 - val_accuracy: 0.5134\n",
      "Epoch 219/500\n",
      "5063/5063 [==============================] - 0s 96us/sample - loss: 0.9722 - accuracy: 0.5358 - val_loss: 0.9913 - val_accuracy: 0.5126\n",
      "Epoch 220/500\n",
      "5063/5063 [==============================] - 1s 112us/sample - loss: 0.9721 - accuracy: 0.5370 - val_loss: 0.9897 - val_accuracy: 0.5118\n",
      "Epoch 221/500\n",
      "5063/5063 [==============================] - 1s 112us/sample - loss: 0.9718 - accuracy: 0.5386 - val_loss: 0.9900 - val_accuracy: 0.5134\n",
      "Epoch 222/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9715 - accuracy: 0.5368 - val_loss: 0.9903 - val_accuracy: 0.5063\n",
      "Epoch 223/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9720 - accuracy: 0.5349 - val_loss: 0.9906 - val_accuracy: 0.5111\n",
      "Epoch 224/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9719 - accuracy: 0.5366 - val_loss: 0.9894 - val_accuracy: 0.5103\n",
      "Epoch 225/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9719 - accuracy: 0.5351 - val_loss: 0.9903 - val_accuracy: 0.5126\n",
      "Epoch 226/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9719 - accuracy: 0.5388 - val_loss: 0.9901 - val_accuracy: 0.5142\n",
      "Epoch 227/500\n",
      "5063/5063 [==============================] - 0s 96us/sample - loss: 0.9715 - accuracy: 0.5366 - val_loss: 0.9894 - val_accuracy: 0.5103\n",
      "Epoch 228/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9716 - accuracy: 0.5368 - val_loss: 0.9926 - val_accuracy: 0.5103\n",
      "Epoch 229/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9715 - accuracy: 0.5402 - val_loss: 0.9902 - val_accuracy: 0.5111\n",
      "Epoch 230/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9715 - accuracy: 0.5351 - val_loss: 0.9893 - val_accuracy: 0.5055\n",
      "Epoch 231/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9714 - accuracy: 0.5364 - val_loss: 0.9933 - val_accuracy: 0.5126\n",
      "Epoch 232/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9712 - accuracy: 0.5360 - val_loss: 0.9915 - val_accuracy: 0.5134\n",
      "Epoch 233/500\n",
      "5063/5063 [==============================] - 0s 96us/sample - loss: 0.9713 - accuracy: 0.5370 - val_loss: 0.9896 - val_accuracy: 0.5142\n",
      "Epoch 234/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9714 - accuracy: 0.5366 - val_loss: 0.9892 - val_accuracy: 0.5079\n",
      "Epoch 235/500\n",
      "5063/5063 [==============================] - 0s 95us/sample - loss: 0.9715 - accuracy: 0.5374 - val_loss: 0.9908 - val_accuracy: 0.5150\n",
      "Epoch 236/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9712 - accuracy: 0.5372 - val_loss: 0.9909 - val_accuracy: 0.5142\n",
      "Epoch 237/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9715 - accuracy: 0.5370 - val_loss: 0.9896 - val_accuracy: 0.5142\n",
      "Epoch 238/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9711 - accuracy: 0.5368 - val_loss: 0.9913 - val_accuracy: 0.5103\n",
      "Epoch 239/500\n",
      "5063/5063 [==============================] - 0s 96us/sample - loss: 0.9712 - accuracy: 0.5372 - val_loss: 0.9892 - val_accuracy: 0.5126\n",
      "Epoch 240/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9707 - accuracy: 0.5364 - val_loss: 0.9905 - val_accuracy: 0.5134\n",
      "Epoch 241/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9712 - accuracy: 0.5360 - val_loss: 0.9890 - val_accuracy: 0.5103\n",
      "Epoch 242/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9709 - accuracy: 0.5358 - val_loss: 0.9891 - val_accuracy: 0.5071\n",
      "Epoch 243/500\n",
      "5063/5063 [==============================] - 0s 96us/sample - loss: 0.9709 - accuracy: 0.5398 - val_loss: 0.9891 - val_accuracy: 0.5071\n",
      "Epoch 244/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9707 - accuracy: 0.5386 - val_loss: 0.9887 - val_accuracy: 0.5142\n",
      "Epoch 245/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9706 - accuracy: 0.5374 - val_loss: 0.9885 - val_accuracy: 0.5103\n",
      "Epoch 246/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9703 - accuracy: 0.5384 - val_loss: 0.9915 - val_accuracy: 0.5103\n",
      "Epoch 247/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9707 - accuracy: 0.5378 - val_loss: 0.9899 - val_accuracy: 0.5142\n",
      "Epoch 248/500\n",
      "5063/5063 [==============================] - 1s 144us/sample - loss: 0.9709 - accuracy: 0.5382 - val_loss: 0.9900 - val_accuracy: 0.5134\n",
      "Epoch 249/500\n",
      "5063/5063 [==============================] - 1s 123us/sample - loss: 0.9707 - accuracy: 0.5368 - val_loss: 0.9889 - val_accuracy: 0.5142\n",
      "Epoch 250/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9707 - accuracy: 0.5349 - val_loss: 0.9897 - val_accuracy: 0.5126\n",
      "Epoch 251/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9703 - accuracy: 0.5366 - val_loss: 0.9912 - val_accuracy: 0.5095\n",
      "Epoch 252/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9700 - accuracy: 0.5370 - val_loss: 0.9889 - val_accuracy: 0.5126\n",
      "Epoch 253/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9701 - accuracy: 0.5347 - val_loss: 0.9901 - val_accuracy: 0.5126\n",
      "Epoch 254/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9698 - accuracy: 0.5398 - val_loss: 0.9926 - val_accuracy: 0.5118\n",
      "Epoch 255/500\n",
      "5063/5063 [==============================] - 1s 108us/sample - loss: 0.9704 - accuracy: 0.5408 - val_loss: 0.9900 - val_accuracy: 0.5118\n",
      "Epoch 256/500\n",
      "5063/5063 [==============================] - 1s 131us/sample - loss: 0.9704 - accuracy: 0.5362 - val_loss: 0.9892 - val_accuracy: 0.5134\n",
      "Epoch 257/500\n",
      "5063/5063 [==============================] - 1s 145us/sample - loss: 0.9703 - accuracy: 0.5378 - val_loss: 0.9882 - val_accuracy: 0.5103\n",
      "Epoch 258/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9701 - accuracy: 0.5358 - val_loss: 0.9886 - val_accuracy: 0.5134\n",
      "Epoch 259/500\n",
      "5063/5063 [==============================] - 1s 130us/sample - loss: 0.9702 - accuracy: 0.5380 - val_loss: 0.9913 - val_accuracy: 0.5103\n",
      "Epoch 260/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9703 - accuracy: 0.5374 - val_loss: 0.9882 - val_accuracy: 0.5150\n",
      "Epoch 261/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 0.9698 - accuracy: 0.5360 - val_loss: 0.9913 - val_accuracy: 0.5103\n",
      "Epoch 262/500\n",
      "5063/5063 [==============================] - 1s 131us/sample - loss: 0.9702 - accuracy: 0.5394 - val_loss: 0.9878 - val_accuracy: 0.5103\n",
      "Epoch 263/500\n",
      "5063/5063 [==============================] - 1s 144us/sample - loss: 0.9699 - accuracy: 0.5368 - val_loss: 0.9884 - val_accuracy: 0.5126\n",
      "Epoch 264/500\n",
      "5063/5063 [==============================] - 1s 108us/sample - loss: 0.9698 - accuracy: 0.5372 - val_loss: 0.9908 - val_accuracy: 0.5118\n",
      "Epoch 265/500\n",
      "5063/5063 [==============================] - 1s 143us/sample - loss: 0.9696 - accuracy: 0.5372 - val_loss: 0.9903 - val_accuracy: 0.5118\n",
      "Epoch 266/500\n",
      "5063/5063 [==============================] - 1s 149us/sample - loss: 0.9700 - accuracy: 0.5372 - val_loss: 0.9886 - val_accuracy: 0.5118\n",
      "Epoch 267/500\n",
      "5063/5063 [==============================] - 1s 141us/sample - loss: 0.9697 - accuracy: 0.5396 - val_loss: 0.9881 - val_accuracy: 0.5095\n",
      "Epoch 268/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9694 - accuracy: 0.5362 - val_loss: 0.9919 - val_accuracy: 0.5126\n",
      "Epoch 269/500\n",
      "5063/5063 [==============================] - 1s 141us/sample - loss: 0.9695 - accuracy: 0.5386 - val_loss: 0.9878 - val_accuracy: 0.5111\n",
      "Epoch 270/500\n",
      "5063/5063 [==============================] - 1s 131us/sample - loss: 0.9693 - accuracy: 0.5384 - val_loss: 0.9882 - val_accuracy: 0.5134\n",
      "Epoch 271/500\n",
      "5063/5063 [==============================] - 1s 160us/sample - loss: 0.9695 - accuracy: 0.5370 - val_loss: 0.9878 - val_accuracy: 0.5087\n",
      "Epoch 272/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5063/5063 [==============================] - 1s 137us/sample - loss: 0.9696 - accuracy: 0.5366 - val_loss: 0.9891 - val_accuracy: 0.5134\n",
      "Epoch 273/500\n",
      "5063/5063 [==============================] - 1s 144us/sample - loss: 0.9696 - accuracy: 0.5368 - val_loss: 0.9904 - val_accuracy: 0.5103\n",
      "Epoch 274/500\n",
      "5063/5063 [==============================] - 1s 148us/sample - loss: 0.9696 - accuracy: 0.5392 - val_loss: 0.9880 - val_accuracy: 0.5150\n",
      "Epoch 275/500\n",
      "5063/5063 [==============================] - 1s 133us/sample - loss: 0.9697 - accuracy: 0.5368 - val_loss: 0.9882 - val_accuracy: 0.5150\n",
      "Epoch 276/500\n",
      "5063/5063 [==============================] - 1s 141us/sample - loss: 0.9688 - accuracy: 0.5390 - val_loss: 0.9922 - val_accuracy: 0.5103\n",
      "Epoch 277/500\n",
      "5063/5063 [==============================] - 1s 143us/sample - loss: 0.9696 - accuracy: 0.5380 - val_loss: 0.9878 - val_accuracy: 0.5134\n",
      "Epoch 278/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9693 - accuracy: 0.5380 - val_loss: 0.9889 - val_accuracy: 0.5126\n",
      "Epoch 279/500\n",
      "5063/5063 [==============================] - 1s 114us/sample - loss: 0.9693 - accuracy: 0.5380 - val_loss: 0.9884 - val_accuracy: 0.5126\n",
      "Epoch 280/500\n",
      "5063/5063 [==============================] - 1s 153us/sample - loss: 0.9689 - accuracy: 0.5396 - val_loss: 0.9889 - val_accuracy: 0.5118\n",
      "Epoch 281/500\n",
      "5063/5063 [==============================] - 1s 126us/sample - loss: 0.9693 - accuracy: 0.5378 - val_loss: 0.9885 - val_accuracy: 0.5134\n",
      "Epoch 282/500\n",
      "5063/5063 [==============================] - 1s 134us/sample - loss: 0.9689 - accuracy: 0.5360 - val_loss: 0.9878 - val_accuracy: 0.5134\n",
      "Epoch 283/500\n",
      "5063/5063 [==============================] - 1s 165us/sample - loss: 0.9695 - accuracy: 0.5384 - val_loss: 0.9885 - val_accuracy: 0.5126\n",
      "Epoch 284/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9691 - accuracy: 0.5386 - val_loss: 0.9881 - val_accuracy: 0.5150\n",
      "Epoch 285/500\n",
      "5063/5063 [==============================] - 1s 146us/sample - loss: 0.9684 - accuracy: 0.5392 - val_loss: 0.9899 - val_accuracy: 0.5063\n",
      "Epoch 286/500\n",
      "5063/5063 [==============================] - 1s 122us/sample - loss: 0.9694 - accuracy: 0.5358 - val_loss: 0.9875 - val_accuracy: 0.5118\n",
      "Epoch 287/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9687 - accuracy: 0.5358 - val_loss: 0.9886 - val_accuracy: 0.5118\n",
      "Epoch 288/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9690 - accuracy: 0.5398 - val_loss: 0.9876 - val_accuracy: 0.5103\n",
      "Epoch 289/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9691 - accuracy: 0.5372 - val_loss: 0.9880 - val_accuracy: 0.5142\n",
      "Epoch 290/500\n",
      "5063/5063 [==============================] - 1s 108us/sample - loss: 0.9688 - accuracy: 0.5386 - val_loss: 0.9876 - val_accuracy: 0.5103\n",
      "Epoch 291/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9687 - accuracy: 0.5378 - val_loss: 0.9879 - val_accuracy: 0.5063\n",
      "Epoch 292/500\n",
      "5063/5063 [==============================] - 1s 108us/sample - loss: 0.9691 - accuracy: 0.5384 - val_loss: 0.9878 - val_accuracy: 0.5142\n",
      "Epoch 293/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9687 - accuracy: 0.5390 - val_loss: 0.9874 - val_accuracy: 0.5095\n",
      "Epoch 294/500\n",
      "5063/5063 [==============================] - 1s 108us/sample - loss: 0.9689 - accuracy: 0.5396 - val_loss: 0.9875 - val_accuracy: 0.5095\n",
      "Epoch 295/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9689 - accuracy: 0.5388 - val_loss: 0.9883 - val_accuracy: 0.5118\n",
      "Epoch 296/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9687 - accuracy: 0.5372 - val_loss: 0.9877 - val_accuracy: 0.5142\n",
      "Epoch 297/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9686 - accuracy: 0.5378 - val_loss: 0.9900 - val_accuracy: 0.5095\n",
      "Epoch 298/500\n",
      "5063/5063 [==============================] - 1s 108us/sample - loss: 0.9683 - accuracy: 0.5396 - val_loss: 0.9870 - val_accuracy: 0.5111\n",
      "Epoch 299/500\n",
      "5063/5063 [==============================] - 1s 114us/sample - loss: 0.9685 - accuracy: 0.5355 - val_loss: 0.9871 - val_accuracy: 0.5134\n",
      "Epoch 300/500\n",
      "5063/5063 [==============================] - 1s 109us/sample - loss: 0.9684 - accuracy: 0.5386 - val_loss: 0.9888 - val_accuracy: 0.5118\n",
      "Epoch 301/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9684 - accuracy: 0.5368 - val_loss: 0.9877 - val_accuracy: 0.5134\n",
      "Epoch 302/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9684 - accuracy: 0.5410 - val_loss: 0.9878 - val_accuracy: 0.5126\n",
      "Epoch 303/500\n",
      "5063/5063 [==============================] - 1s 125us/sample - loss: 0.9683 - accuracy: 0.5392 - val_loss: 0.9875 - val_accuracy: 0.5142\n",
      "Epoch 304/500\n",
      "5063/5063 [==============================] - 1s 160us/sample - loss: 0.9683 - accuracy: 0.5394 - val_loss: 0.9878 - val_accuracy: 0.5142\n",
      "Epoch 305/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9681 - accuracy: 0.5366 - val_loss: 0.9878 - val_accuracy: 0.5126\n",
      "Epoch 306/500\n",
      "5063/5063 [==============================] - 1s 140us/sample - loss: 0.9678 - accuracy: 0.5376 - val_loss: 0.9869 - val_accuracy: 0.5055\n",
      "Epoch 307/500\n",
      "5063/5063 [==============================] - 1s 130us/sample - loss: 0.9681 - accuracy: 0.5404 - val_loss: 0.9884 - val_accuracy: 0.5111\n",
      "Epoch 308/500\n",
      "5063/5063 [==============================] - 1s 116us/sample - loss: 0.9681 - accuracy: 0.5386 - val_loss: 0.9871 - val_accuracy: 0.5142\n",
      "Epoch 309/500\n",
      "5063/5063 [==============================] - 1s 112us/sample - loss: 0.9678 - accuracy: 0.5410 - val_loss: 0.9873 - val_accuracy: 0.5079\n",
      "Epoch 310/500\n",
      "5063/5063 [==============================] - 1s 126us/sample - loss: 0.9682 - accuracy: 0.5376 - val_loss: 0.9875 - val_accuracy: 0.5126\n",
      "Epoch 311/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9681 - accuracy: 0.5376 - val_loss: 0.9865 - val_accuracy: 0.5150\n",
      "Epoch 312/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9682 - accuracy: 0.5386 - val_loss: 0.9864 - val_accuracy: 0.5134\n",
      "Epoch 313/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9681 - accuracy: 0.5404 - val_loss: 0.9873 - val_accuracy: 0.5126\n",
      "Epoch 314/500\n",
      "5063/5063 [==============================] - 1s 114us/sample - loss: 0.9680 - accuracy: 0.5366 - val_loss: 0.9874 - val_accuracy: 0.5126\n",
      "Epoch 315/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9677 - accuracy: 0.5390 - val_loss: 0.9867 - val_accuracy: 0.5126\n",
      "Epoch 316/500\n",
      "5063/5063 [==============================] - 1s 138us/sample - loss: 0.9676 - accuracy: 0.5392 - val_loss: 0.9892 - val_accuracy: 0.5103\n",
      "Epoch 317/500\n",
      "5063/5063 [==============================] - 1s 124us/sample - loss: 0.9678 - accuracy: 0.5378 - val_loss: 0.9909 - val_accuracy: 0.5071\n",
      "Epoch 318/500\n",
      "5063/5063 [==============================] - 1s 114us/sample - loss: 0.9682 - accuracy: 0.5380 - val_loss: 0.9891 - val_accuracy: 0.5103\n",
      "Epoch 319/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9675 - accuracy: 0.5392 - val_loss: 0.9867 - val_accuracy: 0.5126\n",
      "Epoch 320/500\n",
      "5063/5063 [==============================] - 1s 134us/sample - loss: 0.9674 - accuracy: 0.5376 - val_loss: 0.9868 - val_accuracy: 0.5118\n",
      "Epoch 321/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9678 - accuracy: 0.5384 - val_loss: 0.9873 - val_accuracy: 0.5142\n",
      "Epoch 322/500\n",
      "5063/5063 [==============================] - 1s 129us/sample - loss: 0.9678 - accuracy: 0.5402 - val_loss: 0.9868 - val_accuracy: 0.5134\n",
      "Epoch 323/500\n",
      "5063/5063 [==============================] - 1s 121us/sample - loss: 0.9676 - accuracy: 0.5372 - val_loss: 0.9869 - val_accuracy: 0.5142\n",
      "Epoch 324/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9672 - accuracy: 0.5406 - val_loss: 0.9864 - val_accuracy: 0.5134\n",
      "Epoch 325/500\n",
      "5063/5063 [==============================] - 1s 134us/sample - loss: 0.9666 - accuracy: 0.5412 - val_loss: 0.9919 - val_accuracy: 0.5071\n",
      "Epoch 326/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5063/5063 [==============================] - 1s 121us/sample - loss: 0.9674 - accuracy: 0.5398 - val_loss: 0.9866 - val_accuracy: 0.5118\n",
      "Epoch 327/500\n",
      "5063/5063 [==============================] - 1s 124us/sample - loss: 0.9675 - accuracy: 0.5366 - val_loss: 0.9870 - val_accuracy: 0.5142\n",
      "Epoch 328/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9676 - accuracy: 0.5388 - val_loss: 0.9866 - val_accuracy: 0.5118\n",
      "Epoch 329/500\n",
      "5063/5063 [==============================] - 1s 124us/sample - loss: 0.9676 - accuracy: 0.5380 - val_loss: 0.9865 - val_accuracy: 0.5142\n",
      "Epoch 330/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9672 - accuracy: 0.5396 - val_loss: 0.9907 - val_accuracy: 0.5079\n",
      "Epoch 331/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9676 - accuracy: 0.5394 - val_loss: 0.9862 - val_accuracy: 0.5126\n",
      "Epoch 332/500\n",
      "5063/5063 [==============================] - 1s 124us/sample - loss: 0.9669 - accuracy: 0.5386 - val_loss: 0.9905 - val_accuracy: 0.5071\n",
      "Epoch 333/500\n",
      "5063/5063 [==============================] - 1s 109us/sample - loss: 0.9676 - accuracy: 0.5396 - val_loss: 0.9874 - val_accuracy: 0.5134\n",
      "Epoch 334/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9673 - accuracy: 0.5378 - val_loss: 0.9888 - val_accuracy: 0.5103\n",
      "Epoch 335/500\n",
      "5063/5063 [==============================] - 1s 187us/sample - loss: 0.9673 - accuracy: 0.5394 - val_loss: 0.9873 - val_accuracy: 0.5126\n",
      "Epoch 336/500\n",
      "5063/5063 [==============================] - 1s 135us/sample - loss: 0.9670 - accuracy: 0.5426 - val_loss: 0.9861 - val_accuracy: 0.5142\n",
      "Epoch 337/500\n",
      "5063/5063 [==============================] - 1s 159us/sample - loss: 0.9673 - accuracy: 0.5378 - val_loss: 0.9868 - val_accuracy: 0.5134\n",
      "Epoch 338/500\n",
      "5063/5063 [==============================] - 1s 114us/sample - loss: 0.9671 - accuracy: 0.5390 - val_loss: 0.9863 - val_accuracy: 0.5142\n",
      "Epoch 339/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9671 - accuracy: 0.5384 - val_loss: 0.9896 - val_accuracy: 0.5095\n",
      "Epoch 340/500\n",
      "5063/5063 [==============================] - 1s 114us/sample - loss: 0.9665 - accuracy: 0.5416 - val_loss: 0.9908 - val_accuracy: 0.5079\n",
      "Epoch 341/500\n",
      "5063/5063 [==============================] - 1s 126us/sample - loss: 0.9674 - accuracy: 0.5394 - val_loss: 0.9882 - val_accuracy: 0.5118\n",
      "Epoch 342/500\n",
      "5063/5063 [==============================] - 1s 109us/sample - loss: 0.9669 - accuracy: 0.5398 - val_loss: 0.9860 - val_accuracy: 0.5134\n",
      "Epoch 343/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9668 - accuracy: 0.5400 - val_loss: 0.9866 - val_accuracy: 0.5142\n",
      "Epoch 344/500\n",
      "5063/5063 [==============================] - 1s 127us/sample - loss: 0.9669 - accuracy: 0.5400 - val_loss: 0.9898 - val_accuracy: 0.5087\n",
      "Epoch 345/500\n",
      "5063/5063 [==============================] - 1s 127us/sample - loss: 0.9668 - accuracy: 0.5380 - val_loss: 0.9907 - val_accuracy: 0.5071\n",
      "Epoch 346/500\n",
      "5063/5063 [==============================] - 1s 140us/sample - loss: 0.9670 - accuracy: 0.5376 - val_loss: 0.9864 - val_accuracy: 0.5150\n",
      "Epoch 347/500\n",
      "5063/5063 [==============================] - 1s 151us/sample - loss: 0.9668 - accuracy: 0.5390 - val_loss: 0.9868 - val_accuracy: 0.5142\n",
      "Epoch 348/500\n",
      "5063/5063 [==============================] - 1s 122us/sample - loss: 0.9666 - accuracy: 0.5396 - val_loss: 0.9873 - val_accuracy: 0.5118\n",
      "Epoch 349/500\n",
      "5063/5063 [==============================] - 1s 133us/sample - loss: 0.9666 - accuracy: 0.5398 - val_loss: 0.9886 - val_accuracy: 0.5111\n",
      "Epoch 350/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9665 - accuracy: 0.5380 - val_loss: 0.9875 - val_accuracy: 0.5087\n",
      "Epoch 351/500\n",
      "5063/5063 [==============================] - 1s 128us/sample - loss: 0.9667 - accuracy: 0.5414 - val_loss: 0.9863 - val_accuracy: 0.5150\n",
      "Epoch 352/500\n",
      "5063/5063 [==============================] - 1s 125us/sample - loss: 0.9667 - accuracy: 0.5376 - val_loss: 0.9876 - val_accuracy: 0.5103\n",
      "Epoch 353/500\n",
      "5063/5063 [==============================] - 1s 149us/sample - loss: 0.9667 - accuracy: 0.5414 - val_loss: 0.9855 - val_accuracy: 0.5134\n",
      "Epoch 354/500\n",
      "5063/5063 [==============================] - 1s 155us/sample - loss: 0.9664 - accuracy: 0.5410 - val_loss: 0.9856 - val_accuracy: 0.5142\n",
      "Epoch 355/500\n",
      "5063/5063 [==============================] - 1s 130us/sample - loss: 0.9662 - accuracy: 0.5400 - val_loss: 0.9871 - val_accuracy: 0.5087\n",
      "Epoch 356/500\n",
      "5063/5063 [==============================] - 1s 139us/sample - loss: 0.9665 - accuracy: 0.5382 - val_loss: 0.9874 - val_accuracy: 0.5111\n",
      "Epoch 357/500\n",
      "5063/5063 [==============================] - 1s 145us/sample - loss: 0.9665 - accuracy: 0.5396 - val_loss: 0.9853 - val_accuracy: 0.5134\n",
      "Epoch 358/500\n",
      "5063/5063 [==============================] - 1s 139us/sample - loss: 0.9665 - accuracy: 0.5380 - val_loss: 0.9930 - val_accuracy: 0.5047\n",
      "Epoch 359/500\n",
      "5063/5063 [==============================] - 1s 133us/sample - loss: 0.9666 - accuracy: 0.5400 - val_loss: 0.9881 - val_accuracy: 0.5126\n",
      "Epoch 360/500\n",
      "5063/5063 [==============================] - 1s 122us/sample - loss: 0.9664 - accuracy: 0.5394 - val_loss: 0.9859 - val_accuracy: 0.5142\n",
      "Epoch 361/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9663 - accuracy: 0.5386 - val_loss: 0.9858 - val_accuracy: 0.5087\n",
      "Epoch 362/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9664 - accuracy: 0.5380 - val_loss: 0.9855 - val_accuracy: 0.5134\n",
      "Epoch 363/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9664 - accuracy: 0.5374 - val_loss: 0.9879 - val_accuracy: 0.5118\n",
      "Epoch 364/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9664 - accuracy: 0.5400 - val_loss: 0.9902 - val_accuracy: 0.5087\n",
      "Epoch 365/500\n",
      "5063/5063 [==============================] - 1s 122us/sample - loss: 0.9661 - accuracy: 0.5412 - val_loss: 0.9862 - val_accuracy: 0.5134\n",
      "Epoch 366/500\n",
      "5063/5063 [==============================] - 1s 167us/sample - loss: 0.9663 - accuracy: 0.5390 - val_loss: 0.9864 - val_accuracy: 0.5126\n",
      "Epoch 367/500\n",
      "5063/5063 [==============================] - 1s 123us/sample - loss: 0.9661 - accuracy: 0.5394 - val_loss: 0.9861 - val_accuracy: 0.5134\n",
      "Epoch 368/500\n",
      "5063/5063 [==============================] - 1s 144us/sample - loss: 0.9658 - accuracy: 0.5408 - val_loss: 0.9864 - val_accuracy: 0.5095\n",
      "Epoch 369/500\n",
      "5063/5063 [==============================] - 1s 129us/sample - loss: 0.9663 - accuracy: 0.5420 - val_loss: 0.9862 - val_accuracy: 0.5134\n",
      "Epoch 370/500\n",
      "5063/5063 [==============================] - 1s 121us/sample - loss: 0.9660 - accuracy: 0.5408 - val_loss: 0.9862 - val_accuracy: 0.5126\n",
      "Epoch 371/500\n",
      "5063/5063 [==============================] - 1s 144us/sample - loss: 0.9657 - accuracy: 0.5390 - val_loss: 0.9880 - val_accuracy: 0.5118\n",
      "Epoch 372/500\n",
      "5063/5063 [==============================] - 1s 157us/sample - loss: 0.9659 - accuracy: 0.5392 - val_loss: 0.9865 - val_accuracy: 0.5126\n",
      "Epoch 373/500\n",
      "5063/5063 [==============================] - 1s 149us/sample - loss: 0.9657 - accuracy: 0.5408 - val_loss: 0.9890 - val_accuracy: 0.5103\n",
      "Epoch 374/500\n",
      "5063/5063 [==============================] - 1s 128us/sample - loss: 0.9661 - accuracy: 0.5398 - val_loss: 0.9862 - val_accuracy: 0.5134\n",
      "Epoch 375/500\n",
      "5063/5063 [==============================] - 1s 149us/sample - loss: 0.9655 - accuracy: 0.5392 - val_loss: 0.9894 - val_accuracy: 0.5087\n",
      "Epoch 376/500\n",
      "5063/5063 [==============================] - 1s 147us/sample - loss: 0.9658 - accuracy: 0.5386 - val_loss: 0.9921 - val_accuracy: 0.5055\n",
      "Epoch 377/500\n",
      "5063/5063 [==============================] - 1s 125us/sample - loss: 0.9659 - accuracy: 0.5382 - val_loss: 0.9882 - val_accuracy: 0.5111\n",
      "Epoch 378/500\n",
      "5063/5063 [==============================] - 1s 122us/sample - loss: 0.9659 - accuracy: 0.5404 - val_loss: 0.9854 - val_accuracy: 0.5134\n",
      "Epoch 379/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9657 - accuracy: 0.5414 - val_loss: 0.9854 - val_accuracy: 0.5142\n",
      "Epoch 380/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5063/5063 [==============================] - 1s 114us/sample - loss: 0.9657 - accuracy: 0.5388 - val_loss: 0.9853 - val_accuracy: 0.5150\n",
      "Epoch 381/500\n",
      "5063/5063 [==============================] - 1s 108us/sample - loss: 0.9655 - accuracy: 0.5384 - val_loss: 0.9857 - val_accuracy: 0.5150\n",
      "Epoch 382/500\n",
      "5063/5063 [==============================] - 0s 96us/sample - loss: 0.9655 - accuracy: 0.5402 - val_loss: 0.9866 - val_accuracy: 0.5118\n",
      "Epoch 383/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9656 - accuracy: 0.5439 - val_loss: 0.9895 - val_accuracy: 0.5071\n",
      "Epoch 384/500\n",
      "5063/5063 [==============================] - 1s 133us/sample - loss: 0.9660 - accuracy: 0.5388 - val_loss: 0.9870 - val_accuracy: 0.5118\n",
      "Epoch 385/500\n",
      "5063/5063 [==============================] - 1s 122us/sample - loss: 0.9654 - accuracy: 0.5398 - val_loss: 0.9859 - val_accuracy: 0.5134\n",
      "Epoch 386/500\n",
      "5063/5063 [==============================] - 1s 108us/sample - loss: 0.9655 - accuracy: 0.5408 - val_loss: 0.9889 - val_accuracy: 0.5079\n",
      "Epoch 387/500\n",
      "5063/5063 [==============================] - 1s 116us/sample - loss: 0.9656 - accuracy: 0.5392 - val_loss: 0.9850 - val_accuracy: 0.5142\n",
      "Epoch 388/500\n",
      "5063/5063 [==============================] - 1s 151us/sample - loss: 0.9654 - accuracy: 0.5392 - val_loss: 0.9866 - val_accuracy: 0.5126\n",
      "Epoch 389/500\n",
      "5063/5063 [==============================] - 1s 136us/sample - loss: 0.9654 - accuracy: 0.5396 - val_loss: 0.9887 - val_accuracy: 0.5095\n",
      "Epoch 390/500\n",
      "5063/5063 [==============================] - 1s 142us/sample - loss: 0.9654 - accuracy: 0.5396 - val_loss: 0.9854 - val_accuracy: 0.5134\n",
      "Epoch 391/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9655 - accuracy: 0.5394 - val_loss: 0.9851 - val_accuracy: 0.5142\n",
      "Epoch 392/500\n",
      "5063/5063 [==============================] - 1s 109us/sample - loss: 0.9653 - accuracy: 0.5370 - val_loss: 0.9874 - val_accuracy: 0.5126\n",
      "Epoch 393/500\n",
      "5063/5063 [==============================] - 1s 113us/sample - loss: 0.9653 - accuracy: 0.5428 - val_loss: 0.9857 - val_accuracy: 0.5118\n",
      "Epoch 394/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9652 - accuracy: 0.5396 - val_loss: 0.9852 - val_accuracy: 0.5103\n",
      "Epoch 395/500\n",
      "5063/5063 [==============================] - 1s 137us/sample - loss: 0.9655 - accuracy: 0.5394 - val_loss: 0.9853 - val_accuracy: 0.5142\n",
      "Epoch 396/500\n",
      "5063/5063 [==============================] - 1s 139us/sample - loss: 0.9656 - accuracy: 0.5414 - val_loss: 0.9856 - val_accuracy: 0.5150\n",
      "Epoch 397/500\n",
      "5063/5063 [==============================] - ETA: 0s - loss: 0.9671 - accuracy: 0.53 - 1s 132us/sample - loss: 0.9652 - accuracy: 0.5384 - val_loss: 0.9858 - val_accuracy: 0.5134\n",
      "Epoch 398/500\n",
      "5063/5063 [==============================] - 1s 116us/sample - loss: 0.9655 - accuracy: 0.5402 - val_loss: 0.9856 - val_accuracy: 0.5134\n",
      "Epoch 399/500\n",
      "5063/5063 [==============================] - 1s 141us/sample - loss: 0.9651 - accuracy: 0.5394 - val_loss: 0.9848 - val_accuracy: 0.5150\n",
      "Epoch 400/500\n",
      "5063/5063 [==============================] - 1s 149us/sample - loss: 0.9651 - accuracy: 0.5396 - val_loss: 0.9860 - val_accuracy: 0.5126\n",
      "Epoch 401/500\n",
      "5063/5063 [==============================] - 1s 129us/sample - loss: 0.9653 - accuracy: 0.5400 - val_loss: 0.9849 - val_accuracy: 0.5134\n",
      "Epoch 402/500\n",
      "5063/5063 [==============================] - 1s 150us/sample - loss: 0.9650 - accuracy: 0.5408 - val_loss: 0.9847 - val_accuracy: 0.5134\n",
      "Epoch 403/500\n",
      "5063/5063 [==============================] - 1s 123us/sample - loss: 0.9651 - accuracy: 0.5404 - val_loss: 0.9849 - val_accuracy: 0.5134\n",
      "Epoch 404/500\n",
      "5063/5063 [==============================] - 1s 129us/sample - loss: 0.9650 - accuracy: 0.5368 - val_loss: 0.9874 - val_accuracy: 0.5095\n",
      "Epoch 405/500\n",
      "5063/5063 [==============================] - 1s 151us/sample - loss: 0.9653 - accuracy: 0.5388 - val_loss: 0.9849 - val_accuracy: 0.5142\n",
      "Epoch 406/500\n",
      "5063/5063 [==============================] - 1s 149us/sample - loss: 0.9651 - accuracy: 0.5416 - val_loss: 0.9870 - val_accuracy: 0.5118\n",
      "Epoch 407/500\n",
      "5063/5063 [==============================] - 1s 142us/sample - loss: 0.9649 - accuracy: 0.5398 - val_loss: 0.9864 - val_accuracy: 0.5134\n",
      "Epoch 408/500\n",
      "5063/5063 [==============================] - 1s 127us/sample - loss: 0.9649 - accuracy: 0.5390 - val_loss: 0.9847 - val_accuracy: 0.5118\n",
      "Epoch 409/500\n",
      "5063/5063 [==============================] - 1s 126us/sample - loss: 0.9651 - accuracy: 0.5386 - val_loss: 0.9851 - val_accuracy: 0.5134\n",
      "Epoch 410/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9650 - accuracy: 0.5412 - val_loss: 0.9855 - val_accuracy: 0.5150\n",
      "Epoch 411/500\n",
      "5063/5063 [==============================] - 1s 163us/sample - loss: 0.9649 - accuracy: 0.5408 - val_loss: 0.9864 - val_accuracy: 0.5134\n",
      "Epoch 412/500\n",
      "5063/5063 [==============================] - 1s 124us/sample - loss: 0.9649 - accuracy: 0.5426 - val_loss: 0.9854 - val_accuracy: 0.5134\n",
      "Epoch 413/500\n",
      "5063/5063 [==============================] - 1s 125us/sample - loss: 0.9649 - accuracy: 0.5400 - val_loss: 0.9847 - val_accuracy: 0.5126\n",
      "Epoch 414/500\n",
      "5063/5063 [==============================] - 1s 132us/sample - loss: 0.9650 - accuracy: 0.5388 - val_loss: 0.9861 - val_accuracy: 0.5126\n",
      "Epoch 415/500\n",
      "5063/5063 [==============================] - 1s 130us/sample - loss: 0.9646 - accuracy: 0.5410 - val_loss: 0.9851 - val_accuracy: 0.5150\n",
      "Epoch 416/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9647 - accuracy: 0.5390 - val_loss: 0.9860 - val_accuracy: 0.5118\n",
      "Epoch 417/500\n",
      "5063/5063 [==============================] - 1s 131us/sample - loss: 0.9648 - accuracy: 0.5426 - val_loss: 0.9850 - val_accuracy: 0.5095\n",
      "Epoch 418/500\n",
      "5063/5063 [==============================] - 1s 151us/sample - loss: 0.9647 - accuracy: 0.5404 - val_loss: 0.9869 - val_accuracy: 0.5095\n",
      "Epoch 419/500\n",
      "5063/5063 [==============================] - 1s 122us/sample - loss: 0.9646 - accuracy: 0.5406 - val_loss: 0.9871 - val_accuracy: 0.5079\n",
      "Epoch 420/500\n",
      "5063/5063 [==============================] - 1s 167us/sample - loss: 0.9644 - accuracy: 0.5402 - val_loss: 0.9894 - val_accuracy: 0.5079\n",
      "Epoch 421/500\n",
      "5063/5063 [==============================] - 1s 125us/sample - loss: 0.9646 - accuracy: 0.5443 - val_loss: 0.9855 - val_accuracy: 0.5079\n",
      "Epoch 422/500\n",
      "5063/5063 [==============================] - 1s 143us/sample - loss: 0.9645 - accuracy: 0.5412 - val_loss: 0.9922 - val_accuracy: 0.5047\n",
      "Epoch 423/500\n",
      "5063/5063 [==============================] - 1s 140us/sample - loss: 0.9646 - accuracy: 0.5410 - val_loss: 0.9844 - val_accuracy: 0.5134\n",
      "Epoch 424/500\n",
      "5063/5063 [==============================] - 1s 129us/sample - loss: 0.9647 - accuracy: 0.5426 - val_loss: 0.9846 - val_accuracy: 0.5126\n",
      "Epoch 425/500\n",
      "5063/5063 [==============================] - 1s 141us/sample - loss: 0.9646 - accuracy: 0.5404 - val_loss: 0.9852 - val_accuracy: 0.5126\n",
      "Epoch 426/500\n",
      "5063/5063 [==============================] - 1s 144us/sample - loss: 0.9647 - accuracy: 0.5386 - val_loss: 0.9873 - val_accuracy: 0.5095\n",
      "Epoch 427/500\n",
      "5063/5063 [==============================] - 1s 134us/sample - loss: 0.9644 - accuracy: 0.5408 - val_loss: 0.9847 - val_accuracy: 0.5118\n",
      "Epoch 428/500\n",
      "5063/5063 [==============================] - 1s 145us/sample - loss: 0.9644 - accuracy: 0.5402 - val_loss: 0.9876 - val_accuracy: 0.5079\n",
      "Epoch 429/500\n",
      "5063/5063 [==============================] - 1s 128us/sample - loss: 0.9646 - accuracy: 0.5414 - val_loss: 0.9847 - val_accuracy: 0.5150\n",
      "Epoch 430/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9644 - accuracy: 0.5380 - val_loss: 0.9876 - val_accuracy: 0.5079\n",
      "Epoch 431/500\n",
      "5063/5063 [==============================] - 1s 121us/sample - loss: 0.9645 - accuracy: 0.5422 - val_loss: 0.9863 - val_accuracy: 0.5126\n",
      "Epoch 432/500\n",
      "5063/5063 [==============================] - 1s 125us/sample - loss: 0.9644 - accuracy: 0.5426 - val_loss: 0.9855 - val_accuracy: 0.5126\n",
      "Epoch 433/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9645 - accuracy: 0.5392 - val_loss: 0.9844 - val_accuracy: 0.5118\n",
      "Epoch 434/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5063/5063 [==============================] - 1s 128us/sample - loss: 0.9640 - accuracy: 0.5398 - val_loss: 0.9941 - val_accuracy: 0.5063\n",
      "Epoch 435/500\n",
      "5063/5063 [==============================] - 1s 121us/sample - loss: 0.9640 - accuracy: 0.5428 - val_loss: 0.9855 - val_accuracy: 0.5087\n",
      "Epoch 436/500\n",
      "5063/5063 [==============================] - 1s 121us/sample - loss: 0.9647 - accuracy: 0.5398 - val_loss: 0.9888 - val_accuracy: 0.5063\n",
      "Epoch 437/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9642 - accuracy: 0.5410 - val_loss: 0.9863 - val_accuracy: 0.5126\n",
      "Epoch 438/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9642 - accuracy: 0.5420 - val_loss: 0.9860 - val_accuracy: 0.5126\n",
      "Epoch 439/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9644 - accuracy: 0.5418 - val_loss: 0.9844 - val_accuracy: 0.5126\n",
      "Epoch 440/500\n",
      "5063/5063 [==============================] - 1s 109us/sample - loss: 0.9642 - accuracy: 0.5404 - val_loss: 0.9843 - val_accuracy: 0.5126\n",
      "Epoch 441/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9641 - accuracy: 0.5386 - val_loss: 0.9860 - val_accuracy: 0.5126\n",
      "Epoch 442/500\n",
      "5063/5063 [==============================] - 1s 121us/sample - loss: 0.9642 - accuracy: 0.5388 - val_loss: 0.9845 - val_accuracy: 0.5150\n",
      "Epoch 443/500\n",
      "5063/5063 [==============================] - 1s 137us/sample - loss: 0.9643 - accuracy: 0.5406 - val_loss: 0.9841 - val_accuracy: 0.5142\n",
      "Epoch 444/500\n",
      "5063/5063 [==============================] - 1s 149us/sample - loss: 0.9642 - accuracy: 0.5418 - val_loss: 0.9875 - val_accuracy: 0.5079\n",
      "Epoch 445/500\n",
      "5063/5063 [==============================] - 1s 156us/sample - loss: 0.9641 - accuracy: 0.5416 - val_loss: 0.9852 - val_accuracy: 0.5150\n",
      "Epoch 446/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9642 - accuracy: 0.5402 - val_loss: 0.9850 - val_accuracy: 0.5150\n",
      "Epoch 447/500\n",
      "5063/5063 [==============================] - 1s 131us/sample - loss: 0.9641 - accuracy: 0.5418 - val_loss: 0.9857 - val_accuracy: 0.5126\n",
      "Epoch 448/500\n",
      "5063/5063 [==============================] - 1s 123us/sample - loss: 0.9643 - accuracy: 0.5384 - val_loss: 0.9856 - val_accuracy: 0.5126\n",
      "Epoch 449/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9642 - accuracy: 0.5398 - val_loss: 0.9844 - val_accuracy: 0.5150\n",
      "Epoch 450/500\n",
      "5063/5063 [==============================] - 1s 172us/sample - loss: 0.9641 - accuracy: 0.5380 - val_loss: 0.9850 - val_accuracy: 0.5126\n",
      "Epoch 451/500\n",
      "5063/5063 [==============================] - 1s 140us/sample - loss: 0.9641 - accuracy: 0.5404 - val_loss: 0.9844 - val_accuracy: 0.5134\n",
      "Epoch 452/500\n",
      "5063/5063 [==============================] - 1s 134us/sample - loss: 0.9641 - accuracy: 0.5420 - val_loss: 0.9847 - val_accuracy: 0.5142\n",
      "Epoch 453/500\n",
      "5063/5063 [==============================] - 1s 121us/sample - loss: 0.9640 - accuracy: 0.5412 - val_loss: 0.9851 - val_accuracy: 0.5126\n",
      "Epoch 454/500\n",
      "5063/5063 [==============================] - 1s 127us/sample - loss: 0.9641 - accuracy: 0.5402 - val_loss: 0.9856 - val_accuracy: 0.5118\n",
      "Epoch 455/500\n",
      "5063/5063 [==============================] - 1s 128us/sample - loss: 0.9640 - accuracy: 0.5426 - val_loss: 0.9840 - val_accuracy: 0.5134\n",
      "Epoch 456/500\n",
      "5063/5063 [==============================] - 1s 130us/sample - loss: 0.9640 - accuracy: 0.5398 - val_loss: 0.9849 - val_accuracy: 0.5126\n",
      "Epoch 457/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9640 - accuracy: 0.5412 - val_loss: 0.9840 - val_accuracy: 0.5150\n",
      "Epoch 458/500\n",
      "5063/5063 [==============================] - 1s 114us/sample - loss: 0.9642 - accuracy: 0.5406 - val_loss: 0.9847 - val_accuracy: 0.5142\n",
      "Epoch 459/500\n",
      "5063/5063 [==============================] - 1s 122us/sample - loss: 0.9637 - accuracy: 0.5418 - val_loss: 0.9841 - val_accuracy: 0.5126\n",
      "Epoch 460/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9636 - accuracy: 0.5398 - val_loss: 0.9836 - val_accuracy: 0.5142\n",
      "Epoch 461/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9640 - accuracy: 0.5398 - val_loss: 0.9850 - val_accuracy: 0.5126\n",
      "Epoch 462/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9640 - accuracy: 0.5398 - val_loss: 0.9840 - val_accuracy: 0.5126\n",
      "Epoch 463/500\n",
      "5063/5063 [==============================] - 1s 131us/sample - loss: 0.9636 - accuracy: 0.5410 - val_loss: 0.9866 - val_accuracy: 0.5103\n",
      "Epoch 464/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9639 - accuracy: 0.5400 - val_loss: 0.9841 - val_accuracy: 0.5134\n",
      "Epoch 465/500\n",
      "5063/5063 [==============================] - 1s 112us/sample - loss: 0.9640 - accuracy: 0.5368 - val_loss: 0.9842 - val_accuracy: 0.5126\n",
      "Epoch 466/500\n",
      "5063/5063 [==============================] - 1s 127us/sample - loss: 0.9637 - accuracy: 0.5398 - val_loss: 0.9896 - val_accuracy: 0.5071\n",
      "Epoch 467/500\n",
      "5063/5063 [==============================] - 1s 128us/sample - loss: 0.9640 - accuracy: 0.5390 - val_loss: 0.9874 - val_accuracy: 0.5087\n",
      "Epoch 468/500\n",
      "5063/5063 [==============================] - 1s 109us/sample - loss: 0.9639 - accuracy: 0.5394 - val_loss: 0.9850 - val_accuracy: 0.5126\n",
      "Epoch 469/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9638 - accuracy: 0.5408 - val_loss: 0.9877 - val_accuracy: 0.5055\n",
      "Epoch 470/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9630 - accuracy: 0.5465 - val_loss: 0.9868 - val_accuracy: 0.5079\n",
      "Epoch 471/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9641 - accuracy: 0.5388 - val_loss: 0.9848 - val_accuracy: 0.5126\n",
      "Epoch 472/500\n",
      "5063/5063 [==============================] - 1s 116us/sample - loss: 0.9637 - accuracy: 0.5374 - val_loss: 0.9849 - val_accuracy: 0.5118\n",
      "Epoch 473/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9632 - accuracy: 0.5394 - val_loss: 0.9836 - val_accuracy: 0.5142\n",
      "Epoch 474/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9634 - accuracy: 0.5426 - val_loss: 0.9855 - val_accuracy: 0.5118\n",
      "Epoch 475/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9637 - accuracy: 0.5396 - val_loss: 0.9858 - val_accuracy: 0.5134\n",
      "Epoch 476/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9633 - accuracy: 0.5414 - val_loss: 0.9862 - val_accuracy: 0.5103\n",
      "Epoch 477/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9637 - accuracy: 0.5412 - val_loss: 0.9854 - val_accuracy: 0.5126\n",
      "Epoch 478/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9634 - accuracy: 0.5428 - val_loss: 0.9840 - val_accuracy: 0.5142\n",
      "Epoch 479/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9637 - accuracy: 0.5412 - val_loss: 0.9850 - val_accuracy: 0.5126\n",
      "Epoch 480/500\n",
      "5063/5063 [==============================] - 1s 122us/sample - loss: 0.9637 - accuracy: 0.5400 - val_loss: 0.9845 - val_accuracy: 0.5134\n",
      "Epoch 481/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9636 - accuracy: 0.5418 - val_loss: 0.9859 - val_accuracy: 0.5118\n",
      "Epoch 482/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9632 - accuracy: 0.5426 - val_loss: 0.9864 - val_accuracy: 0.5103\n",
      "Epoch 483/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9634 - accuracy: 0.5408 - val_loss: 0.9871 - val_accuracy: 0.5063\n",
      "Epoch 484/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9634 - accuracy: 0.5410 - val_loss: 0.9838 - val_accuracy: 0.5166\n",
      "Epoch 485/500\n",
      "5063/5063 [==============================] - 1s 116us/sample - loss: 0.9635 - accuracy: 0.5402 - val_loss: 0.9846 - val_accuracy: 0.5118\n",
      "Epoch 486/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9634 - accuracy: 0.5406 - val_loss: 0.9850 - val_accuracy: 0.5126\n",
      "Epoch 487/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9634 - accuracy: 0.5420 - val_loss: 0.9839 - val_accuracy: 0.5134\n",
      "Epoch 488/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5063/5063 [==============================] - 1s 113us/sample - loss: 0.9633 - accuracy: 0.5412 - val_loss: 0.9843 - val_accuracy: 0.5118\n",
      "Epoch 489/500\n",
      "5063/5063 [==============================] - 1s 114us/sample - loss: 0.9633 - accuracy: 0.5412 - val_loss: 0.9862 - val_accuracy: 0.5103\n",
      "Epoch 490/500\n",
      "5063/5063 [==============================] - 1s 163us/sample - loss: 0.9634 - accuracy: 0.5416 - val_loss: 0.9839 - val_accuracy: 0.5150\n",
      "Epoch 491/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9633 - accuracy: 0.5428 - val_loss: 0.9850 - val_accuracy: 0.5126\n",
      "Epoch 492/500\n",
      "5063/5063 [==============================] - 1s 143us/sample - loss: 0.9634 - accuracy: 0.5418 - val_loss: 0.9849 - val_accuracy: 0.5126\n",
      "Epoch 493/500\n",
      "5063/5063 [==============================] - 1s 136us/sample - loss: 0.9630 - accuracy: 0.5400 - val_loss: 0.9865 - val_accuracy: 0.5071\n",
      "Epoch 494/500\n",
      "5063/5063 [==============================] - 1s 121us/sample - loss: 0.9632 - accuracy: 0.5414 - val_loss: 0.9842 - val_accuracy: 0.5118\n",
      "Epoch 495/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9634 - accuracy: 0.5420 - val_loss: 0.9841 - val_accuracy: 0.5142\n",
      "Epoch 496/500\n",
      "5063/5063 [==============================] - 1s 109us/sample - loss: 0.9631 - accuracy: 0.5430 - val_loss: 0.9866 - val_accuracy: 0.5055\n",
      "Epoch 497/500\n",
      "5063/5063 [==============================] - 1s 131us/sample - loss: 0.9633 - accuracy: 0.5426 - val_loss: 0.9837 - val_accuracy: 0.5134\n",
      "Epoch 498/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9633 - accuracy: 0.5396 - val_loss: 0.9867 - val_accuracy: 0.5055\n",
      "Epoch 499/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9634 - accuracy: 0.5386 - val_loss: 0.9840 - val_accuracy: 0.5134\n",
      "Epoch 500/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9631 - accuracy: 0.5384 - val_loss: 0.9897 - val_accuracy: 0.5063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4f4d5b90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model02.fit(train_X02, train_y02, validation_split=validation_split,epochs=epochs,callbacks=[early_stoping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                1920      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 5,561\n",
      "Trainable params: 5,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model03.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5063 samples, validate on 1266 samples\n",
      "Epoch 1/500\n",
      "5063/5063 [==============================] - 2s 374us/sample - loss: 1.0742 - accuracy: 0.4484 - val_loss: 1.0623 - val_accuracy: 0.4645\n",
      "Epoch 2/500\n",
      "5063/5063 [==============================] - 1s 123us/sample - loss: 1.0613 - accuracy: 0.4584 - val_loss: 1.0574 - val_accuracy: 0.4645\n",
      "Epoch 3/500\n",
      "5063/5063 [==============================] - 1s 121us/sample - loss: 1.0579 - accuracy: 0.4584 - val_loss: 1.0563 - val_accuracy: 0.4645\n",
      "Epoch 4/500\n",
      "5063/5063 [==============================] - 1s 106us/sample - loss: 1.0540 - accuracy: 0.4584 - val_loss: 1.0510 - val_accuracy: 0.4645\n",
      "Epoch 5/500\n",
      "5063/5063 [==============================] - 1s 113us/sample - loss: 1.0502 - accuracy: 0.4584 - val_loss: 1.0456 - val_accuracy: 0.4645\n",
      "Epoch 6/500\n",
      "5063/5063 [==============================] - 1s 122us/sample - loss: 1.0457 - accuracy: 0.4584 - val_loss: 1.0405 - val_accuracy: 0.4645\n",
      "Epoch 7/500\n",
      "5063/5063 [==============================] - 1s 139us/sample - loss: 1.0406 - accuracy: 0.4584 - val_loss: 1.0332 - val_accuracy: 0.4645\n",
      "Epoch 8/500\n",
      "5063/5063 [==============================] - 1s 162us/sample - loss: 1.0339 - accuracy: 0.4584 - val_loss: 1.0352 - val_accuracy: 0.4645\n",
      "Epoch 9/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 1.0278 - accuracy: 0.4800 - val_loss: 1.0209 - val_accuracy: 0.4882\n",
      "Epoch 10/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 1.0220 - accuracy: 0.5023 - val_loss: 1.0152 - val_accuracy: 0.5134\n",
      "Epoch 11/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 1.0180 - accuracy: 0.5044 - val_loss: 1.0110 - val_accuracy: 0.5095\n",
      "Epoch 12/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 1.0154 - accuracy: 0.5070 - val_loss: 1.0112 - val_accuracy: 0.5055\n",
      "Epoch 13/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 1.0137 - accuracy: 0.5035 - val_loss: 1.0052 - val_accuracy: 0.5111\n",
      "Epoch 14/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 1.0115 - accuracy: 0.5100 - val_loss: 1.0039 - val_accuracy: 0.5134\n",
      "Epoch 15/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 1.0099 - accuracy: 0.5084 - val_loss: 1.0081 - val_accuracy: 0.5103\n",
      "Epoch 16/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 1.0085 - accuracy: 0.5119 - val_loss: 1.0003 - val_accuracy: 0.5126\n",
      "Epoch 17/500\n",
      "5063/5063 [==============================] - 1s 106us/sample - loss: 1.0074 - accuracy: 0.5125 - val_loss: 1.0001 - val_accuracy: 0.5103\n",
      "Epoch 18/500\n",
      "5063/5063 [==============================] - 1s 106us/sample - loss: 1.0057 - accuracy: 0.5133 - val_loss: 0.9990 - val_accuracy: 0.5103\n",
      "Epoch 19/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 1.0056 - accuracy: 0.5116 - val_loss: 0.9973 - val_accuracy: 0.5166\n",
      "Epoch 20/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 1.0047 - accuracy: 0.5135 - val_loss: 0.9971 - val_accuracy: 0.5182\n",
      "Epoch 21/500\n",
      "5063/5063 [==============================] - 1s 158us/sample - loss: 1.0042 - accuracy: 0.5131 - val_loss: 0.9963 - val_accuracy: 0.5158\n",
      "Epoch 22/500\n",
      "5063/5063 [==============================] - 1s 132us/sample - loss: 1.0034 - accuracy: 0.5121 - val_loss: 0.9952 - val_accuracy: 0.5150\n",
      "Epoch 23/500\n",
      "5063/5063 [==============================] - 1s 116us/sample - loss: 1.0025 - accuracy: 0.5173 - val_loss: 0.9938 - val_accuracy: 0.5182\n",
      "Epoch 24/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 1.0017 - accuracy: 0.5153 - val_loss: 0.9935 - val_accuracy: 0.5158\n",
      "Epoch 25/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 1.0009 - accuracy: 0.5161 - val_loss: 0.9925 - val_accuracy: 0.5166\n",
      "Epoch 26/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 1.0009 - accuracy: 0.5159 - val_loss: 0.9919 - val_accuracy: 0.5166\n",
      "Epoch 27/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9999 - accuracy: 0.5161 - val_loss: 0.9908 - val_accuracy: 0.5158\n",
      "Epoch 28/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9995 - accuracy: 0.5179 - val_loss: 0.9915 - val_accuracy: 0.5213\n",
      "Epoch 29/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9991 - accuracy: 0.5173 - val_loss: 0.9894 - val_accuracy: 0.5213\n",
      "Epoch 30/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9984 - accuracy: 0.5135 - val_loss: 0.9898 - val_accuracy: 0.5150\n",
      "Epoch 31/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9969 - accuracy: 0.5193 - val_loss: 0.9932 - val_accuracy: 0.5134\n",
      "Epoch 32/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 0.9972 - accuracy: 0.5169 - val_loss: 0.9888 - val_accuracy: 0.5166\n",
      "Epoch 33/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 0.9962 - accuracy: 0.5181 - val_loss: 0.9877 - val_accuracy: 0.5166\n",
      "Epoch 34/500\n",
      "5063/5063 [==============================] - 1s 106us/sample - loss: 0.9960 - accuracy: 0.5236 - val_loss: 0.9915 - val_accuracy: 0.5103\n",
      "Epoch 35/500\n",
      "5063/5063 [==============================] - 1s 106us/sample - loss: 0.9961 - accuracy: 0.5202 - val_loss: 0.9857 - val_accuracy: 0.5190\n",
      "Epoch 36/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9948 - accuracy: 0.5214 - val_loss: 0.9864 - val_accuracy: 0.5158\n",
      "Epoch 37/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9950 - accuracy: 0.5195 - val_loss: 0.9939 - val_accuracy: 0.5079\n",
      "Epoch 38/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9948 - accuracy: 0.5204 - val_loss: 0.9858 - val_accuracy: 0.5190\n",
      "Epoch 39/500\n",
      "5063/5063 [==============================] - 1s 160us/sample - loss: 0.9931 - accuracy: 0.5202 - val_loss: 0.9855 - val_accuracy: 0.5197\n",
      "Epoch 40/500\n",
      "5063/5063 [==============================] - 1s 144us/sample - loss: 0.9931 - accuracy: 0.5216 - val_loss: 0.9856 - val_accuracy: 0.5182\n",
      "Epoch 41/500\n",
      "5063/5063 [==============================] - 1s 175us/sample - loss: 0.9932 - accuracy: 0.5212 - val_loss: 0.9833 - val_accuracy: 0.5237\n",
      "Epoch 42/500\n",
      "5063/5063 [==============================] - 1s 141us/sample - loss: 0.9926 - accuracy: 0.5214 - val_loss: 0.9835 - val_accuracy: 0.5197\n",
      "Epoch 43/500\n",
      "5063/5063 [==============================] - 1s 127us/sample - loss: 0.9924 - accuracy: 0.5183 - val_loss: 0.9830 - val_accuracy: 0.5284\n",
      "Epoch 44/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9923 - accuracy: 0.5246 - val_loss: 0.9819 - val_accuracy: 0.5213\n",
      "Epoch 45/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9908 - accuracy: 0.5228 - val_loss: 0.9834 - val_accuracy: 0.5190\n",
      "Epoch 46/500\n",
      "5063/5063 [==============================] - 1s 141us/sample - loss: 0.9912 - accuracy: 0.5204 - val_loss: 0.9807 - val_accuracy: 0.5221\n",
      "Epoch 47/500\n",
      "5063/5063 [==============================] - 1s 168us/sample - loss: 0.9910 - accuracy: 0.5224 - val_loss: 0.9802 - val_accuracy: 0.5269\n",
      "Epoch 48/500\n",
      "5063/5063 [==============================] - 1s 165us/sample - loss: 0.9905 - accuracy: 0.5234 - val_loss: 0.9800 - val_accuracy: 0.5269\n",
      "Epoch 49/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9895 - accuracy: 0.5234 - val_loss: 0.9843 - val_accuracy: 0.5126\n",
      "Epoch 50/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9899 - accuracy: 0.5268 - val_loss: 0.9796 - val_accuracy: 0.5221\n",
      "Epoch 51/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9890 - accuracy: 0.5248 - val_loss: 0.9789 - val_accuracy: 0.5245\n",
      "Epoch 52/500\n",
      "5063/5063 [==============================] - 0s 99us/sample - loss: 0.9892 - accuracy: 0.5238 - val_loss: 0.9781 - val_accuracy: 0.5292\n",
      "Epoch 53/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9887 - accuracy: 0.5236 - val_loss: 0.9780 - val_accuracy: 0.5292\n",
      "Epoch 54/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9882 - accuracy: 0.5210 - val_loss: 0.9774 - val_accuracy: 0.5284\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9875 - accuracy: 0.5232 - val_loss: 0.9816 - val_accuracy: 0.5150\n",
      "Epoch 56/500\n",
      "5063/5063 [==============================] - 0s 96us/sample - loss: 0.9871 - accuracy: 0.5244 - val_loss: 0.9775 - val_accuracy: 0.5340\n",
      "Epoch 57/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9872 - accuracy: 0.5258 - val_loss: 0.9805 - val_accuracy: 0.5142\n",
      "Epoch 58/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9877 - accuracy: 0.5234 - val_loss: 0.9793 - val_accuracy: 0.5237\n",
      "Epoch 59/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9866 - accuracy: 0.5258 - val_loss: 0.9762 - val_accuracy: 0.5324\n",
      "Epoch 60/500\n",
      "5063/5063 [==============================] - 0s 96us/sample - loss: 0.9863 - accuracy: 0.5266 - val_loss: 0.9758 - val_accuracy: 0.5332\n",
      "Epoch 61/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9854 - accuracy: 0.5287 - val_loss: 0.9767 - val_accuracy: 0.5237\n",
      "Epoch 62/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9860 - accuracy: 0.5278 - val_loss: 0.9792 - val_accuracy: 0.5134\n",
      "Epoch 63/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9857 - accuracy: 0.5254 - val_loss: 0.9795 - val_accuracy: 0.5126\n",
      "Epoch 64/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9852 - accuracy: 0.5266 - val_loss: 0.9785 - val_accuracy: 0.5166\n",
      "Epoch 65/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9850 - accuracy: 0.5274 - val_loss: 0.9766 - val_accuracy: 0.5332\n",
      "Epoch 66/500\n",
      "5063/5063 [==============================] - 1s 101us/sample - loss: 0.9848 - accuracy: 0.5248 - val_loss: 0.9734 - val_accuracy: 0.5348\n",
      "Epoch 67/500\n",
      "5063/5063 [==============================] - 1s 134us/sample - loss: 0.9844 - accuracy: 0.5283 - val_loss: 0.9742 - val_accuracy: 0.5292\n",
      "Epoch 68/500\n",
      "5063/5063 [==============================] - 1s 157us/sample - loss: 0.9843 - accuracy: 0.5268 - val_loss: 0.9737 - val_accuracy: 0.5371\n",
      "Epoch 69/500\n",
      "5063/5063 [==============================] - 1s 116us/sample - loss: 0.9830 - accuracy: 0.5283 - val_loss: 0.9753 - val_accuracy: 0.5237\n",
      "Epoch 70/500\n",
      "5063/5063 [==============================] - 1s 182us/sample - loss: 0.9834 - accuracy: 0.5266 - val_loss: 0.9739 - val_accuracy: 0.5363\n",
      "Epoch 71/500\n",
      "5063/5063 [==============================] - 1s 145us/sample - loss: 0.9834 - accuracy: 0.5278 - val_loss: 0.9842 - val_accuracy: 0.5079\n",
      "Epoch 72/500\n",
      "5063/5063 [==============================] - 1s 126us/sample - loss: 0.9835 - accuracy: 0.5262 - val_loss: 0.9800 - val_accuracy: 0.5095\n",
      "Epoch 73/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9828 - accuracy: 0.5283 - val_loss: 0.9720 - val_accuracy: 0.5340\n",
      "Epoch 74/500\n",
      "5063/5063 [==============================] - 1s 149us/sample - loss: 0.9830 - accuracy: 0.5274 - val_loss: 0.9725 - val_accuracy: 0.5308\n",
      "Epoch 75/500\n",
      "5063/5063 [==============================] - 1s 122us/sample - loss: 0.9825 - accuracy: 0.5279 - val_loss: 0.9733 - val_accuracy: 0.5284\n",
      "Epoch 76/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9822 - accuracy: 0.5289 - val_loss: 0.9714 - val_accuracy: 0.5387\n",
      "Epoch 77/500\n",
      "5063/5063 [==============================] - 1s 156us/sample - loss: 0.9822 - accuracy: 0.5319 - val_loss: 0.9744 - val_accuracy: 0.5261\n",
      "Epoch 78/500\n",
      "5063/5063 [==============================] - 1s 129us/sample - loss: 0.9816 - accuracy: 0.5281 - val_loss: 0.9722 - val_accuracy: 0.5300\n",
      "Epoch 79/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 0.9815 - accuracy: 0.5289 - val_loss: 0.9710 - val_accuracy: 0.5316\n",
      "Epoch 80/500\n",
      "5063/5063 [==============================] - 1s 122us/sample - loss: 0.9813 - accuracy: 0.5305 - val_loss: 0.9742 - val_accuracy: 0.5261\n",
      "Epoch 81/500\n",
      "5063/5063 [==============================] - 1s 143us/sample - loss: 0.9812 - accuracy: 0.5289 - val_loss: 0.9702 - val_accuracy: 0.5395\n",
      "Epoch 82/500\n",
      "5063/5063 [==============================] - 1s 125us/sample - loss: 0.9812 - accuracy: 0.5297 - val_loss: 0.9704 - val_accuracy: 0.5300\n",
      "Epoch 83/500\n",
      "5063/5063 [==============================] - 1s 114us/sample - loss: 0.9812 - accuracy: 0.5279 - val_loss: 0.9707 - val_accuracy: 0.5324\n",
      "Epoch 84/500\n",
      "5063/5063 [==============================] - 1s 141us/sample - loss: 0.9808 - accuracy: 0.5295 - val_loss: 0.9697 - val_accuracy: 0.5308\n",
      "Epoch 85/500\n",
      "5063/5063 [==============================] - 1s 126us/sample - loss: 0.9804 - accuracy: 0.5270 - val_loss: 0.9692 - val_accuracy: 0.5355\n",
      "Epoch 86/500\n",
      "5063/5063 [==============================] - 1s 159us/sample - loss: 0.9807 - accuracy: 0.5278 - val_loss: 0.9723 - val_accuracy: 0.5284\n",
      "Epoch 87/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9805 - accuracy: 0.5293 - val_loss: 0.9689 - val_accuracy: 0.5395\n",
      "Epoch 88/500\n",
      "5063/5063 [==============================] - 1s 151us/sample - loss: 0.9795 - accuracy: 0.5293 - val_loss: 0.9695 - val_accuracy: 0.5419\n",
      "Epoch 89/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9795 - accuracy: 0.5327 - val_loss: 0.9690 - val_accuracy: 0.5332\n",
      "Epoch 90/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9798 - accuracy: 0.5293 - val_loss: 0.9705 - val_accuracy: 0.5316\n",
      "Epoch 91/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9786 - accuracy: 0.5311 - val_loss: 0.9694 - val_accuracy: 0.5434\n",
      "Epoch 92/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9796 - accuracy: 0.5287 - val_loss: 0.9714 - val_accuracy: 0.5379\n",
      "Epoch 93/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9792 - accuracy: 0.5285 - val_loss: 0.9678 - val_accuracy: 0.5355\n",
      "Epoch 94/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9799 - accuracy: 0.5313 - val_loss: 0.9720 - val_accuracy: 0.5261\n",
      "Epoch 95/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9794 - accuracy: 0.5291 - val_loss: 0.9897 - val_accuracy: 0.4992\n",
      "Epoch 96/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9791 - accuracy: 0.5317 - val_loss: 0.9691 - val_accuracy: 0.5427\n",
      "Epoch 97/500\n",
      "5063/5063 [==============================] - 1s 101us/sample - loss: 0.9785 - accuracy: 0.5331 - val_loss: 0.9676 - val_accuracy: 0.5355\n",
      "Epoch 98/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9791 - accuracy: 0.5317 - val_loss: 0.9681 - val_accuracy: 0.5324\n",
      "Epoch 99/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9787 - accuracy: 0.5333 - val_loss: 0.9683 - val_accuracy: 0.5324\n",
      "Epoch 100/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9787 - accuracy: 0.5285 - val_loss: 0.9670 - val_accuracy: 0.5363\n",
      "Epoch 101/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9781 - accuracy: 0.5327 - val_loss: 0.9668 - val_accuracy: 0.5363\n",
      "Epoch 102/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9780 - accuracy: 0.5331 - val_loss: 0.9681 - val_accuracy: 0.5332\n",
      "Epoch 103/500\n",
      "5063/5063 [==============================] - 1s 101us/sample - loss: 0.9785 - accuracy: 0.5321 - val_loss: 0.9670 - val_accuracy: 0.5403\n",
      "Epoch 104/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9782 - accuracy: 0.5307 - val_loss: 0.9667 - val_accuracy: 0.5403\n",
      "Epoch 105/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9779 - accuracy: 0.5305 - val_loss: 0.9665 - val_accuracy: 0.5363\n",
      "Epoch 106/500\n",
      "5063/5063 [==============================] - 1s 101us/sample - loss: 0.9778 - accuracy: 0.5295 - val_loss: 0.9674 - val_accuracy: 0.5442\n",
      "Epoch 107/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9778 - accuracy: 0.5309 - val_loss: 0.9670 - val_accuracy: 0.5332\n",
      "Epoch 108/500\n",
      "5063/5063 [==============================] - 0s 99us/sample - loss: 0.9774 - accuracy: 0.5313 - val_loss: 0.9679 - val_accuracy: 0.5316\n",
      "Epoch 109/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9775 - accuracy: 0.5313 - val_loss: 0.9723 - val_accuracy: 0.5245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9777 - accuracy: 0.5317 - val_loss: 0.9700 - val_accuracy: 0.5261\n",
      "Epoch 111/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9773 - accuracy: 0.5335 - val_loss: 0.9663 - val_accuracy: 0.5355\n",
      "Epoch 112/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9777 - accuracy: 0.5303 - val_loss: 0.9659 - val_accuracy: 0.5355\n",
      "Epoch 113/500\n",
      "5063/5063 [==============================] - 0s 99us/sample - loss: 0.9771 - accuracy: 0.5360 - val_loss: 0.9664 - val_accuracy: 0.5442\n",
      "Epoch 114/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9774 - accuracy: 0.5319 - val_loss: 0.9661 - val_accuracy: 0.5348\n",
      "Epoch 115/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9775 - accuracy: 0.5339 - val_loss: 0.9661 - val_accuracy: 0.5450\n",
      "Epoch 116/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9769 - accuracy: 0.5299 - val_loss: 0.9669 - val_accuracy: 0.5308\n",
      "Epoch 117/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9773 - accuracy: 0.5315 - val_loss: 0.9657 - val_accuracy: 0.5371\n",
      "Epoch 118/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9770 - accuracy: 0.5329 - val_loss: 0.9656 - val_accuracy: 0.5363\n",
      "Epoch 119/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9766 - accuracy: 0.5319 - val_loss: 0.9660 - val_accuracy: 0.5316\n",
      "Epoch 120/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9762 - accuracy: 0.5341 - val_loss: 0.9658 - val_accuracy: 0.5324\n",
      "Epoch 121/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9770 - accuracy: 0.5297 - val_loss: 0.9699 - val_accuracy: 0.5292\n",
      "Epoch 122/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9769 - accuracy: 0.5279 - val_loss: 0.9655 - val_accuracy: 0.5324\n",
      "Epoch 123/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9765 - accuracy: 0.5317 - val_loss: 0.9678 - val_accuracy: 0.5284\n",
      "Epoch 124/500\n",
      "5063/5063 [==============================] - 0s 99us/sample - loss: 0.9763 - accuracy: 0.5299 - val_loss: 0.9655 - val_accuracy: 0.5355\n",
      "Epoch 125/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9760 - accuracy: 0.5331 - val_loss: 0.9649 - val_accuracy: 0.5371\n",
      "Epoch 126/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9754 - accuracy: 0.5329 - val_loss: 0.9661 - val_accuracy: 0.5284\n",
      "Epoch 127/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9756 - accuracy: 0.5331 - val_loss: 0.9684 - val_accuracy: 0.5308\n",
      "Epoch 128/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9756 - accuracy: 0.5355 - val_loss: 0.9655 - val_accuracy: 0.5308\n",
      "Epoch 129/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9763 - accuracy: 0.5335 - val_loss: 0.9652 - val_accuracy: 0.5316\n",
      "Epoch 130/500\n",
      "5063/5063 [==============================] - 1s 144us/sample - loss: 0.9756 - accuracy: 0.5301 - val_loss: 0.9659 - val_accuracy: 0.5442\n",
      "Epoch 131/500\n",
      "5063/5063 [==============================] - 1s 123us/sample - loss: 0.9756 - accuracy: 0.5327 - val_loss: 0.9678 - val_accuracy: 0.5403\n",
      "Epoch 132/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 0.9750 - accuracy: 0.5339 - val_loss: 0.9657 - val_accuracy: 0.5419\n",
      "Epoch 133/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 0.9758 - accuracy: 0.5351 - val_loss: 0.9646 - val_accuracy: 0.5363\n",
      "Epoch 134/500\n",
      "5063/5063 [==============================] - 1s 136us/sample - loss: 0.9757 - accuracy: 0.5329 - val_loss: 0.9647 - val_accuracy: 0.5458\n",
      "Epoch 135/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9758 - accuracy: 0.5331 - val_loss: 0.9644 - val_accuracy: 0.5363\n",
      "Epoch 136/500\n",
      "5063/5063 [==============================] - 1s 125us/sample - loss: 0.9752 - accuracy: 0.5313 - val_loss: 0.9665 - val_accuracy: 0.5395\n",
      "Epoch 137/500\n",
      "5063/5063 [==============================] - 1s 133us/sample - loss: 0.9755 - accuracy: 0.5317 - val_loss: 0.9648 - val_accuracy: 0.5332\n",
      "Epoch 138/500\n",
      "5063/5063 [==============================] - 1s 136us/sample - loss: 0.9756 - accuracy: 0.5337 - val_loss: 0.9681 - val_accuracy: 0.5284\n",
      "Epoch 139/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9754 - accuracy: 0.5315 - val_loss: 0.9727 - val_accuracy: 0.5197\n",
      "Epoch 140/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 0.9752 - accuracy: 0.5311 - val_loss: 0.9650 - val_accuracy: 0.5300\n",
      "Epoch 141/500\n",
      "5063/5063 [==============================] - 1s 151us/sample - loss: 0.9751 - accuracy: 0.5337 - val_loss: 0.9637 - val_accuracy: 0.5371\n",
      "Epoch 142/500\n",
      "5063/5063 [==============================] - 1s 122us/sample - loss: 0.9751 - accuracy: 0.5343 - val_loss: 0.9636 - val_accuracy: 0.5379\n",
      "Epoch 143/500\n",
      "5063/5063 [==============================] - 1s 129us/sample - loss: 0.9747 - accuracy: 0.5355 - val_loss: 0.9658 - val_accuracy: 0.5300\n",
      "Epoch 144/500\n",
      "5063/5063 [==============================] - 1s 150us/sample - loss: 0.9745 - accuracy: 0.5335 - val_loss: 0.9730 - val_accuracy: 0.5205\n",
      "Epoch 145/500\n",
      "5063/5063 [==============================] - 1s 121us/sample - loss: 0.9748 - accuracy: 0.5301 - val_loss: 0.9665 - val_accuracy: 0.5300\n",
      "Epoch 146/500\n",
      "5063/5063 [==============================] - 1s 140us/sample - loss: 0.9747 - accuracy: 0.5347 - val_loss: 0.9633 - val_accuracy: 0.5379\n",
      "Epoch 147/500\n",
      "5063/5063 [==============================] - 1s 156us/sample - loss: 0.9748 - accuracy: 0.5329 - val_loss: 0.9635 - val_accuracy: 0.5371\n",
      "Epoch 148/500\n",
      "5063/5063 [==============================] - 1s 140us/sample - loss: 0.9745 - accuracy: 0.5329 - val_loss: 0.9632 - val_accuracy: 0.5355\n",
      "Epoch 149/500\n",
      "5063/5063 [==============================] - 1s 161us/sample - loss: 0.9746 - accuracy: 0.5353 - val_loss: 0.9655 - val_accuracy: 0.5292\n",
      "Epoch 150/500\n",
      "5063/5063 [==============================] - 1s 150us/sample - loss: 0.9746 - accuracy: 0.5333 - val_loss: 0.9632 - val_accuracy: 0.5379\n",
      "Epoch 151/500\n",
      "5063/5063 [==============================] - 1s 152us/sample - loss: 0.9743 - accuracy: 0.5341 - val_loss: 0.9631 - val_accuracy: 0.5363\n",
      "Epoch 152/500\n",
      "5063/5063 [==============================] - 1s 149us/sample - loss: 0.9742 - accuracy: 0.5347 - val_loss: 0.9639 - val_accuracy: 0.5340\n",
      "Epoch 153/500\n",
      "5063/5063 [==============================] - 1s 130us/sample - loss: 0.9736 - accuracy: 0.5349 - val_loss: 0.9653 - val_accuracy: 0.5284\n",
      "Epoch 154/500\n",
      "5063/5063 [==============================] - 1s 127us/sample - loss: 0.9741 - accuracy: 0.5368 - val_loss: 0.9642 - val_accuracy: 0.5316\n",
      "Epoch 155/500\n",
      "5063/5063 [==============================] - 1s 113us/sample - loss: 0.9741 - accuracy: 0.5327 - val_loss: 0.9659 - val_accuracy: 0.5292\n",
      "Epoch 156/500\n",
      "5063/5063 [==============================] - 1s 128us/sample - loss: 0.9745 - accuracy: 0.5313 - val_loss: 0.9636 - val_accuracy: 0.5434\n",
      "Epoch 157/500\n",
      "5063/5063 [==============================] - 1s 151us/sample - loss: 0.9740 - accuracy: 0.5357 - val_loss: 0.9631 - val_accuracy: 0.5363\n",
      "Epoch 158/500\n",
      "5063/5063 [==============================] - 1s 132us/sample - loss: 0.9740 - accuracy: 0.5362 - val_loss: 0.9627 - val_accuracy: 0.5379\n",
      "Epoch 159/500\n",
      "5063/5063 [==============================] - 1s 150us/sample - loss: 0.9741 - accuracy: 0.5339 - val_loss: 0.9646 - val_accuracy: 0.5292\n",
      "Epoch 160/500\n",
      "5063/5063 [==============================] - 1s 136us/sample - loss: 0.9732 - accuracy: 0.5333 - val_loss: 0.9624 - val_accuracy: 0.5379\n",
      "Epoch 161/500\n",
      "5063/5063 [==============================] - 1s 122us/sample - loss: 0.9741 - accuracy: 0.5315 - val_loss: 0.9625 - val_accuracy: 0.5371\n",
      "Epoch 162/500\n",
      "5063/5063 [==============================] - 1s 184us/sample - loss: 0.9736 - accuracy: 0.5325 - val_loss: 0.9625 - val_accuracy: 0.5363\n",
      "Epoch 163/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9739 - accuracy: 0.5321 - val_loss: 0.9627 - val_accuracy: 0.5379\n",
      "Epoch 164/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5063/5063 [==============================] - 1s 105us/sample - loss: 0.9732 - accuracy: 0.5333 - val_loss: 0.9625 - val_accuracy: 0.5363\n",
      "Epoch 165/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9739 - accuracy: 0.5341 - val_loss: 0.9634 - val_accuracy: 0.5340\n",
      "Epoch 166/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9736 - accuracy: 0.5303 - val_loss: 0.9624 - val_accuracy: 0.5371\n",
      "Epoch 167/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9731 - accuracy: 0.5349 - val_loss: 0.9622 - val_accuracy: 0.5371\n",
      "Epoch 168/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9735 - accuracy: 0.5370 - val_loss: 0.9623 - val_accuracy: 0.5387\n",
      "Epoch 169/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9737 - accuracy: 0.5364 - val_loss: 0.9622 - val_accuracy: 0.5371\n",
      "Epoch 170/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9739 - accuracy: 0.5349 - val_loss: 0.9621 - val_accuracy: 0.5379\n",
      "Epoch 171/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9735 - accuracy: 0.5374 - val_loss: 0.9623 - val_accuracy: 0.5395\n",
      "Epoch 172/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9731 - accuracy: 0.5358 - val_loss: 0.9660 - val_accuracy: 0.5276\n",
      "Epoch 173/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9732 - accuracy: 0.5325 - val_loss: 0.9629 - val_accuracy: 0.5340\n",
      "Epoch 174/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9731 - accuracy: 0.5351 - val_loss: 0.9630 - val_accuracy: 0.5332\n",
      "Epoch 175/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9731 - accuracy: 0.5315 - val_loss: 0.9623 - val_accuracy: 0.5403\n",
      "Epoch 176/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9729 - accuracy: 0.5372 - val_loss: 0.9621 - val_accuracy: 0.5379\n",
      "Epoch 177/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9726 - accuracy: 0.5331 - val_loss: 0.9659 - val_accuracy: 0.5276\n",
      "Epoch 178/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9732 - accuracy: 0.5331 - val_loss: 0.9646 - val_accuracy: 0.5308\n",
      "Epoch 179/500\n",
      "5063/5063 [==============================] - 1s 150us/sample - loss: 0.9726 - accuracy: 0.5355 - val_loss: 0.9618 - val_accuracy: 0.5395\n",
      "Epoch 180/500\n",
      "5063/5063 [==============================] - 1s 178us/sample - loss: 0.9731 - accuracy: 0.5347 - val_loss: 0.9625 - val_accuracy: 0.5340\n",
      "Epoch 181/500\n",
      "5063/5063 [==============================] - 1s 136us/sample - loss: 0.9726 - accuracy: 0.5349 - val_loss: 0.9636 - val_accuracy: 0.5308\n",
      "Epoch 182/500\n",
      "5063/5063 [==============================] - 1s 136us/sample - loss: 0.9729 - accuracy: 0.5335 - val_loss: 0.9616 - val_accuracy: 0.5379\n",
      "Epoch 183/500\n",
      "5063/5063 [==============================] - 1s 113us/sample - loss: 0.9724 - accuracy: 0.5362 - val_loss: 0.9616 - val_accuracy: 0.5403\n",
      "Epoch 184/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9722 - accuracy: 0.5351 - val_loss: 0.9646 - val_accuracy: 0.5411\n",
      "Epoch 185/500\n",
      "5063/5063 [==============================] - 0s 99us/sample - loss: 0.9731 - accuracy: 0.5355 - val_loss: 0.9616 - val_accuracy: 0.5387\n",
      "Epoch 186/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9720 - accuracy: 0.5347 - val_loss: 0.9646 - val_accuracy: 0.5292\n",
      "Epoch 187/500\n",
      "5063/5063 [==============================] - 0s 99us/sample - loss: 0.9725 - accuracy: 0.5341 - val_loss: 0.9616 - val_accuracy: 0.5395\n",
      "Epoch 188/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9726 - accuracy: 0.5355 - val_loss: 0.9614 - val_accuracy: 0.5387\n",
      "Epoch 189/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9725 - accuracy: 0.5357 - val_loss: 0.9615 - val_accuracy: 0.5395\n",
      "Epoch 190/500\n",
      "5063/5063 [==============================] - 0s 99us/sample - loss: 0.9723 - accuracy: 0.5351 - val_loss: 0.9626 - val_accuracy: 0.5411\n",
      "Epoch 191/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9722 - accuracy: 0.5329 - val_loss: 0.9636 - val_accuracy: 0.5300\n",
      "Epoch 192/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9723 - accuracy: 0.5355 - val_loss: 0.9622 - val_accuracy: 0.5348\n",
      "Epoch 193/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9723 - accuracy: 0.5370 - val_loss: 0.9616 - val_accuracy: 0.5395\n",
      "Epoch 194/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9717 - accuracy: 0.5355 - val_loss: 0.9651 - val_accuracy: 0.5269\n",
      "Epoch 195/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9722 - accuracy: 0.5349 - val_loss: 0.9661 - val_accuracy: 0.5276\n",
      "Epoch 196/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9723 - accuracy: 0.5347 - val_loss: 0.9615 - val_accuracy: 0.5395\n",
      "Epoch 197/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9722 - accuracy: 0.5351 - val_loss: 0.9614 - val_accuracy: 0.5379\n",
      "Epoch 198/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9719 - accuracy: 0.5358 - val_loss: 0.9611 - val_accuracy: 0.5395\n",
      "Epoch 199/500\n",
      "5063/5063 [==============================] - 1s 101us/sample - loss: 0.9720 - accuracy: 0.5358 - val_loss: 0.9664 - val_accuracy: 0.5253\n",
      "Epoch 200/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9721 - accuracy: 0.5351 - val_loss: 0.9625 - val_accuracy: 0.5403\n",
      "Epoch 201/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9719 - accuracy: 0.5337 - val_loss: 0.9703 - val_accuracy: 0.5245\n",
      "Epoch 202/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9722 - accuracy: 0.5313 - val_loss: 0.9646 - val_accuracy: 0.5269\n",
      "Epoch 203/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9722 - accuracy: 0.5358 - val_loss: 0.9610 - val_accuracy: 0.5387\n",
      "Epoch 204/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9716 - accuracy: 0.5353 - val_loss: 0.9630 - val_accuracy: 0.5308\n",
      "Epoch 205/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9717 - accuracy: 0.5345 - val_loss: 0.9631 - val_accuracy: 0.5403\n",
      "Epoch 206/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9720 - accuracy: 0.5355 - val_loss: 0.9622 - val_accuracy: 0.5395\n",
      "Epoch 207/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9717 - accuracy: 0.5343 - val_loss: 0.9644 - val_accuracy: 0.5292\n",
      "Epoch 208/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9710 - accuracy: 0.5345 - val_loss: 0.9610 - val_accuracy: 0.5395\n",
      "Epoch 209/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9716 - accuracy: 0.5358 - val_loss: 0.9610 - val_accuracy: 0.5387\n",
      "Epoch 210/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9711 - accuracy: 0.5351 - val_loss: 0.9608 - val_accuracy: 0.5403\n",
      "Epoch 211/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9713 - accuracy: 0.5358 - val_loss: 0.9611 - val_accuracy: 0.5379\n",
      "Epoch 212/500\n",
      "5063/5063 [==============================] - 1s 101us/sample - loss: 0.9716 - accuracy: 0.5366 - val_loss: 0.9610 - val_accuracy: 0.5379\n",
      "Epoch 213/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9712 - accuracy: 0.5351 - val_loss: 0.9620 - val_accuracy: 0.5324\n",
      "Epoch 214/500\n",
      "5063/5063 [==============================] - 1s 106us/sample - loss: 0.9714 - accuracy: 0.5341 - val_loss: 0.9613 - val_accuracy: 0.5379\n",
      "Epoch 215/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9715 - accuracy: 0.5370 - val_loss: 0.9624 - val_accuracy: 0.5316\n",
      "Epoch 216/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9713 - accuracy: 0.5349 - val_loss: 0.9619 - val_accuracy: 0.5324\n",
      "Epoch 217/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9711 - accuracy: 0.5337 - val_loss: 0.9688 - val_accuracy: 0.5269\n",
      "Epoch 218/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9716 - accuracy: 0.5343 - val_loss: 0.9606 - val_accuracy: 0.5419\n",
      "Epoch 219/500\n",
      "5063/5063 [==============================] - 1s 101us/sample - loss: 0.9713 - accuracy: 0.5358 - val_loss: 0.9612 - val_accuracy: 0.5387\n",
      "Epoch 220/500\n",
      "5063/5063 [==============================] - 0s 96us/sample - loss: 0.9713 - accuracy: 0.5341 - val_loss: 0.9606 - val_accuracy: 0.5371\n",
      "Epoch 221/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9711 - accuracy: 0.5372 - val_loss: 0.9613 - val_accuracy: 0.5395\n",
      "Epoch 222/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9713 - accuracy: 0.5362 - val_loss: 0.9605 - val_accuracy: 0.5403\n",
      "Epoch 223/500\n",
      "5063/5063 [==============================] - 0s 99us/sample - loss: 0.9706 - accuracy: 0.5392 - val_loss: 0.9616 - val_accuracy: 0.5355\n",
      "Epoch 224/500\n",
      "5063/5063 [==============================] - 0s 97us/sample - loss: 0.9710 - accuracy: 0.5357 - val_loss: 0.9603 - val_accuracy: 0.5387\n",
      "Epoch 225/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9709 - accuracy: 0.5376 - val_loss: 0.9603 - val_accuracy: 0.5411\n",
      "Epoch 226/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9710 - accuracy: 0.5368 - val_loss: 0.9605 - val_accuracy: 0.5387\n",
      "Epoch 227/500\n",
      "5063/5063 [==============================] - 1s 153us/sample - loss: 0.9708 - accuracy: 0.5355 - val_loss: 0.9603 - val_accuracy: 0.5387\n",
      "Epoch 228/500\n",
      "5063/5063 [==============================] - 1s 158us/sample - loss: 0.9706 - accuracy: 0.5364 - val_loss: 0.9609 - val_accuracy: 0.5371\n",
      "Epoch 229/500\n",
      "5063/5063 [==============================] - 1s 213us/sample - loss: 0.9705 - accuracy: 0.5327 - val_loss: 0.9603 - val_accuracy: 0.5419\n",
      "Epoch 230/500\n",
      "5063/5063 [==============================] - 1s 116us/sample - loss: 0.9704 - accuracy: 0.5335 - val_loss: 0.9604 - val_accuracy: 0.5379\n",
      "Epoch 231/500\n",
      "5063/5063 [==============================] - 1s 106us/sample - loss: 0.9703 - accuracy: 0.5376 - val_loss: 0.9612 - val_accuracy: 0.5371\n",
      "Epoch 232/500\n",
      "5063/5063 [==============================] - 1s 146us/sample - loss: 0.9707 - accuracy: 0.5353 - val_loss: 0.9650 - val_accuracy: 0.5245\n",
      "Epoch 233/500\n",
      "5063/5063 [==============================] - 1s 155us/sample - loss: 0.9709 - accuracy: 0.5360 - val_loss: 0.9624 - val_accuracy: 0.5395\n",
      "Epoch 234/500\n",
      "5063/5063 [==============================] - 1s 168us/sample - loss: 0.9706 - accuracy: 0.5396 - val_loss: 0.9690 - val_accuracy: 0.5245\n",
      "Epoch 235/500\n",
      "5063/5063 [==============================] - 1s 165us/sample - loss: 0.9713 - accuracy: 0.5358 - val_loss: 0.9607 - val_accuracy: 0.5379\n",
      "Epoch 236/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9708 - accuracy: 0.5364 - val_loss: 0.9613 - val_accuracy: 0.5340\n",
      "Epoch 237/500\n",
      "5063/5063 [==============================] - 1s 149us/sample - loss: 0.9699 - accuracy: 0.5347 - val_loss: 0.9599 - val_accuracy: 0.5411\n",
      "Epoch 238/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9706 - accuracy: 0.5355 - val_loss: 0.9605 - val_accuracy: 0.5379\n",
      "Epoch 239/500\n",
      "5063/5063 [==============================] - 1s 129us/sample - loss: 0.9707 - accuracy: 0.5349 - val_loss: 0.9606 - val_accuracy: 0.5379\n",
      "Epoch 240/500\n",
      "5063/5063 [==============================] - 1s 150us/sample - loss: 0.9704 - accuracy: 0.5351 - val_loss: 0.9598 - val_accuracy: 0.5411\n",
      "Epoch 241/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9704 - accuracy: 0.5360 - val_loss: 0.9599 - val_accuracy: 0.5411\n",
      "Epoch 242/500\n",
      "5063/5063 [==============================] - 1s 160us/sample - loss: 0.9704 - accuracy: 0.5345 - val_loss: 0.9598 - val_accuracy: 0.5387\n",
      "Epoch 243/500\n",
      "5063/5063 [==============================] - 1s 149us/sample - loss: 0.9703 - accuracy: 0.5360 - val_loss: 0.9598 - val_accuracy: 0.5403\n",
      "Epoch 244/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9704 - accuracy: 0.5374 - val_loss: 0.9617 - val_accuracy: 0.5324\n",
      "Epoch 245/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9703 - accuracy: 0.5376 - val_loss: 0.9648 - val_accuracy: 0.5253\n",
      "Epoch 246/500\n",
      "5063/5063 [==============================] - 1s 128us/sample - loss: 0.9703 - accuracy: 0.5378 - val_loss: 0.9602 - val_accuracy: 0.5379\n",
      "Epoch 247/500\n",
      "5063/5063 [==============================] - 1s 133us/sample - loss: 0.9699 - accuracy: 0.5355 - val_loss: 0.9618 - val_accuracy: 0.5316\n",
      "Epoch 248/500\n",
      "5063/5063 [==============================] - 1s 139us/sample - loss: 0.9701 - accuracy: 0.5353 - val_loss: 0.9596 - val_accuracy: 0.5411\n",
      "Epoch 249/500\n",
      "5063/5063 [==============================] - 1s 152us/sample - loss: 0.9699 - accuracy: 0.5362 - val_loss: 0.9602 - val_accuracy: 0.5387\n",
      "Epoch 250/500\n",
      "5063/5063 [==============================] - 1s 132us/sample - loss: 0.9700 - accuracy: 0.5390 - val_loss: 0.9596 - val_accuracy: 0.5379\n",
      "Epoch 251/500\n",
      "5063/5063 [==============================] - 1s 116us/sample - loss: 0.9697 - accuracy: 0.5360 - val_loss: 0.9604 - val_accuracy: 0.5379\n",
      "Epoch 252/500\n",
      "5063/5063 [==============================] - 1s 178us/sample - loss: 0.9701 - accuracy: 0.5374 - val_loss: 0.9599 - val_accuracy: 0.5395\n",
      "Epoch 253/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9702 - accuracy: 0.5364 - val_loss: 0.9597 - val_accuracy: 0.5419\n",
      "Epoch 254/500\n",
      "5063/5063 [==============================] - 1s 139us/sample - loss: 0.9700 - accuracy: 0.5382 - val_loss: 0.9676 - val_accuracy: 0.5253\n",
      "Epoch 255/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9702 - accuracy: 0.5370 - val_loss: 0.9598 - val_accuracy: 0.5395\n",
      "Epoch 256/500\n",
      "5063/5063 [==============================] - 1s 170us/sample - loss: 0.9698 - accuracy: 0.5362 - val_loss: 0.9611 - val_accuracy: 0.5340\n",
      "Epoch 257/500\n",
      "5063/5063 [==============================] - 1s 129us/sample - loss: 0.9697 - accuracy: 0.5358 - val_loss: 0.9603 - val_accuracy: 0.5363\n",
      "Epoch 258/500\n",
      "5063/5063 [==============================] - 1s 138us/sample - loss: 0.9697 - accuracy: 0.5366 - val_loss: 0.9623 - val_accuracy: 0.5300\n",
      "Epoch 259/500\n",
      "5063/5063 [==============================] - 1s 141us/sample - loss: 0.9699 - accuracy: 0.5357 - val_loss: 0.9596 - val_accuracy: 0.5387\n",
      "Epoch 260/500\n",
      "5063/5063 [==============================] - 1s 169us/sample - loss: 0.9694 - accuracy: 0.5368 - val_loss: 0.9647 - val_accuracy: 0.5245\n",
      "Epoch 261/500\n",
      "5063/5063 [==============================] - 1s 112us/sample - loss: 0.9696 - accuracy: 0.5374 - val_loss: 0.9600 - val_accuracy: 0.5387\n",
      "Epoch 262/500\n",
      "5063/5063 [==============================] - 1s 127us/sample - loss: 0.9696 - accuracy: 0.5345 - val_loss: 0.9602 - val_accuracy: 0.5371\n",
      "Epoch 263/500\n",
      "5063/5063 [==============================] - 1s 116us/sample - loss: 0.9695 - accuracy: 0.5382 - val_loss: 0.9665 - val_accuracy: 0.5261\n",
      "Epoch 264/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9693 - accuracy: 0.5370 - val_loss: 0.9645 - val_accuracy: 0.5245\n",
      "Epoch 265/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9692 - accuracy: 0.5386 - val_loss: 0.9626 - val_accuracy: 0.5284\n",
      "Epoch 266/500\n",
      "5063/5063 [==============================] - 1s 127us/sample - loss: 0.9697 - accuracy: 0.5355 - val_loss: 0.9594 - val_accuracy: 0.5411\n",
      "Epoch 267/500\n",
      "5063/5063 [==============================] - 1s 123us/sample - loss: 0.9695 - accuracy: 0.5386 - val_loss: 0.9595 - val_accuracy: 0.5387\n",
      "Epoch 268/500\n",
      "5063/5063 [==============================] - 1s 108us/sample - loss: 0.9692 - accuracy: 0.5388 - val_loss: 0.9670 - val_accuracy: 0.5245\n",
      "Epoch 269/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9695 - accuracy: 0.5376 - val_loss: 0.9594 - val_accuracy: 0.5411\n",
      "Epoch 270/500\n",
      "5063/5063 [==============================] - 1s 131us/sample - loss: 0.9695 - accuracy: 0.5380 - val_loss: 0.9598 - val_accuracy: 0.5387\n",
      "Epoch 271/500\n",
      "5063/5063 [==============================] - 1s 162us/sample - loss: 0.9692 - accuracy: 0.5392 - val_loss: 0.9593 - val_accuracy: 0.5387\n",
      "Epoch 272/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5063/5063 [==============================] - 1s 124us/sample - loss: 0.9695 - accuracy: 0.5366 - val_loss: 0.9605 - val_accuracy: 0.5355\n",
      "Epoch 273/500\n",
      "5063/5063 [==============================] - 1s 137us/sample - loss: 0.9693 - accuracy: 0.5355 - val_loss: 0.9593 - val_accuracy: 0.5387\n",
      "Epoch 274/500\n",
      "5063/5063 [==============================] - 1s 130us/sample - loss: 0.9690 - accuracy: 0.5378 - val_loss: 0.9592 - val_accuracy: 0.5379\n",
      "Epoch 275/500\n",
      "5063/5063 [==============================] - 1s 121us/sample - loss: 0.9693 - accuracy: 0.5410 - val_loss: 0.9592 - val_accuracy: 0.5403\n",
      "Epoch 276/500\n",
      "5063/5063 [==============================] - 1s 151us/sample - loss: 0.9686 - accuracy: 0.5345 - val_loss: 0.9602 - val_accuracy: 0.5355\n",
      "Epoch 277/500\n",
      "5063/5063 [==============================] - 1s 139us/sample - loss: 0.9695 - accuracy: 0.5351 - val_loss: 0.9595 - val_accuracy: 0.5395\n",
      "Epoch 278/500\n",
      "5063/5063 [==============================] - 1s 150us/sample - loss: 0.9691 - accuracy: 0.5382 - val_loss: 0.9657 - val_accuracy: 0.5261\n",
      "Epoch 279/500\n",
      "5063/5063 [==============================] - 1s 124us/sample - loss: 0.9694 - accuracy: 0.5388 - val_loss: 0.9592 - val_accuracy: 0.5411\n",
      "Epoch 280/500\n",
      "5063/5063 [==============================] - 1s 130us/sample - loss: 0.9690 - accuracy: 0.5355 - val_loss: 0.9592 - val_accuracy: 0.5379\n",
      "Epoch 281/500\n",
      "5063/5063 [==============================] - 1s 132us/sample - loss: 0.9688 - accuracy: 0.5376 - val_loss: 0.9594 - val_accuracy: 0.5395\n",
      "Epoch 282/500\n",
      "5063/5063 [==============================] - 1s 140us/sample - loss: 0.9690 - accuracy: 0.5376 - val_loss: 0.9592 - val_accuracy: 0.5419\n",
      "Epoch 283/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9690 - accuracy: 0.5360 - val_loss: 0.9622 - val_accuracy: 0.5284\n",
      "Epoch 284/500\n",
      "5063/5063 [==============================] - ETA: 0s - loss: 0.9685 - accuracy: 0.53 - 1s 124us/sample - loss: 0.9688 - accuracy: 0.5382 - val_loss: 0.9597 - val_accuracy: 0.5379\n",
      "Epoch 285/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9686 - accuracy: 0.5376 - val_loss: 0.9590 - val_accuracy: 0.5387\n",
      "Epoch 286/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9691 - accuracy: 0.5388 - val_loss: 0.9595 - val_accuracy: 0.5395\n",
      "Epoch 287/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9685 - accuracy: 0.5394 - val_loss: 0.9608 - val_accuracy: 0.5403\n",
      "Epoch 288/500\n",
      "5063/5063 [==============================] - 1s 128us/sample - loss: 0.9689 - accuracy: 0.5374 - val_loss: 0.9632 - val_accuracy: 0.5371\n",
      "Epoch 289/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9692 - accuracy: 0.5360 - val_loss: 0.9590 - val_accuracy: 0.5403\n",
      "Epoch 290/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9684 - accuracy: 0.5382 - val_loss: 0.9612 - val_accuracy: 0.5419\n",
      "Epoch 291/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9689 - accuracy: 0.5372 - val_loss: 0.9592 - val_accuracy: 0.5411\n",
      "Epoch 292/500\n",
      "5063/5063 [==============================] - 1s 114us/sample - loss: 0.9686 - accuracy: 0.5386 - val_loss: 0.9594 - val_accuracy: 0.5371\n",
      "Epoch 293/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9686 - accuracy: 0.5353 - val_loss: 0.9599 - val_accuracy: 0.5379\n",
      "Epoch 294/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9687 - accuracy: 0.5380 - val_loss: 0.9592 - val_accuracy: 0.5379\n",
      "Epoch 295/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9683 - accuracy: 0.5376 - val_loss: 0.9627 - val_accuracy: 0.5269\n",
      "Epoch 296/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9690 - accuracy: 0.5370 - val_loss: 0.9603 - val_accuracy: 0.5348\n",
      "Epoch 297/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9685 - accuracy: 0.5380 - val_loss: 0.9625 - val_accuracy: 0.5261\n",
      "Epoch 298/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 0.9689 - accuracy: 0.5396 - val_loss: 0.9591 - val_accuracy: 0.5411\n",
      "Epoch 299/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9686 - accuracy: 0.5388 - val_loss: 0.9595 - val_accuracy: 0.5379\n",
      "Epoch 300/500\n",
      "5063/5063 [==============================] - 1s 106us/sample - loss: 0.9687 - accuracy: 0.5362 - val_loss: 0.9607 - val_accuracy: 0.5332\n",
      "Epoch 301/500\n",
      "5063/5063 [==============================] - 1s 127us/sample - loss: 0.9684 - accuracy: 0.5384 - val_loss: 0.9606 - val_accuracy: 0.5403\n",
      "Epoch 302/500\n",
      "5063/5063 [==============================] - 1s 131us/sample - loss: 0.9682 - accuracy: 0.5386 - val_loss: 0.9624 - val_accuracy: 0.5269\n",
      "Epoch 303/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9683 - accuracy: 0.5374 - val_loss: 0.9647 - val_accuracy: 0.5253\n",
      "Epoch 304/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9683 - accuracy: 0.5358 - val_loss: 0.9591 - val_accuracy: 0.5371\n",
      "Epoch 305/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9676 - accuracy: 0.5396 - val_loss: 0.9601 - val_accuracy: 0.5340\n",
      "Epoch 306/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9681 - accuracy: 0.5398 - val_loss: 0.9599 - val_accuracy: 0.5387\n",
      "Epoch 307/500\n",
      "5063/5063 [==============================] - 1s 146us/sample - loss: 0.9682 - accuracy: 0.5388 - val_loss: 0.9611 - val_accuracy: 0.5300\n",
      "Epoch 308/500\n",
      "5063/5063 [==============================] - 1s 112us/sample - loss: 0.9682 - accuracy: 0.5364 - val_loss: 0.9602 - val_accuracy: 0.5348\n",
      "Epoch 309/500\n",
      "5063/5063 [==============================] - 1s 127us/sample - loss: 0.9680 - accuracy: 0.5408 - val_loss: 0.9619 - val_accuracy: 0.5284\n",
      "Epoch 310/500\n",
      "5063/5063 [==============================] - 1s 132us/sample - loss: 0.9681 - accuracy: 0.5394 - val_loss: 0.9598 - val_accuracy: 0.5387\n",
      "Epoch 311/500\n",
      "5063/5063 [==============================] - 1s 164us/sample - loss: 0.9684 - accuracy: 0.5325 - val_loss: 0.9591 - val_accuracy: 0.5371\n",
      "Epoch 312/500\n",
      "5063/5063 [==============================] - 1s 138us/sample - loss: 0.9679 - accuracy: 0.5378 - val_loss: 0.9617 - val_accuracy: 0.5300\n",
      "Epoch 313/500\n",
      "5063/5063 [==============================] - 1s 137us/sample - loss: 0.9681 - accuracy: 0.5394 - val_loss: 0.9592 - val_accuracy: 0.5363\n",
      "Epoch 314/500\n",
      "5063/5063 [==============================] - 1s 109us/sample - loss: 0.9677 - accuracy: 0.5390 - val_loss: 0.9590 - val_accuracy: 0.5363\n",
      "Epoch 315/500\n",
      "5063/5063 [==============================] - 1s 114us/sample - loss: 0.9681 - accuracy: 0.5360 - val_loss: 0.9588 - val_accuracy: 0.5371\n",
      "Epoch 316/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9680 - accuracy: 0.5372 - val_loss: 0.9587 - val_accuracy: 0.5371\n",
      "Epoch 317/500\n",
      "5063/5063 [==============================] - 1s 167us/sample - loss: 0.9679 - accuracy: 0.5370 - val_loss: 0.9592 - val_accuracy: 0.5363\n",
      "Epoch 318/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9679 - accuracy: 0.5396 - val_loss: 0.9592 - val_accuracy: 0.5387\n",
      "Epoch 319/500\n",
      "5063/5063 [==============================] - 1s 126us/sample - loss: 0.9679 - accuracy: 0.5378 - val_loss: 0.9588 - val_accuracy: 0.5363\n",
      "Epoch 320/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9678 - accuracy: 0.5382 - val_loss: 0.9596 - val_accuracy: 0.5371\n",
      "Epoch 321/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9668 - accuracy: 0.5364 - val_loss: 0.9652 - val_accuracy: 0.5316\n",
      "Epoch 322/500\n",
      "5063/5063 [==============================] - 1s 101us/sample - loss: 0.9679 - accuracy: 0.5404 - val_loss: 0.9589 - val_accuracy: 0.5371\n",
      "Epoch 323/500\n",
      "5063/5063 [==============================] - 1s 116us/sample - loss: 0.9678 - accuracy: 0.5376 - val_loss: 0.9639 - val_accuracy: 0.5261\n",
      "Epoch 324/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9682 - accuracy: 0.5370 - val_loss: 0.9593 - val_accuracy: 0.5387\n",
      "Epoch 325/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9677 - accuracy: 0.5378 - val_loss: 0.9620 - val_accuracy: 0.5284\n",
      "Epoch 326/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5063/5063 [==============================] - 1s 155us/sample - loss: 0.9678 - accuracy: 0.5378 - val_loss: 0.9589 - val_accuracy: 0.5355\n",
      "Epoch 327/500\n",
      "5063/5063 [==============================] - 1s 144us/sample - loss: 0.9680 - accuracy: 0.5384 - val_loss: 0.9589 - val_accuracy: 0.5340\n",
      "Epoch 328/500\n",
      "5063/5063 [==============================] - 1s 129us/sample - loss: 0.9679 - accuracy: 0.5388 - val_loss: 0.9588 - val_accuracy: 0.5355\n",
      "Epoch 329/500\n",
      "5063/5063 [==============================] - 1s 131us/sample - loss: 0.9674 - accuracy: 0.5378 - val_loss: 0.9585 - val_accuracy: 0.5371\n",
      "Epoch 330/500\n",
      "5063/5063 [==============================] - 1s 139us/sample - loss: 0.9676 - accuracy: 0.5378 - val_loss: 0.9591 - val_accuracy: 0.5355\n",
      "Epoch 331/500\n",
      "5063/5063 [==============================] - 1s 130us/sample - loss: 0.9679 - accuracy: 0.5368 - val_loss: 0.9586 - val_accuracy: 0.5395\n",
      "Epoch 332/500\n",
      "5063/5063 [==============================] - 1s 164us/sample - loss: 0.9676 - accuracy: 0.5347 - val_loss: 0.9593 - val_accuracy: 0.5387\n",
      "Epoch 333/500\n",
      "5063/5063 [==============================] - 1s 125us/sample - loss: 0.9676 - accuracy: 0.5368 - val_loss: 0.9606 - val_accuracy: 0.5332\n",
      "Epoch 334/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9678 - accuracy: 0.5358 - val_loss: 0.9608 - val_accuracy: 0.5324\n",
      "Epoch 335/500\n",
      "5063/5063 [==============================] - 1s 132us/sample - loss: 0.9671 - accuracy: 0.5370 - val_loss: 0.9606 - val_accuracy: 0.5419\n",
      "Epoch 336/500\n",
      "5063/5063 [==============================] - 1s 153us/sample - loss: 0.9676 - accuracy: 0.5392 - val_loss: 0.9586 - val_accuracy: 0.5403\n",
      "Epoch 337/500\n",
      "5063/5063 [==============================] - 1s 146us/sample - loss: 0.9674 - accuracy: 0.5378 - val_loss: 0.9587 - val_accuracy: 0.5371\n",
      "Epoch 338/500\n",
      "5063/5063 [==============================] - 1s 125us/sample - loss: 0.9675 - accuracy: 0.5388 - val_loss: 0.9649 - val_accuracy: 0.5261\n",
      "Epoch 339/500\n",
      "5063/5063 [==============================] - 1s 133us/sample - loss: 0.9678 - accuracy: 0.5370 - val_loss: 0.9598 - val_accuracy: 0.5348\n",
      "Epoch 340/500\n",
      "5063/5063 [==============================] - 1s 116us/sample - loss: 0.9673 - accuracy: 0.5386 - val_loss: 0.9586 - val_accuracy: 0.5403\n",
      "Epoch 341/500\n",
      "5063/5063 [==============================] - 1s 172us/sample - loss: 0.9674 - accuracy: 0.5366 - val_loss: 0.9601 - val_accuracy: 0.5332\n",
      "Epoch 342/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9678 - accuracy: 0.5360 - val_loss: 0.9587 - val_accuracy: 0.5340\n",
      "Epoch 343/500\n",
      "5063/5063 [==============================] - 1s 142us/sample - loss: 0.9675 - accuracy: 0.5408 - val_loss: 0.9585 - val_accuracy: 0.5403\n",
      "Epoch 344/500\n",
      "5063/5063 [==============================] - 1s 144us/sample - loss: 0.9674 - accuracy: 0.5390 - val_loss: 0.9613 - val_accuracy: 0.5308\n",
      "Epoch 345/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9673 - accuracy: 0.5364 - val_loss: 0.9584 - val_accuracy: 0.5387\n",
      "Epoch 346/500\n",
      "5063/5063 [==============================] - 1s 114us/sample - loss: 0.9670 - accuracy: 0.5388 - val_loss: 0.9613 - val_accuracy: 0.5308\n",
      "Epoch 347/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9676 - accuracy: 0.5384 - val_loss: 0.9592 - val_accuracy: 0.5379\n",
      "Epoch 348/500\n",
      "5063/5063 [==============================] - 1s 127us/sample - loss: 0.9670 - accuracy: 0.5398 - val_loss: 0.9599 - val_accuracy: 0.5332\n",
      "Epoch 349/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9672 - accuracy: 0.5402 - val_loss: 0.9586 - val_accuracy: 0.5355\n",
      "Epoch 350/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9668 - accuracy: 0.5376 - val_loss: 0.9584 - val_accuracy: 0.5355\n",
      "Epoch 351/500\n",
      "5063/5063 [==============================] - 1s 130us/sample - loss: 0.9672 - accuracy: 0.5402 - val_loss: 0.9584 - val_accuracy: 0.5363\n",
      "Epoch 352/500\n",
      "5063/5063 [==============================] - 1s 113us/sample - loss: 0.9674 - accuracy: 0.5396 - val_loss: 0.9592 - val_accuracy: 0.5379\n",
      "Epoch 353/500\n",
      "5063/5063 [==============================] - 1s 129us/sample - loss: 0.9670 - accuracy: 0.5343 - val_loss: 0.9606 - val_accuracy: 0.5316\n",
      "Epoch 354/500\n",
      "5063/5063 [==============================] - 1s 121us/sample - loss: 0.9671 - accuracy: 0.5398 - val_loss: 0.9606 - val_accuracy: 0.5332\n",
      "Epoch 355/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9672 - accuracy: 0.5366 - val_loss: 0.9604 - val_accuracy: 0.5332\n",
      "Epoch 356/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9670 - accuracy: 0.5400 - val_loss: 0.9609 - val_accuracy: 0.5324\n",
      "Epoch 357/500\n",
      "5063/5063 [==============================] - 1s 129us/sample - loss: 0.9673 - accuracy: 0.5386 - val_loss: 0.9598 - val_accuracy: 0.5332\n",
      "Epoch 358/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9671 - accuracy: 0.5380 - val_loss: 0.9589 - val_accuracy: 0.5355\n",
      "Epoch 359/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9671 - accuracy: 0.5396 - val_loss: 0.9585 - val_accuracy: 0.5355\n",
      "Epoch 360/500\n",
      "5063/5063 [==============================] - 1s 172us/sample - loss: 0.9669 - accuracy: 0.5368 - val_loss: 0.9594 - val_accuracy: 0.5363\n",
      "Epoch 361/500\n",
      "5063/5063 [==============================] - 1s 132us/sample - loss: 0.9669 - accuracy: 0.5376 - val_loss: 0.9587 - val_accuracy: 0.5348\n",
      "Epoch 362/500\n",
      "5063/5063 [==============================] - 1s 147us/sample - loss: 0.9671 - accuracy: 0.5372 - val_loss: 0.9585 - val_accuracy: 0.5340\n",
      "Epoch 363/500\n",
      "5063/5063 [==============================] - 1s 137us/sample - loss: 0.9669 - accuracy: 0.5396 - val_loss: 0.9582 - val_accuracy: 0.5371\n",
      "Epoch 364/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9667 - accuracy: 0.5412 - val_loss: 0.9598 - val_accuracy: 0.5419\n",
      "Epoch 365/500\n",
      "5063/5063 [==============================] - 1s 116us/sample - loss: 0.9667 - accuracy: 0.5388 - val_loss: 0.9585 - val_accuracy: 0.5371\n",
      "Epoch 366/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9663 - accuracy: 0.5396 - val_loss: 0.9591 - val_accuracy: 0.5379\n",
      "Epoch 367/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9669 - accuracy: 0.5380 - val_loss: 0.9583 - val_accuracy: 0.5379\n",
      "Epoch 368/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9667 - accuracy: 0.5370 - val_loss: 0.9583 - val_accuracy: 0.5355\n",
      "Epoch 369/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9667 - accuracy: 0.5382 - val_loss: 0.9584 - val_accuracy: 0.5387\n",
      "Epoch 370/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9666 - accuracy: 0.5384 - val_loss: 0.9585 - val_accuracy: 0.5355\n",
      "Epoch 371/500\n",
      "5063/5063 [==============================] - 1s 108us/sample - loss: 0.9665 - accuracy: 0.5366 - val_loss: 0.9602 - val_accuracy: 0.5340\n",
      "Epoch 372/500\n",
      "5063/5063 [==============================] - 1s 150us/sample - loss: 0.9662 - accuracy: 0.5422 - val_loss: 0.9583 - val_accuracy: 0.5387\n",
      "Epoch 373/500\n",
      "5063/5063 [==============================] - 1s 135us/sample - loss: 0.9666 - accuracy: 0.5400 - val_loss: 0.9582 - val_accuracy: 0.5363\n",
      "Epoch 374/500\n",
      "5063/5063 [==============================] - 1s 140us/sample - loss: 0.9667 - accuracy: 0.5398 - val_loss: 0.9583 - val_accuracy: 0.5379\n",
      "Epoch 375/500\n",
      "5063/5063 [==============================] - 1s 134us/sample - loss: 0.9662 - accuracy: 0.5370 - val_loss: 0.9596 - val_accuracy: 0.5411\n",
      "Epoch 376/500\n",
      "5063/5063 [==============================] - 1s 116us/sample - loss: 0.9667 - accuracy: 0.5386 - val_loss: 0.9587 - val_accuracy: 0.5340\n",
      "Epoch 377/500\n",
      "5063/5063 [==============================] - 1s 149us/sample - loss: 0.9666 - accuracy: 0.5394 - val_loss: 0.9584 - val_accuracy: 0.5371\n",
      "Epoch 378/500\n",
      "5063/5063 [==============================] - 1s 138us/sample - loss: 0.9665 - accuracy: 0.5404 - val_loss: 0.9590 - val_accuracy: 0.5387\n",
      "Epoch 379/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9663 - accuracy: 0.5416 - val_loss: 0.9584 - val_accuracy: 0.5379\n",
      "Epoch 380/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9662 - accuracy: 0.5382 - val_loss: 0.9586 - val_accuracy: 0.5348\n",
      "Epoch 381/500\n",
      "5063/5063 [==============================] - 1s 106us/sample - loss: 0.9668 - accuracy: 0.5374 - val_loss: 0.9600 - val_accuracy: 0.5332\n",
      "Epoch 382/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9666 - accuracy: 0.5384 - val_loss: 0.9594 - val_accuracy: 0.5348\n",
      "Epoch 383/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9663 - accuracy: 0.5364 - val_loss: 0.9602 - val_accuracy: 0.5411\n",
      "Epoch 384/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9669 - accuracy: 0.5370 - val_loss: 0.9624 - val_accuracy: 0.5261\n",
      "Epoch 385/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9665 - accuracy: 0.5408 - val_loss: 0.9597 - val_accuracy: 0.5355\n",
      "Epoch 386/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9668 - accuracy: 0.5392 - val_loss: 0.9637 - val_accuracy: 0.5269\n",
      "Epoch 387/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9667 - accuracy: 0.5384 - val_loss: 0.9584 - val_accuracy: 0.5355\n",
      "Epoch 388/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9663 - accuracy: 0.5384 - val_loss: 0.9604 - val_accuracy: 0.5340\n",
      "Epoch 389/500\n",
      "5063/5063 [==============================] - 1s 170us/sample - loss: 0.9663 - accuracy: 0.5378 - val_loss: 0.9604 - val_accuracy: 0.5403\n",
      "Epoch 390/500\n",
      "5063/5063 [==============================] - 1s 138us/sample - loss: 0.9666 - accuracy: 0.5378 - val_loss: 0.9581 - val_accuracy: 0.5348\n",
      "Epoch 391/500\n",
      "5063/5063 [==============================] - 1s 146us/sample - loss: 0.9665 - accuracy: 0.5408 - val_loss: 0.9582 - val_accuracy: 0.5355\n",
      "Epoch 392/500\n",
      "5063/5063 [==============================] - 1s 136us/sample - loss: 0.9665 - accuracy: 0.5392 - val_loss: 0.9593 - val_accuracy: 0.5340\n",
      "Epoch 393/500\n",
      "5063/5063 [==============================] - 1s 108us/sample - loss: 0.9664 - accuracy: 0.5376 - val_loss: 0.9588 - val_accuracy: 0.5355\n",
      "Epoch 394/500\n",
      "5063/5063 [==============================] - 1s 166us/sample - loss: 0.9661 - accuracy: 0.5382 - val_loss: 0.9582 - val_accuracy: 0.5363\n",
      "Epoch 395/500\n",
      "5063/5063 [==============================] - 1s 134us/sample - loss: 0.9663 - accuracy: 0.5394 - val_loss: 0.9603 - val_accuracy: 0.5332\n",
      "Epoch 396/500\n",
      "5063/5063 [==============================] - 1s 131us/sample - loss: 0.9661 - accuracy: 0.5372 - val_loss: 0.9585 - val_accuracy: 0.5348\n",
      "Epoch 397/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9662 - accuracy: 0.5386 - val_loss: 0.9587 - val_accuracy: 0.5379\n",
      "Epoch 398/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9657 - accuracy: 0.5386 - val_loss: 0.9583 - val_accuracy: 0.5355\n",
      "Epoch 399/500\n",
      "5063/5063 [==============================] - 1s 122us/sample - loss: 0.9664 - accuracy: 0.5378 - val_loss: 0.9583 - val_accuracy: 0.5371\n",
      "Epoch 400/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9662 - accuracy: 0.5384 - val_loss: 0.9594 - val_accuracy: 0.5348\n",
      "Epoch 401/500\n",
      "5063/5063 [==============================] - 1s 116us/sample - loss: 0.9661 - accuracy: 0.5386 - val_loss: 0.9587 - val_accuracy: 0.5340\n",
      "Epoch 402/500\n",
      "5063/5063 [==============================] - 1s 121us/sample - loss: 0.9661 - accuracy: 0.5360 - val_loss: 0.9582 - val_accuracy: 0.5363\n",
      "Epoch 403/500\n",
      "5063/5063 [==============================] - 1s 133us/sample - loss: 0.9659 - accuracy: 0.5376 - val_loss: 0.9594 - val_accuracy: 0.5340\n",
      "Epoch 404/500\n",
      "5063/5063 [==============================] - 1s 165us/sample - loss: 0.9660 - accuracy: 0.5390 - val_loss: 0.9581 - val_accuracy: 0.5355\n",
      "Epoch 405/500\n",
      "5063/5063 [==============================] - 1s 134us/sample - loss: 0.9662 - accuracy: 0.5392 - val_loss: 0.9592 - val_accuracy: 0.5387\n",
      "Epoch 406/500\n",
      "5063/5063 [==============================] - 1s 129us/sample - loss: 0.9661 - accuracy: 0.5392 - val_loss: 0.9583 - val_accuracy: 0.5348\n",
      "Epoch 407/500\n",
      "5063/5063 [==============================] - 1s 172us/sample - loss: 0.9656 - accuracy: 0.5394 - val_loss: 0.9589 - val_accuracy: 0.5348\n",
      "Epoch 408/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9663 - accuracy: 0.5398 - val_loss: 0.9587 - val_accuracy: 0.5340\n",
      "Epoch 409/500\n",
      "5063/5063 [==============================] - 1s 109us/sample - loss: 0.9658 - accuracy: 0.5384 - val_loss: 0.9739 - val_accuracy: 0.5213\n",
      "Epoch 410/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9668 - accuracy: 0.5388 - val_loss: 0.9591 - val_accuracy: 0.5340\n",
      "Epoch 411/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9661 - accuracy: 0.5392 - val_loss: 0.9584 - val_accuracy: 0.5355\n",
      "Epoch 412/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9658 - accuracy: 0.5402 - val_loss: 0.9671 - val_accuracy: 0.5221\n",
      "Epoch 413/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9662 - accuracy: 0.5360 - val_loss: 0.9582 - val_accuracy: 0.5355\n",
      "Epoch 414/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9659 - accuracy: 0.5402 - val_loss: 0.9637 - val_accuracy: 0.5269\n",
      "Epoch 415/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9657 - accuracy: 0.5402 - val_loss: 0.9586 - val_accuracy: 0.5348\n",
      "Epoch 416/500\n",
      "5063/5063 [==============================] - 0s 99us/sample - loss: 0.9656 - accuracy: 0.5396 - val_loss: 0.9613 - val_accuracy: 0.5292\n",
      "Epoch 417/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9660 - accuracy: 0.5394 - val_loss: 0.9588 - val_accuracy: 0.5340\n",
      "Epoch 418/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9661 - accuracy: 0.5372 - val_loss: 0.9589 - val_accuracy: 0.5340\n",
      "Epoch 419/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9660 - accuracy: 0.5364 - val_loss: 0.9581 - val_accuracy: 0.5355\n",
      "Epoch 420/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9660 - accuracy: 0.5404 - val_loss: 0.9592 - val_accuracy: 0.5355\n",
      "Epoch 421/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9657 - accuracy: 0.5400 - val_loss: 0.9581 - val_accuracy: 0.5355\n",
      "Epoch 422/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9659 - accuracy: 0.5374 - val_loss: 0.9587 - val_accuracy: 0.5340\n",
      "Epoch 423/500\n",
      "5063/5063 [==============================] - 1s 125us/sample - loss: 0.9654 - accuracy: 0.5412 - val_loss: 0.9687 - val_accuracy: 0.5213\n",
      "Epoch 424/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9654 - accuracy: 0.5408 - val_loss: 0.9592 - val_accuracy: 0.5395\n",
      "Epoch 425/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9655 - accuracy: 0.5404 - val_loss: 0.9583 - val_accuracy: 0.5348\n",
      "Epoch 426/500\n",
      "5063/5063 [==============================] - 1s 105us/sample - loss: 0.9657 - accuracy: 0.5366 - val_loss: 0.9620 - val_accuracy: 0.5276\n",
      "Epoch 427/500\n",
      "5063/5063 [==============================] - 0s 99us/sample - loss: 0.9656 - accuracy: 0.5386 - val_loss: 0.9597 - val_accuracy: 0.5316\n",
      "Epoch 428/500\n",
      "5063/5063 [==============================] - 1s 101us/sample - loss: 0.9656 - accuracy: 0.5374 - val_loss: 0.9587 - val_accuracy: 0.5371\n",
      "Epoch 429/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9658 - accuracy: 0.5366 - val_loss: 0.9610 - val_accuracy: 0.5292\n",
      "Epoch 430/500\n",
      "5063/5063 [==============================] - 1s 102us/sample - loss: 0.9658 - accuracy: 0.5408 - val_loss: 0.9596 - val_accuracy: 0.5411\n",
      "Epoch 431/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9659 - accuracy: 0.5390 - val_loss: 0.9599 - val_accuracy: 0.5324\n",
      "Epoch 432/500\n",
      "5063/5063 [==============================] - 1s 144us/sample - loss: 0.9652 - accuracy: 0.5402 - val_loss: 0.9588 - val_accuracy: 0.5332\n",
      "Epoch 433/500\n",
      "5063/5063 [==============================] - 1s 106us/sample - loss: 0.9656 - accuracy: 0.5404 - val_loss: 0.9582 - val_accuracy: 0.5379\n",
      "Epoch 434/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9657 - accuracy: 0.5380 - val_loss: 0.9589 - val_accuracy: 0.5340\n",
      "Epoch 435/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9657 - accuracy: 0.5388 - val_loss: 0.9585 - val_accuracy: 0.5340\n",
      "Epoch 436/500\n",
      "5063/5063 [==============================] - 1s 104us/sample - loss: 0.9653 - accuracy: 0.5382 - val_loss: 0.9588 - val_accuracy: 0.5371\n",
      "Epoch 437/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9656 - accuracy: 0.5408 - val_loss: 0.9597 - val_accuracy: 0.5316\n",
      "Epoch 438/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9648 - accuracy: 0.5394 - val_loss: 0.9614 - val_accuracy: 0.5261\n",
      "Epoch 439/500\n",
      "5063/5063 [==============================] - 1s 101us/sample - loss: 0.9647 - accuracy: 0.5406 - val_loss: 0.9579 - val_accuracy: 0.5355\n",
      "Epoch 440/500\n",
      "5063/5063 [==============================] - 1s 103us/sample - loss: 0.9659 - accuracy: 0.5394 - val_loss: 0.9589 - val_accuracy: 0.5332\n",
      "Epoch 441/500\n",
      "5063/5063 [==============================] - 1s 100us/sample - loss: 0.9655 - accuracy: 0.5396 - val_loss: 0.9585 - val_accuracy: 0.5371\n",
      "Epoch 442/500\n",
      "5063/5063 [==============================] - 0s 99us/sample - loss: 0.9653 - accuracy: 0.5404 - val_loss: 0.9626 - val_accuracy: 0.5292\n",
      "Epoch 443/500\n",
      "5063/5063 [==============================] - 1s 99us/sample - loss: 0.9655 - accuracy: 0.5382 - val_loss: 0.9597 - val_accuracy: 0.5403\n",
      "Epoch 444/500\n",
      "5063/5063 [==============================] - 0s 98us/sample - loss: 0.9658 - accuracy: 0.5392 - val_loss: 0.9586 - val_accuracy: 0.5332\n",
      "Epoch 445/500\n",
      "5063/5063 [==============================] - 1s 160us/sample - loss: 0.9654 - accuracy: 0.5368 - val_loss: 0.9583 - val_accuracy: 0.5340\n",
      "Epoch 446/500\n",
      "5063/5063 [==============================] - 1s 161us/sample - loss: 0.9654 - accuracy: 0.5412 - val_loss: 0.9591 - val_accuracy: 0.5324\n",
      "Epoch 447/500\n",
      "5063/5063 [==============================] - 1s 141us/sample - loss: 0.9654 - accuracy: 0.5372 - val_loss: 0.9590 - val_accuracy: 0.5340\n",
      "Epoch 448/500\n",
      "5063/5063 [==============================] - 1s 127us/sample - loss: 0.9654 - accuracy: 0.5378 - val_loss: 0.9593 - val_accuracy: 0.5395\n",
      "Epoch 449/500\n",
      "5063/5063 [==============================] - 1s 141us/sample - loss: 0.9653 - accuracy: 0.5384 - val_loss: 0.9581 - val_accuracy: 0.5355\n",
      "Epoch 450/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9655 - accuracy: 0.5376 - val_loss: 0.9601 - val_accuracy: 0.5292\n",
      "Epoch 451/500\n",
      "5063/5063 [==============================] - 1s 125us/sample - loss: 0.9653 - accuracy: 0.5392 - val_loss: 0.9614 - val_accuracy: 0.5276\n",
      "Epoch 452/500\n",
      "5063/5063 [==============================] - 1s 116us/sample - loss: 0.9653 - accuracy: 0.5400 - val_loss: 0.9580 - val_accuracy: 0.5379\n",
      "Epoch 453/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9653 - accuracy: 0.5412 - val_loss: 0.9583 - val_accuracy: 0.5332\n",
      "Epoch 454/500\n",
      "5063/5063 [==============================] - 1s 106us/sample - loss: 0.9652 - accuracy: 0.5388 - val_loss: 0.9583 - val_accuracy: 0.5363\n",
      "Epoch 455/500\n",
      "5063/5063 [==============================] - 1s 110us/sample - loss: 0.9652 - accuracy: 0.5398 - val_loss: 0.9582 - val_accuracy: 0.5332\n",
      "Epoch 456/500\n",
      "5063/5063 [==============================] - 1s 124us/sample - loss: 0.9650 - accuracy: 0.5396 - val_loss: 0.9581 - val_accuracy: 0.5355\n",
      "Epoch 457/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9655 - accuracy: 0.5398 - val_loss: 0.9585 - val_accuracy: 0.5340\n",
      "Epoch 458/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9654 - accuracy: 0.5390 - val_loss: 0.9612 - val_accuracy: 0.5276\n",
      "Epoch 459/500\n",
      "5063/5063 [==============================] - 1s 118us/sample - loss: 0.9652 - accuracy: 0.5372 - val_loss: 0.9580 - val_accuracy: 0.5379\n",
      "Epoch 460/500\n",
      "5063/5063 [==============================] - 1s 127us/sample - loss: 0.9653 - accuracy: 0.5390 - val_loss: 0.9596 - val_accuracy: 0.5300\n",
      "Epoch 461/500\n",
      "5063/5063 [==============================] - 1s 128us/sample - loss: 0.9647 - accuracy: 0.5426 - val_loss: 0.9585 - val_accuracy: 0.5371\n",
      "Epoch 462/500\n",
      "5063/5063 [==============================] - 1s 107us/sample - loss: 0.9652 - accuracy: 0.5424 - val_loss: 0.9581 - val_accuracy: 0.5371\n",
      "Epoch 463/500\n",
      "5063/5063 [==============================] - 1s 124us/sample - loss: 0.9653 - accuracy: 0.5392 - val_loss: 0.9582 - val_accuracy: 0.5371\n",
      "Epoch 464/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9651 - accuracy: 0.5398 - val_loss: 0.9582 - val_accuracy: 0.5348\n",
      "Epoch 465/500\n",
      "5063/5063 [==============================] - 1s 115us/sample - loss: 0.9653 - accuracy: 0.5412 - val_loss: 0.9580 - val_accuracy: 0.5387\n",
      "Epoch 466/500\n",
      "5063/5063 [==============================] - 1s 127us/sample - loss: 0.9653 - accuracy: 0.5376 - val_loss: 0.9582 - val_accuracy: 0.5340\n",
      "Epoch 467/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9652 - accuracy: 0.5406 - val_loss: 0.9580 - val_accuracy: 0.5379\n",
      "Epoch 468/500\n",
      "5063/5063 [==============================] - 1s 124us/sample - loss: 0.9651 - accuracy: 0.5412 - val_loss: 0.9592 - val_accuracy: 0.5332\n",
      "Epoch 469/500\n",
      "5063/5063 [==============================] - 1s 121us/sample - loss: 0.9651 - accuracy: 0.5402 - val_loss: 0.9593 - val_accuracy: 0.5324\n",
      "Epoch 470/500\n",
      "5063/5063 [==============================] - 1s 113us/sample - loss: 0.9641 - accuracy: 0.5432 - val_loss: 0.9582 - val_accuracy: 0.5340\n",
      "Epoch 471/500\n",
      "5063/5063 [==============================] - 1s 109us/sample - loss: 0.9648 - accuracy: 0.5416 - val_loss: 0.9589 - val_accuracy: 0.5379\n",
      "Epoch 472/500\n",
      "5063/5063 [==============================] - 1s 138us/sample - loss: 0.9650 - accuracy: 0.5386 - val_loss: 0.9615 - val_accuracy: 0.5300\n",
      "Epoch 473/500\n",
      "5063/5063 [==============================] - 1s 146us/sample - loss: 0.9651 - accuracy: 0.5396 - val_loss: 0.9596 - val_accuracy: 0.5292\n",
      "Epoch 474/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9652 - accuracy: 0.5406 - val_loss: 0.9584 - val_accuracy: 0.5324\n",
      "Epoch 475/500\n",
      "5063/5063 [==============================] - 1s 134us/sample - loss: 0.9649 - accuracy: 0.5392 - val_loss: 0.9582 - val_accuracy: 0.5363\n",
      "Epoch 476/500\n",
      "5063/5063 [==============================] - 1s 132us/sample - loss: 0.9650 - accuracy: 0.5414 - val_loss: 0.9630 - val_accuracy: 0.5308\n",
      "Epoch 477/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9652 - accuracy: 0.5410 - val_loss: 0.9582 - val_accuracy: 0.5363\n",
      "Epoch 478/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9646 - accuracy: 0.5400 - val_loss: 0.9627 - val_accuracy: 0.5292\n",
      "Epoch 479/500\n",
      "5063/5063 [==============================] - 1s 119us/sample - loss: 0.9647 - accuracy: 0.5404 - val_loss: 0.9583 - val_accuracy: 0.5340\n",
      "Epoch 480/500\n",
      "5063/5063 [==============================] - 1s 120us/sample - loss: 0.9647 - accuracy: 0.5398 - val_loss: 0.9592 - val_accuracy: 0.5332\n",
      "Epoch 481/500\n",
      "5063/5063 [==============================] - 1s 114us/sample - loss: 0.9650 - accuracy: 0.5386 - val_loss: 0.9600 - val_accuracy: 0.5292\n",
      "Epoch 482/500\n",
      "5063/5063 [==============================] - 1s 126us/sample - loss: 0.9653 - accuracy: 0.5424 - val_loss: 0.9618 - val_accuracy: 0.5292\n",
      "Epoch 483/500\n",
      "5063/5063 [==============================] - 1s 147us/sample - loss: 0.9650 - accuracy: 0.5404 - val_loss: 0.9592 - val_accuracy: 0.5324\n",
      "Epoch 484/500\n",
      "5063/5063 [==============================] - 1s 141us/sample - loss: 0.9650 - accuracy: 0.5392 - val_loss: 0.9589 - val_accuracy: 0.5316\n",
      "Epoch 485/500\n",
      "5063/5063 [==============================] - 1s 154us/sample - loss: 0.9649 - accuracy: 0.5404 - val_loss: 0.9580 - val_accuracy: 0.5379\n",
      "Epoch 486/500\n",
      "5063/5063 [==============================] - 1s 122us/sample - loss: 0.9647 - accuracy: 0.5402 - val_loss: 0.9584 - val_accuracy: 0.5348\n",
      "Epoch 487/500\n",
      "5063/5063 [==============================] - 1s 117us/sample - loss: 0.9643 - accuracy: 0.5380 - val_loss: 0.9622 - val_accuracy: 0.5292\n",
      "Epoch 488/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5063/5063 [==============================] - 1s 114us/sample - loss: 0.9650 - accuracy: 0.5388 - val_loss: 0.9592 - val_accuracy: 0.5324\n",
      "Epoch 489/500\n",
      "5063/5063 [==============================] - 1s 111us/sample - loss: 0.9652 - accuracy: 0.5400 - val_loss: 0.9579 - val_accuracy: 0.5387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a512e4710>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model03.fit(train_X03, train_y03, validation_split=validation_split,epochs=epochs,callbacks=[early_stoping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                2176      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 6,069\n",
      "Trainable params: 6,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model04.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5036 samples, validate on 1260 samples\n",
      "Epoch 1/500\n",
      "5036/5036 [==============================] - 2s 413us/sample - loss: 1.0673 - accuracy: 0.4591 - val_loss: 1.0614 - val_accuracy: 0.4627\n",
      "Epoch 2/500\n",
      "5036/5036 [==============================] - 1s 117us/sample - loss: 1.0613 - accuracy: 0.4591 - val_loss: 1.0589 - val_accuracy: 0.4627\n",
      "Epoch 3/500\n",
      "5036/5036 [==============================] - 1s 150us/sample - loss: 1.0591 - accuracy: 0.4591 - val_loss: 1.0560 - val_accuracy: 0.4627\n",
      "Epoch 4/500\n",
      "5036/5036 [==============================] - 1s 122us/sample - loss: 1.0546 - accuracy: 0.4591 - val_loss: 1.0505 - val_accuracy: 0.4627\n",
      "Epoch 5/500\n",
      "5036/5036 [==============================] - 1s 101us/sample - loss: 1.0502 - accuracy: 0.4591 - val_loss: 1.0442 - val_accuracy: 0.4627\n",
      "Epoch 6/500\n",
      "5036/5036 [==============================] - 1s 152us/sample - loss: 1.0443 - accuracy: 0.4591 - val_loss: 1.0348 - val_accuracy: 0.4627\n",
      "Epoch 7/500\n",
      "5036/5036 [==============================] - 1s 139us/sample - loss: 1.0378 - accuracy: 0.4591 - val_loss: 1.0263 - val_accuracy: 0.4627\n",
      "Epoch 8/500\n",
      "5036/5036 [==============================] - 1s 114us/sample - loss: 1.0317 - accuracy: 0.4861 - val_loss: 1.0215 - val_accuracy: 0.4754\n",
      "Epoch 9/500\n",
      "5036/5036 [==============================] - 1s 117us/sample - loss: 1.0261 - accuracy: 0.4990 - val_loss: 1.0171 - val_accuracy: 0.5198\n",
      "Epoch 10/500\n",
      "5036/5036 [==============================] - 1s 180us/sample - loss: 1.0221 - accuracy: 0.5032 - val_loss: 1.0056 - val_accuracy: 0.5159\n",
      "Epoch 11/500\n",
      "5036/5036 [==============================] - 1s 115us/sample - loss: 1.0192 - accuracy: 0.5060 - val_loss: 1.0016 - val_accuracy: 0.5159\n",
      "Epoch 12/500\n",
      "5036/5036 [==============================] - 1s 120us/sample - loss: 1.0166 - accuracy: 0.5087 - val_loss: 0.9993 - val_accuracy: 0.5238\n",
      "Epoch 13/500\n",
      "5036/5036 [==============================] - 1s 105us/sample - loss: 1.0143 - accuracy: 0.5097 - val_loss: 0.9968 - val_accuracy: 0.5206\n",
      "Epoch 14/500\n",
      "5036/5036 [==============================] - 1s 106us/sample - loss: 1.0126 - accuracy: 0.5089 - val_loss: 0.9961 - val_accuracy: 0.5167\n",
      "Epoch 15/500\n",
      "5036/5036 [==============================] - 1s 129us/sample - loss: 1.0104 - accuracy: 0.5091 - val_loss: 0.9952 - val_accuracy: 0.5222\n",
      "Epoch 16/500\n",
      "5036/5036 [==============================] - 1s 139us/sample - loss: 1.0096 - accuracy: 0.5135 - val_loss: 0.9931 - val_accuracy: 0.5190\n",
      "Epoch 17/500\n",
      "5036/5036 [==============================] - 1s 160us/sample - loss: 1.0089 - accuracy: 0.5097 - val_loss: 0.9918 - val_accuracy: 0.5278\n",
      "Epoch 18/500\n",
      "5036/5036 [==============================] - 1s 118us/sample - loss: 1.0069 - accuracy: 0.5129 - val_loss: 0.9917 - val_accuracy: 0.5246\n",
      "Epoch 19/500\n",
      "5036/5036 [==============================] - 1s 110us/sample - loss: 1.0056 - accuracy: 0.5157 - val_loss: 0.9896 - val_accuracy: 0.5294\n",
      "Epoch 20/500\n",
      "5036/5036 [==============================] - 1s 159us/sample - loss: 1.0043 - accuracy: 0.5135 - val_loss: 0.9888 - val_accuracy: 0.5286\n",
      "Epoch 21/500\n",
      "5036/5036 [==============================] - 1s 117us/sample - loss: 1.0031 - accuracy: 0.5165 - val_loss: 0.9880 - val_accuracy: 0.5278\n",
      "Epoch 22/500\n",
      "5036/5036 [==============================] - 1s 123us/sample - loss: 1.0012 - accuracy: 0.5195 - val_loss: 0.9873 - val_accuracy: 0.5302\n",
      "Epoch 23/500\n",
      "5036/5036 [==============================] - 1s 105us/sample - loss: 1.0012 - accuracy: 0.5163 - val_loss: 0.9873 - val_accuracy: 0.5238\n",
      "Epoch 24/500\n",
      "5036/5036 [==============================] - 1s 102us/sample - loss: 1.0003 - accuracy: 0.5123 - val_loss: 0.9861 - val_accuracy: 0.5294\n",
      "Epoch 25/500\n",
      "5036/5036 [==============================] - 1s 107us/sample - loss: 0.9988 - accuracy: 0.5131 - val_loss: 0.9855 - val_accuracy: 0.5278\n",
      "Epoch 26/500\n",
      "5036/5036 [==============================] - 1s 105us/sample - loss: 0.9976 - accuracy: 0.5185 - val_loss: 0.9864 - val_accuracy: 0.5198\n",
      "Epoch 27/500\n",
      "5036/5036 [==============================] - 1s 105us/sample - loss: 0.9972 - accuracy: 0.5167 - val_loss: 0.9849 - val_accuracy: 0.5262\n",
      "Epoch 28/500\n",
      "5036/5036 [==============================] - 1s 104us/sample - loss: 0.9965 - accuracy: 0.5181 - val_loss: 0.9846 - val_accuracy: 0.5270\n",
      "Epoch 29/500\n",
      "5036/5036 [==============================] - 1s 107us/sample - loss: 0.9956 - accuracy: 0.5187 - val_loss: 0.9836 - val_accuracy: 0.5294\n",
      "Epoch 30/500\n",
      "5036/5036 [==============================] - 1s 105us/sample - loss: 0.9955 - accuracy: 0.5179 - val_loss: 0.9836 - val_accuracy: 0.5254\n",
      "Epoch 31/500\n",
      "5036/5036 [==============================] - 1s 109us/sample - loss: 0.9949 - accuracy: 0.5183 - val_loss: 0.9829 - val_accuracy: 0.5302\n",
      "Epoch 32/500\n",
      "5036/5036 [==============================] - 1s 124us/sample - loss: 0.9937 - accuracy: 0.5205 - val_loss: 0.9823 - val_accuracy: 0.5302\n",
      "Epoch 33/500\n",
      "5036/5036 [==============================] - 1s 125us/sample - loss: 0.9932 - accuracy: 0.5210 - val_loss: 0.9921 - val_accuracy: 0.5056\n",
      "Epoch 34/500\n",
      "5036/5036 [==============================] - 1s 103us/sample - loss: 0.9923 - accuracy: 0.5187 - val_loss: 0.9816 - val_accuracy: 0.5310\n",
      "Epoch 35/500\n",
      "5036/5036 [==============================] - 1s 101us/sample - loss: 0.9915 - accuracy: 0.5197 - val_loss: 0.9853 - val_accuracy: 0.5119\n",
      "Epoch 36/500\n",
      "5036/5036 [==============================] - 1s 107us/sample - loss: 0.9926 - accuracy: 0.5214 - val_loss: 0.9852 - val_accuracy: 0.5222\n",
      "Epoch 37/500\n",
      "5036/5036 [==============================] - 0s 99us/sample - loss: 0.9911 - accuracy: 0.5187 - val_loss: 0.9807 - val_accuracy: 0.5317\n",
      "Epoch 38/500\n",
      "5036/5036 [==============================] - 1s 99us/sample - loss: 0.9906 - accuracy: 0.5208 - val_loss: 0.9841 - val_accuracy: 0.5262\n",
      "Epoch 39/500\n",
      "5036/5036 [==============================] - 1s 100us/sample - loss: 0.9896 - accuracy: 0.5210 - val_loss: 0.9808 - val_accuracy: 0.5254\n",
      "Epoch 40/500\n",
      "5036/5036 [==============================] - 1s 102us/sample - loss: 0.9894 - accuracy: 0.5193 - val_loss: 0.9807 - val_accuracy: 0.5302\n",
      "Epoch 41/500\n",
      "5036/5036 [==============================] - 0s 99us/sample - loss: 0.9892 - accuracy: 0.5246 - val_loss: 0.9837 - val_accuracy: 0.5254\n",
      "Epoch 42/500\n",
      "5036/5036 [==============================] - 0s 99us/sample - loss: 0.9885 - accuracy: 0.5218 - val_loss: 0.9793 - val_accuracy: 0.5286\n",
      "Epoch 43/500\n",
      "5036/5036 [==============================] - 0s 98us/sample - loss: 0.9884 - accuracy: 0.5256 - val_loss: 0.9796 - val_accuracy: 0.5302\n",
      "Epoch 44/500\n",
      "5036/5036 [==============================] - 1s 103us/sample - loss: 0.9874 - accuracy: 0.5238 - val_loss: 0.9790 - val_accuracy: 0.5278\n",
      "Epoch 45/500\n",
      "5036/5036 [==============================] - 1s 99us/sample - loss: 0.9867 - accuracy: 0.5270 - val_loss: 0.9825 - val_accuracy: 0.5310\n",
      "Epoch 46/500\n",
      "5036/5036 [==============================] - 1s 99us/sample - loss: 0.9870 - accuracy: 0.5250 - val_loss: 0.9791 - val_accuracy: 0.5286\n",
      "Epoch 47/500\n",
      "5036/5036 [==============================] - 1s 104us/sample - loss: 0.9866 - accuracy: 0.5242 - val_loss: 0.9787 - val_accuracy: 0.5230\n",
      "Epoch 48/500\n",
      "5036/5036 [==============================] - 1s 145us/sample - loss: 0.9864 - accuracy: 0.5218 - val_loss: 0.9787 - val_accuracy: 0.5214\n",
      "Epoch 49/500\n",
      "5036/5036 [==============================] - 1s 124us/sample - loss: 0.9869 - accuracy: 0.5232 - val_loss: 0.9855 - val_accuracy: 0.5175\n",
      "Epoch 50/500\n",
      "5036/5036 [==============================] - 1s 102us/sample - loss: 0.9856 - accuracy: 0.5256 - val_loss: 0.9785 - val_accuracy: 0.5302\n",
      "Epoch 51/500\n",
      "5036/5036 [==============================] - 1s 163us/sample - loss: 0.9855 - accuracy: 0.5252 - val_loss: 0.9787 - val_accuracy: 0.5286\n",
      "Epoch 52/500\n",
      "5036/5036 [==============================] - 1s 125us/sample - loss: 0.9852 - accuracy: 0.5240 - val_loss: 0.9797 - val_accuracy: 0.5310\n",
      "Epoch 53/500\n",
      "5036/5036 [==============================] - 1s 148us/sample - loss: 0.9842 - accuracy: 0.5258 - val_loss: 0.9786 - val_accuracy: 0.5302\n",
      "Epoch 54/500\n",
      "5036/5036 [==============================] - 1s 136us/sample - loss: 0.9844 - accuracy: 0.5260 - val_loss: 0.9778 - val_accuracy: 0.5286\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5036/5036 [==============================] - 1s 108us/sample - loss: 0.9840 - accuracy: 0.5276 - val_loss: 0.9779 - val_accuracy: 0.5198\n",
      "Epoch 56/500\n",
      "5036/5036 [==============================] - 1s 115us/sample - loss: 0.9835 - accuracy: 0.5282 - val_loss: 0.9775 - val_accuracy: 0.5238\n",
      "Epoch 57/500\n",
      "5036/5036 [==============================] - 1s 132us/sample - loss: 0.9844 - accuracy: 0.5264 - val_loss: 0.9780 - val_accuracy: 0.5294\n",
      "Epoch 58/500\n",
      "5036/5036 [==============================] - 1s 130us/sample - loss: 0.9838 - accuracy: 0.5262 - val_loss: 0.9784 - val_accuracy: 0.5302\n",
      "Epoch 59/500\n",
      "5036/5036 [==============================] - 1s 114us/sample - loss: 0.9839 - accuracy: 0.5278 - val_loss: 0.9900 - val_accuracy: 0.5127\n",
      "Epoch 60/500\n",
      "5036/5036 [==============================] - 1s 112us/sample - loss: 0.9837 - accuracy: 0.5274 - val_loss: 0.9786 - val_accuracy: 0.5206\n",
      "Epoch 61/500\n",
      "5036/5036 [==============================] - 1s 115us/sample - loss: 0.9839 - accuracy: 0.5284 - val_loss: 0.9784 - val_accuracy: 0.5286\n",
      "Epoch 62/500\n",
      "5036/5036 [==============================] - 1s 125us/sample - loss: 0.9827 - accuracy: 0.5248 - val_loss: 0.9824 - val_accuracy: 0.5262\n",
      "Epoch 63/500\n",
      "5036/5036 [==============================] - 1s 112us/sample - loss: 0.9824 - accuracy: 0.5282 - val_loss: 0.9806 - val_accuracy: 0.5270\n",
      "Epoch 64/500\n",
      "5036/5036 [==============================] - 1s 127us/sample - loss: 0.9822 - accuracy: 0.5274 - val_loss: 0.9786 - val_accuracy: 0.5310\n",
      "Epoch 65/500\n",
      "5036/5036 [==============================] - 1s 133us/sample - loss: 0.9819 - accuracy: 0.5284 - val_loss: 0.9848 - val_accuracy: 0.5135\n",
      "Epoch 66/500\n",
      "5036/5036 [==============================] - 1s 115us/sample - loss: 0.9825 - accuracy: 0.5302 - val_loss: 0.9769 - val_accuracy: 0.5270\n",
      "Epoch 67/500\n",
      "5036/5036 [==============================] - 1s 133us/sample - loss: 0.9821 - accuracy: 0.5302 - val_loss: 0.9823 - val_accuracy: 0.5238\n",
      "Epoch 68/500\n",
      "5036/5036 [==============================] - 1s 152us/sample - loss: 0.9819 - accuracy: 0.5304 - val_loss: 0.9793 - val_accuracy: 0.5310\n",
      "Epoch 69/500\n",
      "5036/5036 [==============================] - 1s 114us/sample - loss: 0.9818 - accuracy: 0.5256 - val_loss: 0.9796 - val_accuracy: 0.5286\n",
      "Epoch 70/500\n",
      "5036/5036 [==============================] - 1s 110us/sample - loss: 0.9821 - accuracy: 0.5280 - val_loss: 0.9813 - val_accuracy: 0.5222\n",
      "Epoch 71/500\n",
      "5036/5036 [==============================] - 1s 105us/sample - loss: 0.9814 - accuracy: 0.5318 - val_loss: 0.9831 - val_accuracy: 0.5183\n",
      "Epoch 72/500\n",
      "5036/5036 [==============================] - 1s 113us/sample - loss: 0.9818 - accuracy: 0.5292 - val_loss: 0.9783 - val_accuracy: 0.5294\n",
      "Epoch 73/500\n",
      "5036/5036 [==============================] - 1s 110us/sample - loss: 0.9814 - accuracy: 0.5274 - val_loss: 0.9810 - val_accuracy: 0.5238\n",
      "Epoch 74/500\n",
      "5036/5036 [==============================] - 1s 117us/sample - loss: 0.9802 - accuracy: 0.5262 - val_loss: 0.9779 - val_accuracy: 0.5254\n",
      "Epoch 75/500\n",
      "5036/5036 [==============================] - 1s 116us/sample - loss: 0.9804 - accuracy: 0.5270 - val_loss: 0.9783 - val_accuracy: 0.5294\n",
      "Epoch 76/500\n",
      "5036/5036 [==============================] - 1s 100us/sample - loss: 0.9810 - accuracy: 0.5290 - val_loss: 0.9765 - val_accuracy: 0.5246\n",
      "Epoch 77/500\n",
      "5036/5036 [==============================] - 1s 110us/sample - loss: 0.9803 - accuracy: 0.5298 - val_loss: 0.9826 - val_accuracy: 0.5190\n",
      "Epoch 78/500\n",
      "5036/5036 [==============================] - 1s 120us/sample - loss: 0.9796 - accuracy: 0.5288 - val_loss: 0.9793 - val_accuracy: 0.5183\n",
      "Epoch 79/500\n",
      "5036/5036 [==============================] - 1s 135us/sample - loss: 0.9812 - accuracy: 0.5276 - val_loss: 0.9765 - val_accuracy: 0.5222\n",
      "Epoch 80/500\n",
      "5036/5036 [==============================] - 1s 125us/sample - loss: 0.9798 - accuracy: 0.5284 - val_loss: 0.9765 - val_accuracy: 0.5254\n",
      "Epoch 81/500\n",
      "5036/5036 [==============================] - 1s 129us/sample - loss: 0.9801 - accuracy: 0.5304 - val_loss: 0.9814 - val_accuracy: 0.5222\n",
      "Epoch 82/500\n",
      "5036/5036 [==============================] - 1s 110us/sample - loss: 0.9799 - accuracy: 0.5304 - val_loss: 0.9803 - val_accuracy: 0.5230\n",
      "Epoch 83/500\n",
      "5036/5036 [==============================] - 1s 113us/sample - loss: 0.9807 - accuracy: 0.5270 - val_loss: 0.9782 - val_accuracy: 0.5278\n",
      "Epoch 84/500\n",
      "5036/5036 [==============================] - 1s 125us/sample - loss: 0.9799 - accuracy: 0.5282 - val_loss: 0.9775 - val_accuracy: 0.5246\n",
      "Epoch 85/500\n",
      "5036/5036 [==============================] - 1s 135us/sample - loss: 0.9789 - accuracy: 0.5328 - val_loss: 0.9792 - val_accuracy: 0.5278\n",
      "Epoch 86/500\n",
      "5036/5036 [==============================] - 1s 141us/sample - loss: 0.9799 - accuracy: 0.5306 - val_loss: 0.9839 - val_accuracy: 0.5159\n",
      "Epoch 87/500\n",
      "5036/5036 [==============================] - 1s 151us/sample - loss: 0.9793 - accuracy: 0.5320 - val_loss: 0.9804 - val_accuracy: 0.5222\n",
      "Epoch 88/500\n",
      "5036/5036 [==============================] - 1s 129us/sample - loss: 0.9791 - accuracy: 0.5324 - val_loss: 0.9775 - val_accuracy: 0.5286\n",
      "Epoch 89/500\n",
      "5036/5036 [==============================] - 1s 107us/sample - loss: 0.9789 - accuracy: 0.5304 - val_loss: 0.9767 - val_accuracy: 0.5246\n",
      "Epoch 90/500\n",
      "5036/5036 [==============================] - 1s 115us/sample - loss: 0.9777 - accuracy: 0.5294 - val_loss: 0.9833 - val_accuracy: 0.5175\n",
      "Epoch 91/500\n",
      "5036/5036 [==============================] - 1s 162us/sample - loss: 0.9788 - accuracy: 0.5302 - val_loss: 0.9773 - val_accuracy: 0.5270\n",
      "Epoch 92/500\n",
      "5036/5036 [==============================] - 1s 128us/sample - loss: 0.9782 - accuracy: 0.5326 - val_loss: 0.9839 - val_accuracy: 0.5135\n",
      "Epoch 93/500\n",
      "5036/5036 [==============================] - 1s 136us/sample - loss: 0.9789 - accuracy: 0.5306 - val_loss: 0.9764 - val_accuracy: 0.5230\n",
      "Epoch 94/500\n",
      "5036/5036 [==============================] - 1s 126us/sample - loss: 0.9791 - accuracy: 0.5322 - val_loss: 0.9795 - val_accuracy: 0.5222\n",
      "Epoch 95/500\n",
      "5036/5036 [==============================] - 1s 116us/sample - loss: 0.9788 - accuracy: 0.5326 - val_loss: 0.9785 - val_accuracy: 0.5262\n",
      "Epoch 96/500\n",
      "5036/5036 [==============================] - 1s 128us/sample - loss: 0.9786 - accuracy: 0.5300 - val_loss: 0.9761 - val_accuracy: 0.5246\n",
      "Epoch 97/500\n",
      "5036/5036 [==============================] - 1s 119us/sample - loss: 0.9788 - accuracy: 0.5306 - val_loss: 0.9779 - val_accuracy: 0.5262\n",
      "Epoch 98/500\n",
      "5036/5036 [==============================] - 1s 116us/sample - loss: 0.9784 - accuracy: 0.5282 - val_loss: 0.9764 - val_accuracy: 0.5262\n",
      "Epoch 99/500\n",
      "5036/5036 [==============================] - 1s 112us/sample - loss: 0.9777 - accuracy: 0.5310 - val_loss: 0.9773 - val_accuracy: 0.5238\n",
      "Epoch 100/500\n",
      "5036/5036 [==============================] - 1s 139us/sample - loss: 0.9781 - accuracy: 0.5312 - val_loss: 0.9829 - val_accuracy: 0.5175\n",
      "Epoch 101/500\n",
      "5036/5036 [==============================] - 1s 136us/sample - loss: 0.9777 - accuracy: 0.5310 - val_loss: 0.9767 - val_accuracy: 0.5270\n",
      "Epoch 102/500\n",
      "5036/5036 [==============================] - 1s 119us/sample - loss: 0.9781 - accuracy: 0.5298 - val_loss: 0.9785 - val_accuracy: 0.5270\n",
      "Epoch 103/500\n",
      "5036/5036 [==============================] - 1s 116us/sample - loss: 0.9775 - accuracy: 0.5312 - val_loss: 0.9766 - val_accuracy: 0.5254\n",
      "Epoch 104/500\n",
      "5036/5036 [==============================] - 1s 128us/sample - loss: 0.9780 - accuracy: 0.5304 - val_loss: 0.9758 - val_accuracy: 0.5246\n",
      "Epoch 105/500\n",
      "5036/5036 [==============================] - 1s 118us/sample - loss: 0.9777 - accuracy: 0.5300 - val_loss: 0.9759 - val_accuracy: 0.5254\n",
      "Epoch 106/500\n",
      "5036/5036 [==============================] - 1s 112us/sample - loss: 0.9781 - accuracy: 0.5296 - val_loss: 0.9770 - val_accuracy: 0.5222\n",
      "Epoch 107/500\n",
      "5036/5036 [==============================] - 1s 132us/sample - loss: 0.9774 - accuracy: 0.5332 - val_loss: 0.9757 - val_accuracy: 0.5246\n",
      "Epoch 108/500\n",
      "5036/5036 [==============================] - 1s 110us/sample - loss: 0.9783 - accuracy: 0.5296 - val_loss: 0.9760 - val_accuracy: 0.5262\n",
      "Epoch 109/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5036/5036 [==============================] - 1s 126us/sample - loss: 0.9770 - accuracy: 0.5340 - val_loss: 0.9757 - val_accuracy: 0.5238\n",
      "Epoch 110/500\n",
      "5036/5036 [==============================] - 1s 141us/sample - loss: 0.9770 - accuracy: 0.5326 - val_loss: 0.9841 - val_accuracy: 0.5151\n",
      "Epoch 111/500\n",
      "5036/5036 [==============================] - 1s 159us/sample - loss: 0.9772 - accuracy: 0.5296 - val_loss: 0.9775 - val_accuracy: 0.5246\n",
      "Epoch 112/500\n",
      "5036/5036 [==============================] - 1s 141us/sample - loss: 0.9763 - accuracy: 0.5302 - val_loss: 0.9757 - val_accuracy: 0.5214\n",
      "Epoch 113/500\n",
      "5036/5036 [==============================] - 1s 129us/sample - loss: 0.9764 - accuracy: 0.5320 - val_loss: 0.9812 - val_accuracy: 0.5198\n",
      "Epoch 114/500\n",
      "5036/5036 [==============================] - 1s 113us/sample - loss: 0.9766 - accuracy: 0.5304 - val_loss: 0.9761 - val_accuracy: 0.5270\n",
      "Epoch 115/500\n",
      "5036/5036 [==============================] - 1s 122us/sample - loss: 0.9765 - accuracy: 0.5306 - val_loss: 0.9754 - val_accuracy: 0.5262\n",
      "Epoch 116/500\n",
      "5036/5036 [==============================] - 1s 115us/sample - loss: 0.9765 - accuracy: 0.5336 - val_loss: 0.9786 - val_accuracy: 0.5246\n",
      "Epoch 117/500\n",
      "5036/5036 [==============================] - 1s 116us/sample - loss: 0.9758 - accuracy: 0.5346 - val_loss: 0.9769 - val_accuracy: 0.5246\n",
      "Epoch 118/500\n",
      "5036/5036 [==============================] - 1s 117us/sample - loss: 0.9766 - accuracy: 0.5318 - val_loss: 0.9786 - val_accuracy: 0.5254\n",
      "Epoch 119/500\n",
      "5036/5036 [==============================] - 1s 121us/sample - loss: 0.9763 - accuracy: 0.5318 - val_loss: 0.9771 - val_accuracy: 0.5230\n",
      "Epoch 120/500\n",
      "5036/5036 [==============================] - 1s 119us/sample - loss: 0.9762 - accuracy: 0.5338 - val_loss: 0.9760 - val_accuracy: 0.5262\n",
      "Epoch 121/500\n",
      "5036/5036 [==============================] - 1s 120us/sample - loss: 0.9762 - accuracy: 0.5306 - val_loss: 0.9757 - val_accuracy: 0.5262\n",
      "Epoch 122/500\n",
      "5036/5036 [==============================] - 1s 119us/sample - loss: 0.9766 - accuracy: 0.5347 - val_loss: 0.9800 - val_accuracy: 0.5214\n",
      "Epoch 123/500\n",
      "5036/5036 [==============================] - 1s 121us/sample - loss: 0.9762 - accuracy: 0.5312 - val_loss: 0.9821 - val_accuracy: 0.5159\n",
      "Epoch 124/500\n",
      "5036/5036 [==============================] - 1s 172us/sample - loss: 0.9755 - accuracy: 0.5316 - val_loss: 0.9776 - val_accuracy: 0.5262\n",
      "Epoch 125/500\n",
      "5036/5036 [==============================] - 1s 130us/sample - loss: 0.9761 - accuracy: 0.5320 - val_loss: 0.9753 - val_accuracy: 0.5270\n",
      "Epoch 126/500\n",
      "5036/5036 [==============================] - 1s 160us/sample - loss: 0.9758 - accuracy: 0.5330 - val_loss: 0.9760 - val_accuracy: 0.5246\n",
      "Epoch 127/500\n",
      "5036/5036 [==============================] - 1s 144us/sample - loss: 0.9758 - accuracy: 0.5324 - val_loss: 0.9764 - val_accuracy: 0.5246\n",
      "Epoch 128/500\n",
      "5036/5036 [==============================] - 1s 122us/sample - loss: 0.9755 - accuracy: 0.5336 - val_loss: 0.9765 - val_accuracy: 0.5222\n",
      "Epoch 129/500\n",
      "5036/5036 [==============================] - 1s 117us/sample - loss: 0.9755 - accuracy: 0.5326 - val_loss: 0.9760 - val_accuracy: 0.5246\n",
      "Epoch 130/500\n",
      "5036/5036 [==============================] - 1s 122us/sample - loss: 0.9757 - accuracy: 0.5355 - val_loss: 0.9752 - val_accuracy: 0.5270\n",
      "Epoch 131/500\n",
      "5036/5036 [==============================] - 1s 127us/sample - loss: 0.9759 - accuracy: 0.5316 - val_loss: 0.9754 - val_accuracy: 0.5246\n",
      "Epoch 132/500\n",
      "5036/5036 [==============================] - 1s 122us/sample - loss: 0.9757 - accuracy: 0.5310 - val_loss: 0.9760 - val_accuracy: 0.5270\n",
      "Epoch 133/500\n",
      "5036/5036 [==============================] - 1s 129us/sample - loss: 0.9755 - accuracy: 0.5322 - val_loss: 0.9779 - val_accuracy: 0.5246\n",
      "Epoch 134/500\n",
      "5036/5036 [==============================] - 1s 127us/sample - loss: 0.9750 - accuracy: 0.5328 - val_loss: 0.9823 - val_accuracy: 0.5151\n",
      "Epoch 135/500\n",
      "5036/5036 [==============================] - 1s 149us/sample - loss: 0.9749 - accuracy: 0.5330 - val_loss: 0.9783 - val_accuracy: 0.5254\n",
      "Epoch 136/500\n",
      "5036/5036 [==============================] - 1s 142us/sample - loss: 0.9749 - accuracy: 0.5322 - val_loss: 0.9752 - val_accuracy: 0.5238\n",
      "Epoch 137/500\n",
      "5036/5036 [==============================] - 1s 174us/sample - loss: 0.9752 - accuracy: 0.5332 - val_loss: 0.9754 - val_accuracy: 0.5254\n",
      "Epoch 138/500\n",
      "5036/5036 [==============================] - 1s 118us/sample - loss: 0.9754 - accuracy: 0.5320 - val_loss: 0.9751 - val_accuracy: 0.5238\n",
      "Epoch 139/500\n",
      "5036/5036 [==============================] - 1s 122us/sample - loss: 0.9748 - accuracy: 0.5338 - val_loss: 0.9762 - val_accuracy: 0.5254\n",
      "Epoch 140/500\n",
      "5036/5036 [==============================] - 1s 115us/sample - loss: 0.9748 - accuracy: 0.5334 - val_loss: 0.9767 - val_accuracy: 0.5214\n",
      "Epoch 141/500\n",
      "5036/5036 [==============================] - 1s 117us/sample - loss: 0.9750 - accuracy: 0.5302 - val_loss: 0.9780 - val_accuracy: 0.5254\n",
      "Epoch 142/500\n",
      "5036/5036 [==============================] - 1s 112us/sample - loss: 0.9747 - accuracy: 0.5318 - val_loss: 0.9752 - val_accuracy: 0.5254\n",
      "Epoch 143/500\n",
      "5036/5036 [==============================] - 1s 125us/sample - loss: 0.9745 - accuracy: 0.5330 - val_loss: 0.9751 - val_accuracy: 0.5246\n",
      "Epoch 144/500\n",
      "5036/5036 [==============================] - 1s 124us/sample - loss: 0.9751 - accuracy: 0.5308 - val_loss: 0.9756 - val_accuracy: 0.5254\n",
      "Epoch 145/500\n",
      "5036/5036 [==============================] - 1s 123us/sample - loss: 0.9746 - accuracy: 0.5336 - val_loss: 0.9768 - val_accuracy: 0.5230\n",
      "Epoch 146/500\n",
      "5036/5036 [==============================] - 1s 177us/sample - loss: 0.9748 - accuracy: 0.5342 - val_loss: 0.9755 - val_accuracy: 0.5238\n",
      "Epoch 147/500\n",
      "5036/5036 [==============================] - 1s 114us/sample - loss: 0.9741 - accuracy: 0.5272 - val_loss: 0.9754 - val_accuracy: 0.5246\n",
      "Epoch 148/500\n",
      "5036/5036 [==============================] - 1s 129us/sample - loss: 0.9746 - accuracy: 0.5322 - val_loss: 0.9785 - val_accuracy: 0.5222\n",
      "Epoch 149/500\n",
      "5036/5036 [==============================] - 1s 140us/sample - loss: 0.9741 - accuracy: 0.5347 - val_loss: 0.9751 - val_accuracy: 0.5246\n",
      "Epoch 150/500\n",
      "5036/5036 [==============================] - 1s 118us/sample - loss: 0.9741 - accuracy: 0.5306 - val_loss: 0.9830 - val_accuracy: 0.5111\n",
      "Epoch 151/500\n",
      "5036/5036 [==============================] - 1s 119us/sample - loss: 0.9746 - accuracy: 0.5332 - val_loss: 0.9773 - val_accuracy: 0.5214\n",
      "Epoch 152/500\n",
      "5036/5036 [==============================] - 1s 131us/sample - loss: 0.9741 - accuracy: 0.5355 - val_loss: 0.9748 - val_accuracy: 0.5254\n",
      "Epoch 153/500\n",
      "5036/5036 [==============================] - 1s 162us/sample - loss: 0.9737 - accuracy: 0.5294 - val_loss: 0.9788 - val_accuracy: 0.5206\n",
      "Epoch 154/500\n",
      "5036/5036 [==============================] - 1s 126us/sample - loss: 0.9741 - accuracy: 0.5344 - val_loss: 0.9750 - val_accuracy: 0.5254\n",
      "Epoch 155/500\n",
      "5036/5036 [==============================] - 1s 137us/sample - loss: 0.9736 - accuracy: 0.5322 - val_loss: 0.9754 - val_accuracy: 0.5254\n",
      "Epoch 156/500\n",
      "5036/5036 [==============================] - 1s 128us/sample - loss: 0.9740 - accuracy: 0.5340 - val_loss: 0.9748 - val_accuracy: 0.5254\n",
      "Epoch 157/500\n",
      "5036/5036 [==============================] - 1s 163us/sample - loss: 0.9739 - accuracy: 0.5326 - val_loss: 0.9766 - val_accuracy: 0.5246\n",
      "Epoch 158/500\n",
      "5036/5036 [==============================] - 1s 127us/sample - loss: 0.9736 - accuracy: 0.5328 - val_loss: 0.9751 - val_accuracy: 0.5254\n",
      "Epoch 159/500\n",
      "5036/5036 [==============================] - 1s 136us/sample - loss: 0.9735 - accuracy: 0.5349 - val_loss: 0.9747 - val_accuracy: 0.5254\n",
      "Epoch 160/500\n",
      "5036/5036 [==============================] - 1s 137us/sample - loss: 0.9736 - accuracy: 0.5332 - val_loss: 0.9753 - val_accuracy: 0.5254\n",
      "Epoch 161/500\n",
      "5036/5036 [==============================] - 1s 120us/sample - loss: 0.9735 - accuracy: 0.5314 - val_loss: 0.9773 - val_accuracy: 0.5214\n",
      "Epoch 162/500\n",
      "5036/5036 [==============================] - 1s 120us/sample - loss: 0.9736 - accuracy: 0.5322 - val_loss: 0.9749 - val_accuracy: 0.5230\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5036/5036 [==============================] - 1s 122us/sample - loss: 0.9732 - accuracy: 0.5340 - val_loss: 0.9791 - val_accuracy: 0.5183\n",
      "Epoch 164/500\n",
      "5036/5036 [==============================] - 1s 116us/sample - loss: 0.9733 - accuracy: 0.5326 - val_loss: 0.9761 - val_accuracy: 0.5254\n",
      "Epoch 165/500\n",
      "5036/5036 [==============================] - 1s 125us/sample - loss: 0.9733 - accuracy: 0.5353 - val_loss: 0.9783 - val_accuracy: 0.5230\n",
      "Epoch 166/500\n",
      "5036/5036 [==============================] - 1s 112us/sample - loss: 0.9725 - accuracy: 0.5330 - val_loss: 0.9758 - val_accuracy: 0.5270\n",
      "Epoch 167/500\n",
      "5036/5036 [==============================] - 1s 120us/sample - loss: 0.9729 - accuracy: 0.5328 - val_loss: 0.9749 - val_accuracy: 0.5246\n",
      "Epoch 168/500\n",
      "5036/5036 [==============================] - 1s 127us/sample - loss: 0.9727 - accuracy: 0.5365 - val_loss: 0.9837 - val_accuracy: 0.5103\n",
      "Epoch 169/500\n",
      "5036/5036 [==============================] - 1s 133us/sample - loss: 0.9733 - accuracy: 0.5347 - val_loss: 0.9756 - val_accuracy: 0.5230\n",
      "Epoch 170/500\n",
      "5036/5036 [==============================] - 1s 172us/sample - loss: 0.9727 - accuracy: 0.5324 - val_loss: 0.9749 - val_accuracy: 0.5246\n",
      "Epoch 171/500\n",
      "5036/5036 [==============================] - 1s 126us/sample - loss: 0.9725 - accuracy: 0.5336 - val_loss: 0.9750 - val_accuracy: 0.5246\n",
      "Epoch 172/500\n",
      "5036/5036 [==============================] - 1s 102us/sample - loss: 0.9731 - accuracy: 0.5346 - val_loss: 0.9748 - val_accuracy: 0.5262\n",
      "Epoch 173/500\n",
      "5036/5036 [==============================] - 1s 107us/sample - loss: 0.9728 - accuracy: 0.5353 - val_loss: 0.9751 - val_accuracy: 0.5254\n",
      "Epoch 174/500\n",
      "5036/5036 [==============================] - 1s 104us/sample - loss: 0.9729 - accuracy: 0.5336 - val_loss: 0.9748 - val_accuracy: 0.5262\n",
      "Epoch 175/500\n",
      "5036/5036 [==============================] - 1s 101us/sample - loss: 0.9729 - accuracy: 0.5314 - val_loss: 0.9748 - val_accuracy: 0.5246\n",
      "Epoch 176/500\n",
      "5036/5036 [==============================] - 1s 100us/sample - loss: 0.9722 - accuracy: 0.5365 - val_loss: 0.9747 - val_accuracy: 0.5270\n",
      "Epoch 177/500\n",
      "5036/5036 [==============================] - 1s 103us/sample - loss: 0.9721 - accuracy: 0.5357 - val_loss: 0.9754 - val_accuracy: 0.5246\n",
      "Epoch 178/500\n",
      "5036/5036 [==============================] - 1s 103us/sample - loss: 0.9722 - accuracy: 0.5332 - val_loss: 0.9811 - val_accuracy: 0.5151\n",
      "Epoch 179/500\n",
      "5036/5036 [==============================] - 1s 101us/sample - loss: 0.9729 - accuracy: 0.5357 - val_loss: 0.9747 - val_accuracy: 0.5270\n",
      "Epoch 180/500\n",
      "5036/5036 [==============================] - 1s 102us/sample - loss: 0.9722 - accuracy: 0.5361 - val_loss: 0.9757 - val_accuracy: 0.5222\n",
      "Epoch 181/500\n",
      "5036/5036 [==============================] - 1s 103us/sample - loss: 0.9722 - accuracy: 0.5347 - val_loss: 0.9780 - val_accuracy: 0.5206\n",
      "Epoch 182/500\n",
      "5036/5036 [==============================] - 1s 104us/sample - loss: 0.9724 - accuracy: 0.5342 - val_loss: 0.9755 - val_accuracy: 0.5238\n",
      "Epoch 183/500\n",
      "5036/5036 [==============================] - 1s 103us/sample - loss: 0.9724 - accuracy: 0.5334 - val_loss: 0.9780 - val_accuracy: 0.5206\n",
      "Epoch 184/500\n",
      "5036/5036 [==============================] - 1s 115us/sample - loss: 0.9726 - accuracy: 0.5342 - val_loss: 0.9746 - val_accuracy: 0.5262\n",
      "Epoch 185/500\n",
      "5036/5036 [==============================] - 1s 138us/sample - loss: 0.9724 - accuracy: 0.5355 - val_loss: 0.9747 - val_accuracy: 0.5278\n",
      "Epoch 186/500\n",
      "5036/5036 [==============================] - 1s 134us/sample - loss: 0.9721 - accuracy: 0.5340 - val_loss: 0.9748 - val_accuracy: 0.5270\n",
      "Epoch 187/500\n",
      "5036/5036 [==============================] - 1s 129us/sample - loss: 0.9721 - accuracy: 0.5340 - val_loss: 0.9752 - val_accuracy: 0.5278\n",
      "Epoch 188/500\n",
      "5036/5036 [==============================] - 1s 109us/sample - loss: 0.9720 - accuracy: 0.5353 - val_loss: 0.9747 - val_accuracy: 0.5278\n",
      "Epoch 189/500\n",
      "5036/5036 [==============================] - 1s 119us/sample - loss: 0.9722 - accuracy: 0.5351 - val_loss: 0.9754 - val_accuracy: 0.5246\n",
      "Epoch 190/500\n",
      "5036/5036 [==============================] - 1s 109us/sample - loss: 0.9719 - accuracy: 0.5359 - val_loss: 0.9746 - val_accuracy: 0.5270\n",
      "Epoch 191/500\n",
      "5036/5036 [==============================] - 1s 115us/sample - loss: 0.9716 - accuracy: 0.5365 - val_loss: 0.9772 - val_accuracy: 0.5214\n",
      "Epoch 192/500\n",
      "5036/5036 [==============================] - 1s 117us/sample - loss: 0.9724 - accuracy: 0.5340 - val_loss: 0.9757 - val_accuracy: 0.5230\n",
      "Epoch 193/500\n",
      "5036/5036 [==============================] - 1s 116us/sample - loss: 0.9717 - accuracy: 0.5342 - val_loss: 0.9797 - val_accuracy: 0.5151\n",
      "Epoch 194/500\n",
      "5036/5036 [==============================] - 1s 117us/sample - loss: 0.9720 - accuracy: 0.5336 - val_loss: 0.9747 - val_accuracy: 0.5270\n",
      "Epoch 195/500\n",
      "5036/5036 [==============================] - 1s 140us/sample - loss: 0.9715 - accuracy: 0.5332 - val_loss: 0.9755 - val_accuracy: 0.5222\n",
      "Epoch 196/500\n",
      "5036/5036 [==============================] - 1s 138us/sample - loss: 0.9719 - accuracy: 0.5330 - val_loss: 0.9768 - val_accuracy: 0.5214\n",
      "Epoch 197/500\n",
      "5036/5036 [==============================] - 1s 152us/sample - loss: 0.9718 - accuracy: 0.5347 - val_loss: 0.9756 - val_accuracy: 0.5206\n",
      "Epoch 198/500\n",
      "5036/5036 [==============================] - 1s 175us/sample - loss: 0.9717 - accuracy: 0.5318 - val_loss: 0.9766 - val_accuracy: 0.5214\n",
      "Epoch 199/500\n",
      "5036/5036 [==============================] - 1s 109us/sample - loss: 0.9717 - accuracy: 0.5336 - val_loss: 0.9745 - val_accuracy: 0.5262\n",
      "Epoch 200/500\n",
      "5036/5036 [==============================] - 1s 144us/sample - loss: 0.9716 - accuracy: 0.5347 - val_loss: 0.9761 - val_accuracy: 0.5222\n",
      "Epoch 201/500\n",
      "5036/5036 [==============================] - 1s 136us/sample - loss: 0.9719 - accuracy: 0.5340 - val_loss: 0.9766 - val_accuracy: 0.5206\n",
      "Epoch 202/500\n",
      "5036/5036 [==============================] - 1s 112us/sample - loss: 0.9716 - accuracy: 0.5353 - val_loss: 0.9766 - val_accuracy: 0.5214\n",
      "Epoch 203/500\n",
      "5036/5036 [==============================] - 1s 107us/sample - loss: 0.9717 - accuracy: 0.5347 - val_loss: 0.9782 - val_accuracy: 0.5206\n",
      "Epoch 204/500\n",
      "5036/5036 [==============================] - 1s 101us/sample - loss: 0.9715 - accuracy: 0.5349 - val_loss: 0.9831 - val_accuracy: 0.5119\n",
      "Epoch 205/500\n",
      "5036/5036 [==============================] - 1s 100us/sample - loss: 0.9713 - accuracy: 0.5369 - val_loss: 0.9764 - val_accuracy: 0.5222\n",
      "Epoch 206/500\n",
      "5036/5036 [==============================] - 1s 100us/sample - loss: 0.9714 - accuracy: 0.5361 - val_loss: 0.9794 - val_accuracy: 0.5175\n",
      "Epoch 207/500\n",
      "5036/5036 [==============================] - 1s 104us/sample - loss: 0.9713 - accuracy: 0.5369 - val_loss: 0.9774 - val_accuracy: 0.5206\n",
      "Epoch 208/500\n",
      "5036/5036 [==============================] - 1s 100us/sample - loss: 0.9714 - accuracy: 0.5346 - val_loss: 0.9750 - val_accuracy: 0.5278\n",
      "Epoch 209/500\n",
      "5036/5036 [==============================] - 1s 104us/sample - loss: 0.9712 - accuracy: 0.5363 - val_loss: 0.9767 - val_accuracy: 0.5198\n",
      "Epoch 210/500\n",
      "5036/5036 [==============================] - 1s 100us/sample - loss: 0.9712 - accuracy: 0.5359 - val_loss: 0.9745 - val_accuracy: 0.5270\n",
      "Epoch 211/500\n",
      "5036/5036 [==============================] - 1s 105us/sample - loss: 0.9706 - accuracy: 0.5357 - val_loss: 0.9783 - val_accuracy: 0.5198\n",
      "Epoch 212/500\n",
      "5036/5036 [==============================] - 0s 99us/sample - loss: 0.9713 - accuracy: 0.5324 - val_loss: 0.9747 - val_accuracy: 0.5262\n",
      "Epoch 213/500\n",
      "5036/5036 [==============================] - 0s 99us/sample - loss: 0.9712 - accuracy: 0.5326 - val_loss: 0.9745 - val_accuracy: 0.5294\n",
      "Epoch 214/500\n",
      "5036/5036 [==============================] - 1s 145us/sample - loss: 0.9709 - accuracy: 0.5332 - val_loss: 0.9745 - val_accuracy: 0.5278\n",
      "Epoch 215/500\n",
      "5036/5036 [==============================] - 1s 170us/sample - loss: 0.9705 - accuracy: 0.5361 - val_loss: 0.9844 - val_accuracy: 0.5127\n",
      "Epoch 216/500\n",
      "5036/5036 [==============================] - 1s 155us/sample - loss: 0.9708 - accuracy: 0.5357 - val_loss: 0.9748 - val_accuracy: 0.5262\n",
      "Epoch 217/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5036/5036 [==============================] - 1s 131us/sample - loss: 0.9709 - accuracy: 0.5336 - val_loss: 0.9746 - val_accuracy: 0.5270\n",
      "Epoch 218/500\n",
      "5036/5036 [==============================] - 1s 138us/sample - loss: 0.9705 - accuracy: 0.5347 - val_loss: 0.9774 - val_accuracy: 0.5206\n",
      "Epoch 219/500\n",
      "5036/5036 [==============================] - 1s 112us/sample - loss: 0.9709 - accuracy: 0.5367 - val_loss: 0.9770 - val_accuracy: 0.5222\n",
      "Epoch 220/500\n",
      "5036/5036 [==============================] - 1s 101us/sample - loss: 0.9705 - accuracy: 0.5347 - val_loss: 0.9749 - val_accuracy: 0.5262\n",
      "Epoch 221/500\n",
      "5036/5036 [==============================] - 1s 100us/sample - loss: 0.9703 - accuracy: 0.5351 - val_loss: 0.9748 - val_accuracy: 0.5286\n",
      "Epoch 222/500\n",
      "5036/5036 [==============================] - 0s 99us/sample - loss: 0.9709 - accuracy: 0.5346 - val_loss: 0.9747 - val_accuracy: 0.5286\n",
      "Epoch 223/500\n",
      "5036/5036 [==============================] - 0s 97us/sample - loss: 0.9706 - accuracy: 0.5365 - val_loss: 0.9784 - val_accuracy: 0.5175\n",
      "Epoch 224/500\n",
      "5036/5036 [==============================] - 1s 100us/sample - loss: 0.9698 - accuracy: 0.5363 - val_loss: 0.9758 - val_accuracy: 0.5222\n",
      "Epoch 225/500\n",
      "5036/5036 [==============================] - 1s 100us/sample - loss: 0.9705 - accuracy: 0.5359 - val_loss: 0.9750 - val_accuracy: 0.5278\n",
      "Epoch 226/500\n",
      "5036/5036 [==============================] - 1s 100us/sample - loss: 0.9708 - accuracy: 0.5357 - val_loss: 0.9779 - val_accuracy: 0.5175\n",
      "Epoch 227/500\n",
      "5036/5036 [==============================] - 0s 98us/sample - loss: 0.9704 - accuracy: 0.5353 - val_loss: 0.9747 - val_accuracy: 0.5278\n",
      "Epoch 228/500\n",
      "5036/5036 [==============================] - 1s 105us/sample - loss: 0.9704 - accuracy: 0.5365 - val_loss: 0.9746 - val_accuracy: 0.5270\n",
      "Epoch 229/500\n",
      "5036/5036 [==============================] - 1s 100us/sample - loss: 0.9704 - accuracy: 0.5371 - val_loss: 0.9745 - val_accuracy: 0.5286\n",
      "Epoch 230/500\n",
      "5036/5036 [==============================] - 1s 100us/sample - loss: 0.9701 - accuracy: 0.5346 - val_loss: 0.9776 - val_accuracy: 0.5198\n",
      "Epoch 231/500\n",
      "5036/5036 [==============================] - 0s 98us/sample - loss: 0.9703 - accuracy: 0.5359 - val_loss: 0.9745 - val_accuracy: 0.5294\n",
      "Epoch 232/500\n",
      "5036/5036 [==============================] - 1s 104us/sample - loss: 0.9702 - accuracy: 0.5336 - val_loss: 0.9774 - val_accuracy: 0.5214\n",
      "Epoch 233/500\n",
      "5036/5036 [==============================] - 1s 99us/sample - loss: 0.9700 - accuracy: 0.5328 - val_loss: 0.9823 - val_accuracy: 0.5087\n",
      "Epoch 234/500\n",
      "5036/5036 [==============================] - 1s 101us/sample - loss: 0.9705 - accuracy: 0.5355 - val_loss: 0.9752 - val_accuracy: 0.5222\n",
      "Epoch 235/500\n",
      "5036/5036 [==============================] - 0s 98us/sample - loss: 0.9701 - accuracy: 0.5347 - val_loss: 0.9747 - val_accuracy: 0.5270\n",
      "Epoch 236/500\n",
      "5036/5036 [==============================] - 1s 103us/sample - loss: 0.9700 - accuracy: 0.5347 - val_loss: 0.9749 - val_accuracy: 0.5246\n",
      "Epoch 237/500\n",
      "5036/5036 [==============================] - 1s 102us/sample - loss: 0.9701 - accuracy: 0.5377 - val_loss: 0.9768 - val_accuracy: 0.5214\n",
      "Epoch 238/500\n",
      "5036/5036 [==============================] - 1s 137us/sample - loss: 0.9702 - accuracy: 0.5353 - val_loss: 0.9745 - val_accuracy: 0.5278\n",
      "Epoch 239/500\n",
      "5036/5036 [==============================] - 1s 113us/sample - loss: 0.9700 - accuracy: 0.5351 - val_loss: 0.9799 - val_accuracy: 0.5159\n",
      "Epoch 240/500\n",
      "5036/5036 [==============================] - 1s 143us/sample - loss: 0.9699 - accuracy: 0.5365 - val_loss: 0.9767 - val_accuracy: 0.5198\n",
      "Epoch 241/500\n",
      "5036/5036 [==============================] - 1s 125us/sample - loss: 0.9700 - accuracy: 0.5369 - val_loss: 0.9746 - val_accuracy: 0.5286\n",
      "Epoch 242/500\n",
      "5036/5036 [==============================] - 1s 156us/sample - loss: 0.9696 - accuracy: 0.5353 - val_loss: 0.9823 - val_accuracy: 0.5127\n",
      "Epoch 243/500\n",
      "5036/5036 [==============================] - 1s 159us/sample - loss: 0.9702 - accuracy: 0.5351 - val_loss: 0.9780 - val_accuracy: 0.5167\n",
      "Epoch 244/500\n",
      "5036/5036 [==============================] - 1s 123us/sample - loss: 0.9698 - accuracy: 0.5338 - val_loss: 0.9744 - val_accuracy: 0.5262\n",
      "Epoch 245/500\n",
      "5036/5036 [==============================] - 1s 124us/sample - loss: 0.9697 - accuracy: 0.5346 - val_loss: 0.9745 - val_accuracy: 0.5270\n",
      "Epoch 246/500\n",
      "5036/5036 [==============================] - 1s 119us/sample - loss: 0.9693 - accuracy: 0.5383 - val_loss: 0.9747 - val_accuracy: 0.5254\n",
      "Epoch 247/500\n",
      "5036/5036 [==============================] - 1s 115us/sample - loss: 0.9695 - accuracy: 0.5371 - val_loss: 0.9745 - val_accuracy: 0.5270\n",
      "Epoch 248/500\n",
      "5036/5036 [==============================] - 1s 110us/sample - loss: 0.9701 - accuracy: 0.5361 - val_loss: 0.9753 - val_accuracy: 0.5238\n",
      "Epoch 249/500\n",
      "5036/5036 [==============================] - 1s 179us/sample - loss: 0.9694 - accuracy: 0.5340 - val_loss: 0.9745 - val_accuracy: 0.5254\n",
      "Epoch 250/500\n",
      "5036/5036 [==============================] - 1s 125us/sample - loss: 0.9696 - accuracy: 0.5365 - val_loss: 0.9757 - val_accuracy: 0.5206\n",
      "Epoch 251/500\n",
      "5036/5036 [==============================] - 1s 118us/sample - loss: 0.9695 - accuracy: 0.5371 - val_loss: 0.9745 - val_accuracy: 0.5262\n",
      "Epoch 252/500\n",
      "5036/5036 [==============================] - 1s 117us/sample - loss: 0.9692 - accuracy: 0.5344 - val_loss: 0.9747 - val_accuracy: 0.5254\n",
      "Epoch 253/500\n",
      "5036/5036 [==============================] - 1s 121us/sample - loss: 0.9696 - accuracy: 0.5346 - val_loss: 0.9746 - val_accuracy: 0.5278\n",
      "Epoch 254/500\n",
      "5036/5036 [==============================] - 1s 151us/sample - loss: 0.9689 - accuracy: 0.5365 - val_loss: 0.9755 - val_accuracy: 0.5238\n",
      "Epoch 255/500\n",
      "5036/5036 [==============================] - 1s 138us/sample - loss: 0.9693 - accuracy: 0.5371 - val_loss: 0.9772 - val_accuracy: 0.5198\n",
      "Epoch 256/500\n",
      "5036/5036 [==============================] - 1s 145us/sample - loss: 0.9695 - accuracy: 0.5367 - val_loss: 0.9750 - val_accuracy: 0.5254\n",
      "Epoch 257/500\n",
      "5036/5036 [==============================] - 1s 130us/sample - loss: 0.9692 - accuracy: 0.5379 - val_loss: 0.9800 - val_accuracy: 0.5143\n",
      "Epoch 258/500\n",
      "5036/5036 [==============================] - 1s 150us/sample - loss: 0.9689 - accuracy: 0.5385 - val_loss: 0.9792 - val_accuracy: 0.5151\n",
      "Epoch 259/500\n",
      "5036/5036 [==============================] - 1s 156us/sample - loss: 0.9692 - accuracy: 0.5363 - val_loss: 0.9770 - val_accuracy: 0.5214\n",
      "Epoch 260/500\n",
      "5036/5036 [==============================] - 1s 117us/sample - loss: 0.9696 - accuracy: 0.5320 - val_loss: 0.9761 - val_accuracy: 0.5206\n",
      "Epoch 261/500\n",
      "5036/5036 [==============================] - 1s 119us/sample - loss: 0.9690 - accuracy: 0.5349 - val_loss: 0.9744 - val_accuracy: 0.5254\n",
      "Epoch 262/500\n",
      "5036/5036 [==============================] - 1s 137us/sample - loss: 0.9690 - accuracy: 0.5365 - val_loss: 0.9745 - val_accuracy: 0.5254\n",
      "Epoch 263/500\n",
      "5036/5036 [==============================] - 1s 132us/sample - loss: 0.9690 - accuracy: 0.5349 - val_loss: 0.9778 - val_accuracy: 0.5183\n",
      "Epoch 264/500\n",
      "5036/5036 [==============================] - 1s 136us/sample - loss: 0.9694 - accuracy: 0.5371 - val_loss: 0.9789 - val_accuracy: 0.5143\n",
      "Epoch 265/500\n",
      "5036/5036 [==============================] - 1s 141us/sample - loss: 0.9693 - accuracy: 0.5355 - val_loss: 0.9745 - val_accuracy: 0.5270\n",
      "Epoch 266/500\n",
      "5036/5036 [==============================] - 1s 152us/sample - loss: 0.9685 - accuracy: 0.5369 - val_loss: 0.9763 - val_accuracy: 0.5198\n",
      "Epoch 267/500\n",
      "5036/5036 [==============================] - 1s 142us/sample - loss: 0.9690 - accuracy: 0.5363 - val_loss: 0.9829 - val_accuracy: 0.5103\n",
      "Epoch 268/500\n",
      "5036/5036 [==============================] - 1s 129us/sample - loss: 0.9692 - accuracy: 0.5353 - val_loss: 0.9745 - val_accuracy: 0.5254\n",
      "Epoch 269/500\n",
      "5036/5036 [==============================] - 1s 160us/sample - loss: 0.9688 - accuracy: 0.5367 - val_loss: 0.9751 - val_accuracy: 0.5254\n",
      "Epoch 270/500\n",
      "5036/5036 [==============================] - 1s 143us/sample - loss: 0.9688 - accuracy: 0.5371 - val_loss: 0.9745 - val_accuracy: 0.5246\n",
      "Epoch 271/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5036/5036 [==============================] - 1s 113us/sample - loss: 0.9681 - accuracy: 0.5381 - val_loss: 0.9759 - val_accuracy: 0.5206\n",
      "Epoch 272/500\n",
      "5036/5036 [==============================] - 1s 104us/sample - loss: 0.9691 - accuracy: 0.5355 - val_loss: 0.9759 - val_accuracy: 0.5222\n",
      "Epoch 273/500\n",
      "5036/5036 [==============================] - 1s 100us/sample - loss: 0.9689 - accuracy: 0.5369 - val_loss: 0.9805 - val_accuracy: 0.5135\n",
      "Epoch 274/500\n",
      "5036/5036 [==============================] - 0s 99us/sample - loss: 0.9692 - accuracy: 0.5377 - val_loss: 0.9772 - val_accuracy: 0.5159\n",
      "Epoch 275/500\n",
      "5036/5036 [==============================] - 0s 99us/sample - loss: 0.9690 - accuracy: 0.5367 - val_loss: 0.9761 - val_accuracy: 0.5206\n",
      "Epoch 276/500\n",
      "5036/5036 [==============================] - 1s 100us/sample - loss: 0.9686 - accuracy: 0.5367 - val_loss: 0.9753 - val_accuracy: 0.5262\n",
      "Epoch 277/500\n",
      "5036/5036 [==============================] - 0s 98us/sample - loss: 0.9692 - accuracy: 0.5377 - val_loss: 0.9745 - val_accuracy: 0.5246\n",
      "Epoch 278/500\n",
      "5036/5036 [==============================] - 0s 98us/sample - loss: 0.9688 - accuracy: 0.5355 - val_loss: 0.9781 - val_accuracy: 0.5190\n",
      "Epoch 279/500\n",
      "5036/5036 [==============================] - 1s 100us/sample - loss: 0.9686 - accuracy: 0.5359 - val_loss: 0.9746 - val_accuracy: 0.5246\n",
      "Epoch 280/500\n",
      "5036/5036 [==============================] - 1s 138us/sample - loss: 0.9687 - accuracy: 0.5379 - val_loss: 0.9771 - val_accuracy: 0.5175\n",
      "Epoch 281/500\n",
      "5036/5036 [==============================] - 1s 111us/sample - loss: 0.9683 - accuracy: 0.5379 - val_loss: 0.9751 - val_accuracy: 0.5246\n",
      "Epoch 282/500\n",
      "5036/5036 [==============================] - 1s 125us/sample - loss: 0.9690 - accuracy: 0.5375 - val_loss: 0.9773 - val_accuracy: 0.5175\n",
      "Epoch 283/500\n",
      "5036/5036 [==============================] - 1s 117us/sample - loss: 0.9683 - accuracy: 0.5369 - val_loss: 0.9753 - val_accuracy: 0.5246\n",
      "Epoch 284/500\n",
      "5036/5036 [==============================] - 1s 119us/sample - loss: 0.9686 - accuracy: 0.5353 - val_loss: 0.9750 - val_accuracy: 0.5222\n",
      "Epoch 285/500\n",
      "5036/5036 [==============================] - 1s 103us/sample - loss: 0.9685 - accuracy: 0.5371 - val_loss: 0.9780 - val_accuracy: 0.5151\n",
      "Epoch 286/500\n",
      "5036/5036 [==============================] - 1s 104us/sample - loss: 0.9682 - accuracy: 0.5363 - val_loss: 0.9747 - val_accuracy: 0.5254\n",
      "Epoch 287/500\n",
      "5036/5036 [==============================] - 1s 104us/sample - loss: 0.9684 - accuracy: 0.5377 - val_loss: 0.9756 - val_accuracy: 0.5254\n",
      "Epoch 288/500\n",
      "5036/5036 [==============================] - 1s 101us/sample - loss: 0.9683 - accuracy: 0.5349 - val_loss: 0.9753 - val_accuracy: 0.5246\n",
      "Epoch 289/500\n",
      "5036/5036 [==============================] - 1s 103us/sample - loss: 0.9681 - accuracy: 0.5363 - val_loss: 0.9793 - val_accuracy: 0.5143\n",
      "Epoch 290/500\n",
      "5036/5036 [==============================] - 1s 123us/sample - loss: 0.9679 - accuracy: 0.5385 - val_loss: 0.9746 - val_accuracy: 0.5238\n",
      "Epoch 291/500\n",
      "5036/5036 [==============================] - 1s 112us/sample - loss: 0.9683 - accuracy: 0.5338 - val_loss: 0.9747 - val_accuracy: 0.5230\n",
      "Epoch 292/500\n",
      "5036/5036 [==============================] - 1s 118us/sample - loss: 0.9685 - accuracy: 0.5363 - val_loss: 0.9751 - val_accuracy: 0.5230\n",
      "Epoch 293/500\n",
      "5036/5036 [==============================] - 1s 121us/sample - loss: 0.9685 - accuracy: 0.5349 - val_loss: 0.9805 - val_accuracy: 0.5095\n",
      "Epoch 294/500\n",
      "5036/5036 [==============================] - 1s 120us/sample - loss: 0.9681 - accuracy: 0.5375 - val_loss: 0.9778 - val_accuracy: 0.5175\n",
      "Epoch 295/500\n",
      "5036/5036 [==============================] - 1s 157us/sample - loss: 0.9681 - accuracy: 0.5365 - val_loss: 0.9751 - val_accuracy: 0.5230\n",
      "Epoch 296/500\n",
      "5036/5036 [==============================] - 1s 120us/sample - loss: 0.9675 - accuracy: 0.5367 - val_loss: 0.9822 - val_accuracy: 0.5103\n",
      "Epoch 297/500\n",
      "5036/5036 [==============================] - 1s 123us/sample - loss: 0.9681 - accuracy: 0.5389 - val_loss: 0.9746 - val_accuracy: 0.5238\n",
      "Epoch 298/500\n",
      "5036/5036 [==============================] - 1s 122us/sample - loss: 0.9682 - accuracy: 0.5367 - val_loss: 0.9773 - val_accuracy: 0.5167\n",
      "Epoch 299/500\n",
      "2464/5036 [=============>................] - ETA: 0s - loss: 0.9637 - accuracy: 0.5394"
     ]
    }
   ],
   "source": [
    "model04.fit(train_X04, train_y04, validation_split=validation_split,epochs=epochs,callbacks=[early_stoping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model01.evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "\n",
    "plt.plot(model01.history.history['accuracy'])\n",
    "plt.plot(model01.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(model01.history.history['loss'])\n",
    "plt.plot(model01.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model02.evaluate(test_X02, test_y02, verbose=0)\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "\n",
    "plt.plot(model02.history.history['accuracy'])\n",
    "plt.plot(model02.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(model02.history.history['loss'])\n",
    "plt.plot(model02.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model03.evaluate(test_X03, test_y03, verbose=0)\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "\n",
    "plt.plot(model03.history.history['accuracy'])\n",
    "plt.plot(model03.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(model03.history.history['loss'])\n",
    "plt.plot(model03.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model04.evaluate(test_X04, test_y04, verbose=0)\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "\n",
    "plt.plot(model04.history.history['accuracy'])\n",
    "plt.plot(model04.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(model04.history.history['loss'])\n",
    "plt.plot(model04.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model01.predict_proba(test_X01)\n",
    "for i in range(len(test_X01)):\n",
    "\tprint(\"X=%s, Predicted=%s\" % (test_X01[i], pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model02.predict_proba(test_X02)\n",
    "for i in range(len(test_X02)):\n",
    "\tprint(\"X=%s, Predicted=%s\" % (test_X02[i], pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model03.predict_proba(test_X03)\n",
    "for i in range(len(test_X03)):\n",
    "\tprint(\"X=%s, Predicted=%s\" % (test_X03[i], pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model04.predict_proba(test_X04)\n",
    "for i in range(len(test_X04)):\n",
    "\tprint(\"X=%s, Predicted=%s\" % (test_X04[i], pred[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
